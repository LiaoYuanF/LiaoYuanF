{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"source/images/Cpp-Basics-3-1.png","path":"images/Cpp-Basics-3-1.png","modified":0,"renderable":0},{"_id":"source/images/cache-friendly-1.png","path":"images/cache-friendly-1.png","modified":0,"renderable":0},{"_id":"source/images/cache-friendly-2.png","path":"images/cache-friendly-2.png","modified":0,"renderable":0},{"_id":"source/images/lock-free-programming-1.png","path":"images/lock-free-programming-1.png","modified":0,"renderable":0},{"_id":"source/images/lock-free-programming-2.png","path":"images/lock-free-programming-2.png","modified":0,"renderable":0},{"_id":"source/images/pattern-1.png","path":"images/pattern-1.png","modified":0,"renderable":0},{"_id":"themes/archer/source/assets/algolia_logo.svg","path":"assets/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/archer/source/assets/beian.png","path":"assets/beian.png","modified":0,"renderable":1},{"_id":"themes/archer/source/assets/example_qr.png","path":"assets/example_qr.png","modified":0,"renderable":1},{"_id":"themes/archer/source/assets/favicon.ico","path":"assets/favicon.ico","modified":0,"renderable":1},{"_id":"themes/archer/source/assets/loading.svg","path":"assets/loading.svg","modified":0,"renderable":1},{"_id":"themes/archer/source/avatar/Misaka.jpg","path":"avatar/Misaka.jpg","modified":0,"renderable":1},{"_id":"themes/archer/source/css/dark.css","path":"css/dark.css","modified":0,"renderable":1},{"_id":"themes/archer/source/css/dark.css.map","path":"css/dark.css.map","modified":0,"renderable":1},{"_id":"themes/archer/source/css/mobile.css","path":"css/mobile.css","modified":0,"renderable":1},{"_id":"themes/archer/source/css/mobile.css.map","path":"css/mobile.css.map","modified":0,"renderable":1},{"_id":"themes/archer/source/css/style.css","path":"css/style.css","modified":0,"renderable":1},{"_id":"themes/archer/source/css/style.css.map","path":"css/style.css.map","modified":0,"renderable":1},{"_id":"themes/archer/source/font/Oswald-Regular.ttf","path":"font/Oswald-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/archer/source/font/Source Sans Pro.woff","path":"font/Source Sans Pro.woff","modified":0,"renderable":1},{"_id":"themes/archer/source/font/Source Sans Pro.woff2","path":"font/Source Sans Pro.woff2","modified":0,"renderable":1},{"_id":"themes/archer/source/font/SourceCodePro-Regular.ttf.woff","path":"font/SourceCodePro-Regular.ttf.woff","modified":0,"renderable":1},{"_id":"themes/archer/source/font/SourceCodePro-Regular.ttf.woff2","path":"font/SourceCodePro-Regular.ttf.woff2","modified":0,"renderable":1},{"_id":"themes/archer/source/intro/404-bg.jpg","path":"intro/404-bg.jpg","modified":0,"renderable":1},{"_id":"themes/archer/source/intro/about-bg.jpg","path":"intro/about-bg.jpg","modified":0,"renderable":1},{"_id":"themes/archer/source/intro/index-bg.jpg","path":"intro/index-bg.jpg","modified":0,"renderable":1},{"_id":"themes/archer/source/intro/post-bg.jpg","path":"intro/post-bg.jpg","modified":0,"renderable":1},{"_id":"themes/archer/source/lib/jquery.min.js","path":"lib/jquery.min.js","modified":0,"renderable":1},{"_id":"themes/archer/source/lib/webfontloader.min.js","path":"lib/webfontloader.min.js","modified":0,"renderable":1},{"_id":"themes/archer/source/scripts/customFontLoader.js","path":"scripts/customFontLoader.js","modified":0,"renderable":1},{"_id":"themes/archer/source/scripts/customFontLoader.js.map","path":"scripts/customFontLoader.js.map","modified":0,"renderable":1},{"_id":"themes/archer/source/scripts/dark.js","path":"scripts/dark.js","modified":0,"renderable":1},{"_id":"themes/archer/source/scripts/dark.js.map","path":"scripts/dark.js.map","modified":0,"renderable":1},{"_id":"themes/archer/source/scripts/main.js","path":"scripts/main.js","modified":0,"renderable":1},{"_id":"themes/archer/source/scripts/main.js.LICENSE.txt","path":"scripts/main.js.LICENSE.txt","modified":0,"renderable":1},{"_id":"themes/archer/source/scripts/main.js.map","path":"scripts/main.js.map","modified":0,"renderable":1},{"_id":"themes/archer/source/scripts/search.js","path":"scripts/search.js","modified":0,"renderable":1},{"_id":"themes/archer/source/scripts/search.js.LICENSE.txt","path":"scripts/search.js.LICENSE.txt","modified":0,"renderable":1},{"_id":"themes/archer/source/scripts/search.js.map","path":"scripts/search.js.map","modified":0,"renderable":1},{"_id":"themes/archer/source/scripts/share.js","path":"scripts/share.js","modified":0,"renderable":1},{"_id":"themes/archer/source/scripts/share.js.map","path":"scripts/share.js.map","modified":0,"renderable":1},{"_id":"source/images/git-note/1.png","path":"images/git-note/1.png","modified":1,"renderable":0},{"_id":"source/images/git-note/2.png","path":"images/git-note/2.png","modified":1,"renderable":0},{"_id":"source/images/git-note/3.png","path":"images/git-note/3.png","modified":1,"renderable":0},{"_id":"source/images/git-note/4.png","path":"images/git-note/4.png","modified":1,"renderable":0},{"_id":"source/images/git-note/5.png","path":"images/git-note/5.png","modified":1,"renderable":0},{"_id":"source/images/git-note/6.png","path":"images/git-note/6.png","modified":1,"renderable":0},{"_id":"source/images/git-note/7.png","path":"images/git-note/7.png","modified":1,"renderable":0},{"_id":"source/images/git-note/8.png","path":"images/git-note/8.png","modified":1,"renderable":0},{"_id":"source/images/git-note/9.png","path":"images/git-note/9.png","modified":1,"renderable":0}],"Cache":[{"_id":"source/_posts/Chain-of-responsibility.md","hash":"70b04a0c3b2280fee8bc921bbc126335fd507616","modified":1702731861172},{"_id":"source/_posts/Cpp-basics-1.md","hash":"50555c469708548399fe8c4b1ae6a2f9f4cf48cc","modified":1702307543053},{"_id":"source/_posts/Cpp-basics-2.md","hash":"bcf386e8add4df4629dfcc29725fb44483ea4b91","modified":1702307552817},{"_id":"source/_posts/Cpp-basics-3.md","hash":"9bcc295c9921ff50ef4a2f7ba3b79a653abb4400","modified":1702307562049},{"_id":"source/_posts/Cpp-basics-4.md","hash":"0a882acecbc8ac648cde2b5679c28e3c829be067","modified":1702307571509},{"_id":"source/_posts/Cpp-basics-5.md","hash":"23eae02768c2a1c419124ad6af54862ed11598bf","modified":1702307580477},{"_id":"source/_posts/Template-programming-1.md","hash":"6468a228b5e0df210112afa5fa7f192a8a29b62a","modified":1702307589473},{"_id":"source/_posts/Thread-safe-circular-queue.md","hash":"8770fa533cc7dda2fb9bbbb12c517a77f0380c00","modified":1705627362463},{"_id":"source/_posts/cache-friendly-programming.md","hash":"9310255a4c3479137567e3664f96020e6231922a","modified":1705545911477},{"_id":"source/_posts/lock-free-programming.md","hash":"263578ab2569346f0659518a7fe5bb0f59a1a9de","modified":1702567127854},{"_id":"source/_posts/some-plans.md","hash":"c16282b0a564daefaa6c09f1dc2144370287d664","modified":1701459323498},{"_id":"source/about/index.md","hash":"d1c4144be14d041ccdb52c7707dcb2c514fe2b80","modified":1705395951786},{"_id":"source/images/Cpp-Basics-3-1.png","hash":"d37ee7ca1525dccd14fb09b71a8d84dc9f528bff","modified":1701615551509},{"_id":"source/images/cache-friendly-2.png","hash":"2bc8adca12bdfb357ca23c3bac491f3d3a171512","modified":1705505625607},{"_id":"source/images/cache-friendly-1.png","hash":"bc7f3894c0e354738369495b5635c5ad4fba712d","modified":1705505625607},{"_id":"source/images/lock-free-programming-2.png","hash":"f2999eceb49bb569f4b7a5f3eb8732c8a61931a6","modified":1702567025426},{"_id":"source/images/lock-free-programming-1.png","hash":"bba06b112ba07b2d6ceb0cbc2b1a29ad3272ebfa","modified":1702567024942},{"_id":"source/images/pattern-1.png","hash":"74a4573dadbe3a7927a146610cb34230ab439c52","modified":1702731607969},{"_id":"themes/archer/layout/_partial/comment/custom.ejs","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1701423241264},{"_id":"themes/archer/.babelrc","hash":"078678843ebb6992f0cc44304faa6f1cb082bd4a","modified":1701423241260},{"_id":"themes/archer/.editorconfig","hash":"3a7f38d9586f73ed1c46cfbc9839b3465ec57d7c","modified":1701423241260},{"_id":"themes/archer/.eslintignore","hash":"304e696987e3f31cd0a7a13a835d58d8bda3aa6c","modified":1701423241260},{"_id":"themes/archer/.eslintrc.json","hash":"352a07b94efa124a5658b502bf973683be09fd00","modified":1701423241260},{"_id":"themes/archer/.gitattributes","hash":"82c1a621642d5b620275ae1ed59845c3f7015a64","modified":1701423241260},{"_id":"themes/archer/.gitignore","hash":"9a5e5d0a05fc5bee9bf00a0c5cefc712b4bf0904","modified":1701423241260},{"_id":"themes/archer/.prettierignore","hash":"29648a30c14f6df709eb6610f506c82825910cc8","modified":1701423241264},{"_id":"themes/archer/.prettierrc.js","hash":"bae1d8dab7bf8b68207386f366e092778940540c","modified":1701423241264},{"_id":"themes/archer/CHANGELOG.md","hash":"6fbf3e5e8ed6ae6fb68fd74bfd2b53d99db4b1fd","modified":1701423241264},{"_id":"themes/archer/LICENSE","hash":"0da0c361bf299375739c6b668a44af0f5faf37bb","modified":1701423241264},{"_id":"themes/archer/README.md","hash":"63eb0f874bc056d407ee343f853adee9a5765434","modified":1701423241264},{"_id":"themes/archer/_config.yml","hash":"3a20bbd6b61b0d95432ec94dca0157084e02546d","modified":1702311024237},{"_id":"themes/archer/gulpfile.js","hash":"ee1ad57aa5113a084091fd86fca2c34e1b9e4b95","modified":1701423241264},{"_id":"themes/archer/package.json","hash":"81af75826e854ac80f6337dc4f1ce4b51f066b0b","modified":1701423241272},{"_id":"themes/archer/webpack.config.js","hash":"e090744d8e7a0d0906d1d6b8192eb906092d1e9b","modified":1701423241304},{"_id":"themes/archer/webpack.dev.js","hash":"7c740341894bd584f72145512a58703bb134ea60","modified":1701423241304},{"_id":"themes/archer/webpack.prod.js","hash":"a34abc06d6cd8fa4e267069468726322a3656e2b","modified":1701423241304},{"_id":"themes/archer/dev/archer.sh","hash":"4065c4e55462d5ecf016464adea0d1db967ef4b4","modified":1701423241264},{"_id":"themes/archer/docs/README-en.md","hash":"f5e40c5803071bd6dafc94070c6939aa0c02d061","modified":1701423241264},{"_id":"themes/archer/docs/develop-guide-en.md","hash":"c62510d3d14b38126b5a86ff30416cb71abc1d9a","modified":1701423241264},{"_id":"themes/archer/docs/develop-guide-zh.md","hash":"451b304c1a5d081313f0532a4f5665f0855d4cfd","modified":1701423241264},{"_id":"themes/archer/languages/default.yml","hash":"e937791c5080868c3abe20bab4cf266a342b5922","modified":1701423241264},{"_id":"themes/archer/languages/en.yml","hash":"5a1a85fed95dab4f01671714ee8cc5420936c05f","modified":1701423241264},{"_id":"themes/archer/layout/404.ejs","hash":"9137c0b1153ca8cd32e60a38fd79b7e4b91c8bf4","modified":1701423241264},{"_id":"themes/archer/layout/about.ejs","hash":"748786bebad03b1ef79c551f26522fa2bee1b9dd","modified":1701423241264},{"_id":"themes/archer/layout/index.ejs","hash":"093f8dbe875cad94b9618f181d1b5621d8874b19","modified":1701423241264},{"_id":"themes/archer/layout/layout.ejs","hash":"1bee90a75c1f4b04c90421419dd68acdec15b998","modified":1701423241264},{"_id":"themes/archer/layout/post.ejs","hash":"d421aba0ab93e2b7a22d060da4c56441bf97cdb9","modified":1701423241264},{"_id":"themes/archer/layout/site-meta.ejs","hash":"562e446a742fde07e0880343d5693bf8cb0dec23","modified":1701423241264},{"_id":"themes/archer/.github/ISSUE_TEMPLATE/-----------bug--help-wanted-or-bug-report-.md","hash":"55e843652d99fae32534a7630e698d2394020baf","modified":1701423241260},{"_id":"themes/archer/.github/ISSUE_TEMPLATE/-----feature-request-.md","hash":"edb6b06041660beb656fd5e4062d5a21577cbb3a","modified":1701423241260},{"_id":"themes/archer/.github/ISSUE_TEMPLATE/-----other-issue-.md","hash":"05f24b2df012808f6410f1ef2230d4fd1a5d6cf5","modified":1701423241260},{"_id":"themes/archer/.github/workflows/deploy-demo-page.yml","hash":"91c065ee0ec29f7bb10263fefa6f3072bc493a38","modified":1701423241260},{"_id":"themes/archer/layout/_partial/algolia.ejs","hash":"c7bf50dd6e60fd8e8dfbeab9960172359af7307e","modified":1701423241264},{"_id":"themes/archer/layout/_partial/base-background-image.ejs","hash":"18365516cd8819de853716f0d47a72a60a5edc46","modified":1701423241264},{"_id":"themes/archer/layout/_partial/base-footer-fixed.ejs","hash":"e4dbde6594c0c2d1c5de71ddf968be0879ceddb7","modified":1701423241264},{"_id":"themes/archer/layout/_partial/base-footer.ejs","hash":"d8f4236166d058421c2e4ff00660be75a3494704","modified":1701423241264},{"_id":"themes/archer/layout/_partial/base-head.ejs","hash":"687c08823e7ce43e6ebb44f2fb4b75549abfed29","modified":1701423241264},{"_id":"themes/archer/layout/_partial/base-header.ejs","hash":"57d1ae0fd6f9f1ab52a64c44a8ae17ee71de22ef","modified":1701423241264},{"_id":"themes/archer/layout/_partial/base-preload-polyfill.ejs","hash":"d046322674052b0667775dca0886f14e0d812897","modified":1701423241264},{"_id":"themes/archer/layout/_partial/base-profile.ejs","hash":"f63032391dd75905b6663628a9ca231fa0283350","modified":1701423241264},{"_id":"themes/archer/layout/_partial/base-social.ejs","hash":"0190f06c2f0345cec00eba2074bbfd1b56a7fdc9","modified":1701423241264},{"_id":"themes/archer/layout/_partial/base-title-tags.ejs","hash":"1d5a95782ffc382fdb6b1239b3b97db125984fa0","modified":1701423241264},{"_id":"themes/archer/layout/_partial/custom-font.ejs","hash":"bc6bfda53f8856e1473263a44fd861e96cc00719","modified":1701423241264},{"_id":"themes/archer/layout/_partial/intro-height.ejs","hash":"7b8b078b1c1e5b216e46b32a0cab67330c92c734","modified":1701423241264},{"_id":"themes/archer/source/assets/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1701423241272},{"_id":"themes/archer/source/assets/beian.png","hash":"a99df13e8eb11db86edebf6e5ac246eb59f4b3c4","modified":1701423241272},{"_id":"themes/archer/source/assets/example_qr.png","hash":"cce20432c34875f4d9c6df927ede0fc0f00bb194","modified":1701423241272},{"_id":"themes/archer/source/assets/favicon.ico","hash":"8b200c575d273d41a179c102442e191414e74eae","modified":1701423241272},{"_id":"themes/archer/source/assets/loading.svg","hash":"45be17d07697d604d8981890eb21e308530c7a38","modified":1701423241272},{"_id":"themes/archer/source/css/dark.css","hash":"4db211216f16a5e66d4d499158f4005a1bbb39f5","modified":1701423241272},{"_id":"themes/archer/source/css/dark.css.map","hash":"f49556935deae49df3158c2eb2265464129ef978","modified":1701423241272},{"_id":"themes/archer/source/css/mobile.css","hash":"acb0dfcce26ec93f59c6ec4936006abbe8daefee","modified":1701423241272},{"_id":"themes/archer/source/css/mobile.css.map","hash":"c9f9dade45b119ae2eb7a93be0160baef4d494f8","modified":1701423241272},{"_id":"themes/archer/source/css/style.css","hash":"f08b1ec3a5fe1bf936401a238d55e0487296b42c","modified":1701423241272},{"_id":"themes/archer/source/font/Source Sans Pro.woff","hash":"a6722c9b6439b7a020a9be3d3178970757a9265c","modified":1701423241272},{"_id":"themes/archer/source/font/Source Sans Pro.woff2","hash":"da65f527a8da65d5eb6721626d28cfdb46ab104a","modified":1701423241272},{"_id":"themes/archer/source/lib/webfontloader.min.js","hash":"4c69aeb4e4f355912503d1c460e8e7aa6ea6963e","modified":1701423241280},{"_id":"themes/archer/source/scripts/customFontLoader.js","hash":"7c2f03fbd2b8340b77b1b02778a34e5ac10b560c","modified":1701423241280},{"_id":"themes/archer/source/scripts/customFontLoader.js.map","hash":"702a44b0b1b450263592bfb1199c8d36ea9834a2","modified":1701423241280},{"_id":"themes/archer/source/scripts/dark.js","hash":"28ba818b2ab8a9454a52fe2710b5a8a81a195e4d","modified":1701423241280},{"_id":"themes/archer/source/scripts/dark.js.map","hash":"feb9e1905c4b313b839c1c3b69ad61c05f265a9a","modified":1701423241280},{"_id":"themes/archer/source/scripts/main.js.LICENSE.txt","hash":"959bfc660011bc6a0800fe9e7974080f64c062aa","modified":1701423241288},{"_id":"themes/archer/source/scripts/search.js.LICENSE.txt","hash":"2c9b607ded909550f2ed2d0f2e7271781d9f78d9","modified":1701423241300},{"_id":"themes/archer/source/scripts/share.js","hash":"2210dd8dacea4f1ca11c0047dfafd0a170abd953","modified":1701423241304},{"_id":"themes/archer/src/js/browser.js","hash":"c56e0094a04d6f20564f8f0da1496cb7631d4dc2","modified":1701423241304},{"_id":"themes/archer/src/js/customFontLoader.js","hash":"98bb3a1c0f69bc2675bfa6579df2dde38ba6fded","modified":1701423241304},{"_id":"themes/archer/src/js/dark.js","hash":"2cd243df8593b18a1a293f483d2db18503c53547","modified":1701423241304},{"_id":"themes/archer/src/js/fancybox.js","hash":"6dfc8015d6000c76806424876f5472f39e5485af","modified":1701423241304},{"_id":"themes/archer/src/js/fontawsome.js","hash":"43e852899ee1bc22495253428a2ff3bdedf89882","modified":1701423241304},{"_id":"themes/archer/src/js/init.js","hash":"dee0a1c959bd4dc3953428b1b2137f42bc659b32","modified":1701423241304},{"_id":"themes/archer/src/js/initSidebar.js","hash":"c9c030a451ed394934c1858c7d55ec5a7b588305","modified":1701423241304},{"_id":"themes/archer/src/js/main.js","hash":"658565fbf20adc5b9b237a53c973d0685ce60202","modified":1701423241304},{"_id":"themes/archer/src/js/mobile.js","hash":"4ae6837e18b729f85b5097867fc742ba2d1edf25","modified":1701423241304},{"_id":"themes/archer/src/js/scroll.js","hash":"3017b329329888b287ad233831138428475749be","modified":1701423241304},{"_id":"themes/archer/src/js/search.js","hash":"0bf92b51fef092989f4fe16fb7ef7724d11e9f58","modified":1701423241304},{"_id":"themes/archer/src/js/share.js","hash":"c2e6a3d8d6883cde0c67484daca5e742ebb8e0d1","modified":1701423241304},{"_id":"themes/archer/src/js/sidebar.js","hash":"2518f2b0b7947530851e6c73245dddc96a618a08","modified":1701423241304},{"_id":"themes/archer/src/js/tag.js","hash":"395db7eb2d09e2df6eefcf3f4c7da5cd809a6221","modified":1701423241304},{"_id":"themes/archer/src/js/toc.js","hash":"96a7e07d1976eb29a77799ac2b7abb47907f4b45","modified":1701423241304},{"_id":"themes/archer/src/js/util.js","hash":"e49b30f6ba82d5183d005fc0192d2d673969586b","modified":1701423241304},{"_id":"themes/archer/src/scss/_common.scss","hash":"e80acb4f0049d24260f0a32a301f985ae7e166b8","modified":1701423241304},{"_id":"themes/archer/src/scss/_mixin.scss","hash":"78da2632e7150baa0fd1f6d04fc59ca5e304903d","modified":1701423241304},{"_id":"themes/archer/src/scss/_normalize.scss","hash":"a2dbeb38ad08bb8975856d75954cc697bf8e5ff7","modified":1701423241304},{"_id":"themes/archer/src/scss/_variables.scss","hash":"01e5cab2b5fc686c52145d65229f17db13a3cc54","modified":1701423241304},{"_id":"themes/archer/src/scss/dark.scss","hash":"739af46f0ef8c0c89c3e78ec577e844678f737b5","modified":1701423241304},{"_id":"themes/archer/src/scss/mobile.scss","hash":"2b542af943a8502aae26362dd2af1fbcf68eac1c","modified":1701423241304},{"_id":"themes/archer/src/scss/style.scss","hash":"b10b9a44efaa293b7ac220e66c963dca04ad4bc7","modified":1701423241304},{"_id":"themes/archer/layout/_partial/comment/changyan.ejs","hash":"cc02b3cf9586135d2d7f822c7ad97d81fdf6d4e5","modified":1701423241264},{"_id":"themes/archer/layout/_partial/comment/disqus.ejs","hash":"0f0612ce9ca5c3dc349153a87fdc9dba5f93c52c","modified":1701423241264},{"_id":"themes/archer/layout/_partial/comment/gitalk.ejs","hash":"840279fd3e21dc1cdb1932fe4d9a3be5f670e764","modified":1701423241264},{"_id":"themes/archer/layout/_partial/comment/gitment.ejs","hash":"eda79ada5171ed44e4f3ae4d8a345ad2c7adb2df","modified":1701423241264},{"_id":"themes/archer/layout/_partial/comment/livere.ejs","hash":"d65d9372fca4b316b94ae511f8ccfb0b92d7b065","modified":1701423241264},{"_id":"themes/archer/layout/_partial/comment/utteranc.ejs","hash":"f4ec58c74e6870b8c22032ad3a3c1ee33e5ec41d","modified":1701423241264},{"_id":"themes/archer/layout/_partial/comment/valine.ejs","hash":"24cd7b9e28ceb4b2083ddccce26517de64b35119","modified":1701423241264},{"_id":"themes/archer/layout/_partial/comment/waline.ejs","hash":"c2208d6f05490bbf1b35cdf1519a39933212c33e","modified":1701423241264},{"_id":"themes/archer/layout/_partial/comment/youyan.ejs","hash":"2f4ef49a74a8d63310af60ecda6d765b8c386ff4","modified":1701423241264},{"_id":"themes/archer/layout/_partial/critical-css/critical-style.ejs","hash":"e67a7a2f6bcbfd97e95577446872e217e0c48e80","modified":1701423241264},{"_id":"themes/archer/layout/_partial/math/mathjax.ejs","hash":"84c40a07765e95213045e9b9f7a8c9aaa9c69161","modified":1701423241264},{"_id":"themes/archer/layout/_partial/script/font-loader.ejs","hash":"0473335774025d185dcbaf641496b25a8f33f7af","modified":1701423241264},{"_id":"themes/archer/layout/_partial/sidebar/base-sidebar.ejs","hash":"bdf08beebbe454da9d4c55b35efd317d5f222be5","modified":1701423241264},{"_id":"themes/archer/layout/_partial/sidebar/sidebar-archives.ejs","hash":"6360da867c23b8daa5e34e62c5c5552e2974e360","modified":1701423241264},{"_id":"themes/archer/layout/_partial/sidebar/sidebar-categories.ejs","hash":"02f407d9f9968d228a6a47f2a283b8cf41836a1a","modified":1701423241264},{"_id":"themes/archer/layout/_partial/sidebar/sidebar-tags.ejs","hash":"469455994771da166ddecb4839efa9ef28f2775d","modified":1701423241264},{"_id":"themes/archer/src/scss/_dark/_common-dark.scss","hash":"fc03470312c57a39bc131a1e86cdd3ea2ddb164a","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_404.scss","hash":"9e5cb20871e5bf1af4cf50694a73bd7c9fe64685","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_algolia.scss","hash":"fd7716d8559a9f58f7caef576c553ca7ba1a85e1","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_index-page.scss","hash":"91dc2a0c1ca8d25b1f27d91fa1c81ceb5ff8c3bc","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_post-page.scss","hash":"7583c8c2004e333c5b94e4b868ac778357e0d21e","modified":1701423241304},{"_id":"themes/archer/src/scss/_dark/_partial/_algolia-dark.scss","hash":"e9ea52ca5410c6a6eb53d2a6de1419d3db97d8ca","modified":1701423241304},{"_id":"themes/archer/src/scss/_dark/_partial/_index-page-dark.scss","hash":"4c1406e82b2d4503e027443f64f0984fe0942e1d","modified":1701423241304},{"_id":"themes/archer/src/scss/_dark/_partial/_post-page-dark.scss","hash":"d61059785c72c626990f5b473dc3570cb52c0d73","modified":1701423241304},{"_id":"themes/archer/src/scss/_mobile/_partial/_index-page-mobile.scss","hash":"2d166bb6f234b8773a9ea12457b10e94902a32f1","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_comment/_gitalk.scss","hash":"341bb251987f30221936e36b44374b2b5ce0d218","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_partial/_footer-fixed.scss","hash":"1eb918f6c16054ef2b53b9eea60c751ad89bbd55","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_partial/_footer.scss","hash":"4aafefa6834c8a8583c1cdace620a31306676a57","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_partial/_header.scss","hash":"ce683553806293fea0466f363b18de0ee341dd4e","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_partial/_intro.scss","hash":"4567b9081f063e5fb388b0671f3bc322bdc9acfa","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_partial/_paginator.scss","hash":"67c2e697a5fbb3b8006cf358ea45eb7f75b496f8","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_partial/_profile.scss","hash":"4771add895f8a47917ae2d0d34b92cb327329bf1","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_partial/_scrollbar.scss","hash":"424c08f4acc3f643567f138ffea7d8337791d2c4","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_post/_code.scss","hash":"504f9fdb723c7b287d958211189d25919ac592f6","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_post/_writing-enhance.scss","hash":"4cb495c64d144b2bcf225f2b87641017bd652e66","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_sidebar/_sidebar-archive.scss","hash":"a7374f46ca31bf8ebf5bafea909100921d0c52a4","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_sidebar/_sidebar-tags.scss","hash":"93cc82cb56663e83e90fbd6fe31ffdd38e694f3b","modified":1701423241304},{"_id":"themes/archer/src/scss/_partial/_sidebar/_sidebar.scss","hash":"b2870a9cdaea9b9c8426d406d6859a8f3f1a995f","modified":1701423241304},{"_id":"themes/archer/src/scss/_dark/_partial/_comment/_gitalk-dark.scss","hash":"57accaee4bb5b502d5d3e94c7981ac6996804cf0","modified":1701423241304},{"_id":"themes/archer/src/scss/_dark/_partial/_partial/_footer-dark.scss","hash":"d074a8fef75ba626dd3448cc42290a8c722fd182","modified":1701423241304},{"_id":"themes/archer/src/scss/_dark/_partial/_partial/_footer-fixed-dark.scss","hash":"f4e3eb7aa19c1061b5d9df4f6a7745902e5843f2","modified":1701423241304},{"_id":"themes/archer/src/scss/_dark/_partial/_partial/_header-dark.scss","hash":"ed815d959a37cccdf9137ace91c68bea8ca922c2","modified":1701423241304},{"_id":"themes/archer/src/scss/_dark/_partial/_partial/_profile-dark.scss","hash":"c0fe68f6e9c196157adc71fea0d97f6f70f0a31b","modified":1701423241304},{"_id":"themes/archer/src/scss/_dark/_partial/_post/_code-dark.scss","hash":"9ded8203699f816558fd1493a3ce7cf3d38818e9","modified":1701423241304},{"_id":"themes/archer/src/scss/_dark/_partial/_sidebar/_sidebar-archive-dark.scss","hash":"79b7548214339807ff713f0c7454a227d24d6d0d","modified":1701423241304},{"_id":"themes/archer/src/scss/_dark/_partial/_sidebar/_sidebar-dark.scss","hash":"8e77738f83a425eebb00513ee98e487fe71fdc22","modified":1701423241304},{"_id":"themes/archer/src/scss/_dark/_partial/_sidebar/_sidebar-tags-dark.scss","hash":"6621db2ff1182e3cd14286af4b8f3d8c5bd14e2a","modified":1701423241304},{"_id":"themes/archer/src/scss/_mobile/_partial/_post/_writing-enhance-mobile.scss","hash":"9e714c1cdc61a4ebd5510667e87e879d0b14de67","modified":1701423241304},{"_id":"themes/archer/src/scss/_mobile/_partial/_sidebar/_sidebar-tags-mobile.scss","hash":"b5c62234defe693b4cfa65bda188d71c937eeaf9","modified":1701423241304},{"_id":"themes/archer/source/avatar/Misaka.jpg","hash":"15d2a495703b4eb7f6673cb4a06b7f5731bee406","modified":1701423288848},{"_id":"themes/archer/source/css/style.css.map","hash":"dbe8f8c1fccf8bd9d28ecf3874036a2281319aa0","modified":1701423241272},{"_id":"themes/archer/source/font/Oswald-Regular.ttf","hash":"965d729546a43a8490ad4cf33c25ac475682100c","modified":1701423241272},{"_id":"themes/archer/source/font/SourceCodePro-Regular.ttf.woff","hash":"12eef75e1ad3eca9dae42b65505010ce4464a315","modified":1701423241276},{"_id":"themes/archer/source/font/SourceCodePro-Regular.ttf.woff2","hash":"f5991289ec17884cb641da0646d278d36702a190","modified":1701423241276},{"_id":"themes/archer/source/intro/404-bg.jpg","hash":"3afb5bb26f4ff0bd0e0a28df955c8aa7d746d3c5","modified":1701423241276},{"_id":"themes/archer/source/lib/jquery.min.js","hash":"ad886e472b3557f3dc7dfa2bc43468ab8d1cef5b","modified":1701423241280},{"_id":"themes/archer/source/intro/about-bg.jpg","hash":"ab388276822417cc4e703312c14e20280ec783b3","modified":1701423241276},{"_id":"themes/archer/source/intro/post-bg.jpg","hash":"525fafb2238c27754d8fa751f143ff1de9b8482d","modified":1701423241280},{"_id":"themes/archer/source/scripts/search.js","hash":"ac8e9d130ea410832a421d661898abee63bd8e67","modified":1701423241296},{"_id":"themes/archer/source/scripts/share.js.map","hash":"1e018aa465800a066480e33c848f380880af6743","modified":1701423241304},{"_id":"themes/archer/docs/snap.png","hash":"0b2a8bf016f6eed576abfdcdb7dcf8de51c12562","modified":1701423241264},{"_id":"themes/archer/source/intro/index-bg.jpg","hash":"96b52e177b8bc53e64ec6ee1e10b2b6a4e13083b","modified":1701423241280},{"_id":"themes/archer/package-lock.json","hash":"400ab1cc2a2f1380a5e9ab69abe3a5b93f923d8d","modified":1701423241272},{"_id":"themes/archer/source/scripts/search.js.map","hash":"bd469588b3bee82b3cf72b72d447c854f4d76875","modified":1701423241304},{"_id":"themes/archer/source/scripts/main.js","hash":"11fd75dddcbef7157fbfb8717b3463a80fda1fb3","modified":1701423241288},{"_id":"themes/archer/source/scripts/main.js.map","hash":"79d928070b7e5333ca241c5563ab4fe9cab31b74","modified":1701423241296},{"_id":"public/content.json","hash":"04597ec3b77d6f90887ced0053094d49fd1793da","modified":1706785889352},{"_id":"public/about/index.html","hash":"298dd04a7e75571ccd146d81583fa21d2c6b327d","modified":1706785889352},{"_id":"public/2024/01/17/cache-friendly-programming/index.html","hash":"7a9b5d77c7703054d5a09ab733fd7f7d8d333c2c","modified":1706599807639},{"_id":"public/2023/12/28/Thread-safe-circular-queue/index.html","hash":"37ba5ca1f7b5d6545ce185a85167954e4b1f19d3","modified":1706785889352},{"_id":"public/2023/12/16/Chain-of-responsibility/index.html","hash":"6c9d07bc2a3f2e898268a46b091c4a3ebe9cc7b9","modified":1706785889352},{"_id":"public/2023/12/11/lock-free-programming/index.html","hash":"b09b90d2b71357a94fd5717edfcb54d144aea563","modified":1706599807639},{"_id":"public/2023/12/08/Template-programming-1/index.html","hash":"bc6d01078bc46d2c60fd99620530985a06e7733a","modified":1706785889352},{"_id":"public/2023/12/03/Cpp-basics-5/index.html","hash":"29a39238b176f7a6f2f27363fa9f68e7168a1c43","modified":1705627368853},{"_id":"public/2023/12/03/Cpp-basics-4/index.html","hash":"8fe4553db4ff623725f30887d55d8b6568499484","modified":1705627368853},{"_id":"public/2023/12/03/Cpp-basics-3/index.html","hash":"823876c40a00e4560deea996a1da4a62ba950ded","modified":1705627368853},{"_id":"public/2023/12/03/Cpp-basics-2/index.html","hash":"56388cda5a4f597737b1e76ef6e059204cd18fb1","modified":1705627368853},{"_id":"public/2023/12/03/Cpp-basics-1/index.html","hash":"5abad7369acc176dcd2a669d647c08b7f43a4360","modified":1705627368853},{"_id":"public/2023/12/02/some-plans/index.html","hash":"275d4d6f1ad3cc8fea091c81146cc883baea16a1","modified":1706517605102},{"_id":"public/archives/index.html","hash":"613ca1b4a05bbe380b3a63faa009f1e4471e083c","modified":1706785889352},{"_id":"public/archives/page/2/index.html","hash":"d45b4d0d9653fed23040bf507b1079ebde090338","modified":1705627368853},{"_id":"public/archives/2023/index.html","hash":"313b60f74ee62f28eedad3df0d19bcbdca197a0c","modified":1706785889352},{"_id":"public/archives/2023/12/index.html","hash":"9c04b9c5aef3e8fb08d93345785c1aae65b2e24e","modified":1706785889352},{"_id":"public/archives/2024/index.html","hash":"94964e4170028a1cfad46ca5685c7f5e8ac2ff39","modified":1706785889352},{"_id":"public/archives/2024/01/index.html","hash":"1001914272dc11c5657945d34604f6a920fba10c","modified":1706785889352},{"_id":"public/index.html","hash":"6a83785e0e7bfde2e9f3bc83c0e798c2923e313d","modified":1706785889352},{"_id":"public/page/2/index.html","hash":"817793fe7996996eb06cf8587057c3cb4205814c","modified":1705627368853},{"_id":"public/tags/design-pattern/index.html","hash":"1c94b19c1f98c3caec904842d10e3bd73b58e1b2","modified":1706785889352},{"_id":"public/tags/Cpp/index.html","hash":"fde5cfef892ffa42b3b68d7c7f2c2fc1d7ee5f64","modified":1706785889352},{"_id":"public/tags/Gpt/index.html","hash":"aa470532c33533e4693c00cff10555448940a297","modified":1706785889352},{"_id":"public/tags/Plan/index.html","hash":"23a4cb67615887280bb4186921a364f623c0e9f0","modified":1706785889352},{"_id":"public/images/Cpp-Basics-3-1.png","hash":"d37ee7ca1525dccd14fb09b71a8d84dc9f528bff","modified":1705507596386},{"_id":"public/images/cache-friendly-2.png","hash":"2bc8adca12bdfb357ca23c3bac491f3d3a171512","modified":1705507596386},{"_id":"public/assets/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1705507596386},{"_id":"public/assets/beian.png","hash":"a99df13e8eb11db86edebf6e5ac246eb59f4b3c4","modified":1705507596386},{"_id":"public/assets/example_qr.png","hash":"cce20432c34875f4d9c6df927ede0fc0f00bb194","modified":1705507596386},{"_id":"public/assets/favicon.ico","hash":"8b200c575d273d41a179c102442e191414e74eae","modified":1705507596386},{"_id":"public/assets/loading.svg","hash":"45be17d07697d604d8981890eb21e308530c7a38","modified":1705507596386},{"_id":"public/css/dark.css.map","hash":"f49556935deae49df3158c2eb2265464129ef978","modified":1705507596386},{"_id":"public/css/mobile.css.map","hash":"c9f9dade45b119ae2eb7a93be0160baef4d494f8","modified":1705507596386},{"_id":"public/font/Source Sans Pro.woff","hash":"a6722c9b6439b7a020a9be3d3178970757a9265c","modified":1705507596386},{"_id":"public/font/Source Sans Pro.woff2","hash":"da65f527a8da65d5eb6721626d28cfdb46ab104a","modified":1705507596386},{"_id":"public/scripts/customFontLoader.js.map","hash":"702a44b0b1b450263592bfb1199c8d36ea9834a2","modified":1705507596386},{"_id":"public/scripts/dark.js.map","hash":"feb9e1905c4b313b839c1c3b69ad61c05f265a9a","modified":1705507596386},{"_id":"public/scripts/main.js.LICENSE.txt","hash":"959bfc660011bc6a0800fe9e7974080f64c062aa","modified":1705507596386},{"_id":"public/scripts/search.js.LICENSE.txt","hash":"2c9b607ded909550f2ed2d0f2e7271781d9f78d9","modified":1705507596386},{"_id":"public/images/cache-friendly-1.png","hash":"bc7f3894c0e354738369495b5635c5ad4fba712d","modified":1705507596386},{"_id":"public/images/lock-free-programming-2.png","hash":"f2999eceb49bb569f4b7a5f3eb8732c8a61931a6","modified":1705507596386},{"_id":"public/avatar/Misaka.jpg","hash":"15d2a495703b4eb7f6673cb4a06b7f5731bee406","modified":1705507596386},{"_id":"public/css/style.css.map","hash":"dbe8f8c1fccf8bd9d28ecf3874036a2281319aa0","modified":1705507596386},{"_id":"public/font/Oswald-Regular.ttf","hash":"965d729546a43a8490ad4cf33c25ac475682100c","modified":1705507596386},{"_id":"public/font/SourceCodePro-Regular.ttf.woff","hash":"12eef75e1ad3eca9dae42b65505010ce4464a315","modified":1705507596386},{"_id":"public/font/SourceCodePro-Regular.ttf.woff2","hash":"f5991289ec17884cb641da0646d278d36702a190","modified":1705507596386},{"_id":"public/intro/404-bg.jpg","hash":"3afb5bb26f4ff0bd0e0a28df955c8aa7d746d3c5","modified":1705507596386},{"_id":"public/css/dark.css","hash":"4db211216f16a5e66d4d499158f4005a1bbb39f5","modified":1705507596386},{"_id":"public/css/mobile.css","hash":"acb0dfcce26ec93f59c6ec4936006abbe8daefee","modified":1705507596386},{"_id":"public/lib/webfontloader.min.js","hash":"4c69aeb4e4f355912503d1c460e8e7aa6ea6963e","modified":1705507596386},{"_id":"public/scripts/customFontLoader.js","hash":"7c2f03fbd2b8340b77b1b02778a34e5ac10b560c","modified":1705507596386},{"_id":"public/scripts/dark.js","hash":"28ba818b2ab8a9454a52fe2710b5a8a81a195e4d","modified":1705507596386},{"_id":"public/css/style.css","hash":"f08b1ec3a5fe1bf936401a238d55e0487296b42c","modified":1705507596386},{"_id":"public/lib/jquery.min.js","hash":"ad886e472b3557f3dc7dfa2bc43468ab8d1cef5b","modified":1705507596386},{"_id":"public/scripts/search.js","hash":"ac8e9d130ea410832a421d661898abee63bd8e67","modified":1705507596386},{"_id":"public/scripts/share.js","hash":"2210dd8dacea4f1ca11c0047dfafd0a170abd953","modified":1705507596386},{"_id":"public/intro/about-bg.jpg","hash":"ab388276822417cc4e703312c14e20280ec783b3","modified":1705507596386},{"_id":"public/intro/post-bg.jpg","hash":"525fafb2238c27754d8fa751f143ff1de9b8482d","modified":1705507596386},{"_id":"public/scripts/share.js.map","hash":"1e018aa465800a066480e33c848f380880af6743","modified":1705507596386},{"_id":"public/scripts/main.js","hash":"11fd75dddcbef7157fbfb8717b3463a80fda1fb3","modified":1705507596386},{"_id":"public/images/lock-free-programming-1.png","hash":"bba06b112ba07b2d6ceb0cbc2b1a29ad3272ebfa","modified":1705507596386},{"_id":"public/intro/index-bg.jpg","hash":"96b52e177b8bc53e64ec6ee1e10b2b6a4e13083b","modified":1705507596386},{"_id":"public/images/pattern-1.png","hash":"74a4573dadbe3a7927a146610cb34230ab439c52","modified":1705507596386},{"_id":"public/scripts/search.js.map","hash":"bd469588b3bee82b3cf72b72d447c854f4d76875","modified":1705507596386},{"_id":"public/scripts/main.js.map","hash":"79d928070b7e5333ca241c5563ab4fe9cab31b74","modified":1705507596386},{"_id":"source/_posts/.invisible/Cpp-basics-1.md","hash":"50555c469708548399fe8c4b1ae6a2f9f4cf48cc","modified":1702307543053},{"_id":"source/_posts/.invisible/Cpp-basics-2.md","hash":"bcf386e8add4df4629dfcc29725fb44483ea4b91","modified":1702307552817},{"_id":"source/_posts/.invisible/Cpp-basics-3.md","hash":"9bcc295c9921ff50ef4a2f7ba3b79a653abb4400","modified":1702307562049},{"_id":"source/_posts/.invisible/Cpp-basics-4.md","hash":"0a882acecbc8ac648cde2b5679c28e3c829be067","modified":1702307571509},{"_id":"source/_posts/.invisible/Cpp-basics-5.md","hash":"23eae02768c2a1c419124ad6af54862ed11598bf","modified":1702307580477},{"_id":"source/_posts/Todo-plans.md","hash":"1f68f07a7d5d13d1f1afc1eadf1ae08a2dfc4b6f","modified":1706629168458},{"_id":"public/2023/12/02/Todo-plans/index.html","hash":"c786c000f3729f23b99ddb525a1471290451c9d7","modified":1706785889352},{"_id":"source/_posts/Cache-friendly-programming.md","hash":"9310255a4c3479137567e3664f96020e6231922a","modified":1705545911477},{"_id":"source/_posts/Lock-free-programming.md","hash":"263578ab2569346f0659518a7fe5bb0f59a1a9de","modified":1702567127854},{"_id":"public/2024/01/17/Cache-friendly-programming/index.html","hash":"5aaf7747702f673e48f1ea2685fa51a02c140087","modified":1706785889352},{"_id":"public/2023/12/11/Lock-free-programming/index.html","hash":"6b473304b3def0478dd9ce1f872e2310a8ade682","modified":1706785889352},{"_id":"source/_posts/Git-note.md","hash":"79fc2dfe8ff3eb000208dcef94c614356dd44b0a","modified":1706785881194},{"_id":"source/images/git-note/5.png","hash":"aa995b49e93ba6614209c3f6810907cf73b398ba","modified":1706785656526},{"_id":"source/images/git-note/4.png","hash":"92a23cfa36203e81b673c5ab7516b524767a0e58","modified":1706785657090},{"_id":"source/images/git-note/6.png","hash":"cf4190b9514a688bb1911d6a1fda643fe7cf4acc","modified":1706785646386},{"_id":"source/images/git-note/7.png","hash":"1133e055bd5c28ff77a6d2eb3319455fbe292748","modified":1706785646626},{"_id":"source/images/git-note/8.png","hash":"ffd56da0fd93052fe3a33a44913f22b72ae0dc0b","modified":1706785646678},{"_id":"source/images/git-note/9.png","hash":"cfa45589cbf8d072db5c2fbc7f27042d0018ad4f","modified":1706785646554},{"_id":"source/images/git-note/2.png","hash":"c3e332416640e8c3dd2c8c2bf9212b56c27fb442","modified":1706785646666},{"_id":"source/images/git-note/3.png","hash":"5888cca8fd2b2652c33f0f9987ba347459c269d6","modified":1706785656526},{"_id":"source/images/git-note/1.png","hash":"dbcb103a253421f3e1d515c7f4275b4efadef824","modified":1706785657158},{"_id":"public/2024/02/01/Git-note/index.html","hash":"37a79456307ddcaba80c988971413037d458ba4b","modified":1706785889352},{"_id":"public/archives/2024/02/index.html","hash":"990ff3f572777858d4039665b68eb9d0b53eb850","modified":1706785889352},{"_id":"public/tags/学习杂记/index.html","hash":"7f9298499d9f65f47f6d1f17370d494a2b554977","modified":1706785889352},{"_id":"public/images/git-note/5.png","hash":"aa995b49e93ba6614209c3f6810907cf73b398ba","modified":1706785889352},{"_id":"public/images/git-note/4.png","hash":"92a23cfa36203e81b673c5ab7516b524767a0e58","modified":1706785889352},{"_id":"public/images/git-note/6.png","hash":"cf4190b9514a688bb1911d6a1fda643fe7cf4acc","modified":1706785889352},{"_id":"public/images/git-note/7.png","hash":"1133e055bd5c28ff77a6d2eb3319455fbe292748","modified":1706785889352},{"_id":"public/images/git-note/8.png","hash":"ffd56da0fd93052fe3a33a44913f22b72ae0dc0b","modified":1706785889352},{"_id":"public/images/git-note/9.png","hash":"cfa45589cbf8d072db5c2fbc7f27042d0018ad4f","modified":1706785889352},{"_id":"public/images/git-note/2.png","hash":"c3e332416640e8c3dd2c8c2bf9212b56c27fb442","modified":1706785889352},{"_id":"public/images/git-note/3.png","hash":"5888cca8fd2b2652c33f0f9987ba347459c269d6","modified":1706785889352},{"_id":"public/images/git-note/1.png","hash":"dbcb103a253421f3e1d515c7f4275b4efadef824","modified":1706785889352}],"Category":[],"Data":[],"Page":[{"title":"About Me","layout":"about","date":"2023-12-01T08:44:29.000Z","_content":"\n## 教育背景\n**西安交通大学** Bachelor\n　　　　\n## 工作经历\n\n### 阿里巴巴网络技术有限公司 \n**服务端开发工程师**  2021年2月 -- 2022年7月\n在工作期间，主要负责供应链业务下商品基础模型开发，以及分布式系统一致性保障的工作。\n\n1. 进行toB的商品基础模型的开发，参与基础商品与货品转换模型的重构。通过改良责任链的设计模式，在重构中降低同tracing调用链的复杂度，优化了10%的程序体积，提升了超过30%的接口响应速度。\n\n2. 解决TB级别的数据在分布式系统中一致性问题，屏蔽了数据在分布式环境下的回流异常造成的不一致对业务的影响，优化系统可用性从99.95%优化到99.97%。\n3. 在降本增效的背景下，清洗对外的同质化服务，清理下线冗余的历史rpc接口超过15%，在保证团队的服务稳定性的情况下降低所负责系统的机器成本超过20%。\n\n### 某量化投资有限公司\n**量化开发工程师**  2022年7月 -- 至今\n从0到1参与高频量化交易系统的开发，负责交易链路中高性能的通信中间件开发和系统整体的微秒级性能优化。\n\n1. 负责量化交易系统内的IPC中间件的开发，优化了原先依赖 Domain Socket 的通信方式，借助 Memory Fence 并且合理利用CPU的 Load/Store Buffer，实现了完全基于共享内存的无锁编程来实现关键交易路径上的通信。\n2. 负责量化交易链路中关键路径的性能优化，通过对交易主链路上的业务进行算法/数据分离以实现模板化改造、对算术运算部分进行CPU缓存友好优化，将业务逻辑内整体穿越时间从80微秒降低至10微秒内。\n\n\n## 专业技能\n\n- 熟悉C++ 20的新特性，了解模板编程\n- 了解无锁编程和缓存友好编程，可以在编程中合理地设计程序以提升缓存的命中率\n- 了解程序性能优化方式，在整个系统的宏观层面优化和微观测时上都有一定的经验\n- 其他语言的开发能力，包括Rust、Java、Python等\n","source":"about/index.md","raw":"---\ntitle: About Me\nlayout: about\ndate: 2023-12-01 16:44:29\n---\n\n## 教育背景\n**西安交通大学** Bachelor\n　　　　\n## 工作经历\n\n### 阿里巴巴网络技术有限公司 \n**服务端开发工程师**  2021年2月 -- 2022年7月\n在工作期间，主要负责供应链业务下商品基础模型开发，以及分布式系统一致性保障的工作。\n\n1. 进行toB的商品基础模型的开发，参与基础商品与货品转换模型的重构。通过改良责任链的设计模式，在重构中降低同tracing调用链的复杂度，优化了10%的程序体积，提升了超过30%的接口响应速度。\n\n2. 解决TB级别的数据在分布式系统中一致性问题，屏蔽了数据在分布式环境下的回流异常造成的不一致对业务的影响，优化系统可用性从99.95%优化到99.97%。\n3. 在降本增效的背景下，清洗对外的同质化服务，清理下线冗余的历史rpc接口超过15%，在保证团队的服务稳定性的情况下降低所负责系统的机器成本超过20%。\n\n### 某量化投资有限公司\n**量化开发工程师**  2022年7月 -- 至今\n从0到1参与高频量化交易系统的开发，负责交易链路中高性能的通信中间件开发和系统整体的微秒级性能优化。\n\n1. 负责量化交易系统内的IPC中间件的开发，优化了原先依赖 Domain Socket 的通信方式，借助 Memory Fence 并且合理利用CPU的 Load/Store Buffer，实现了完全基于共享内存的无锁编程来实现关键交易路径上的通信。\n2. 负责量化交易链路中关键路径的性能优化，通过对交易主链路上的业务进行算法/数据分离以实现模板化改造、对算术运算部分进行CPU缓存友好优化，将业务逻辑内整体穿越时间从80微秒降低至10微秒内。\n\n\n## 专业技能\n\n- 熟悉C++ 20的新特性，了解模板编程\n- 了解无锁编程和缓存友好编程，可以在编程中合理地设计程序以提升缓存的命中率\n- 了解程序性能优化方式，在整个系统的宏观层面优化和微观测时上都有一定的经验\n- 其他语言的开发能力，包括Rust、Java、Python等\n","updated":"2024-01-16T09:05:51.786Z","path":"about/index.html","comments":1,"_id":"clrhz6rwc00000ox547gvgicj","content":"<h2 id=\"教育背景\"><a href=\"#教育背景\" class=\"headerlink\" title=\"教育背景\"></a>教育背景</h2><p><strong>西安交通大学</strong> Bachelor\n　　　　</p>\n<h2 id=\"工作经历\"><a href=\"#工作经历\" class=\"headerlink\" title=\"工作经历\"></a>工作经历</h2><h3 id=\"阿里巴巴网络技术有限公司\"><a href=\"#阿里巴巴网络技术有限公司\" class=\"headerlink\" title=\"阿里巴巴网络技术有限公司\"></a>阿里巴巴网络技术有限公司</h3><p><strong>服务端开发工程师</strong>  2021年2月 – 2022年7月<br>在工作期间，主要负责供应链业务下商品基础模型开发，以及分布式系统一致性保障的工作。</p>\n<ol>\n<li><p>进行toB的商品基础模型的开发，参与基础商品与货品转换模型的重构。通过改良责任链的设计模式，在重构中降低同tracing调用链的复杂度，优化了10%的程序体积，提升了超过30%的接口响应速度。</p>\n</li>\n<li><p>解决TB级别的数据在分布式系统中一致性问题，屏蔽了数据在分布式环境下的回流异常造成的不一致对业务的影响，优化系统可用性从99.95%优化到99.97%。</p>\n</li>\n<li><p>在降本增效的背景下，清洗对外的同质化服务，清理下线冗余的历史rpc接口超过15%，在保证团队的服务稳定性的情况下降低所负责系统的机器成本超过20%。</p>\n</li>\n</ol>\n<h3 id=\"某量化投资有限公司\"><a href=\"#某量化投资有限公司\" class=\"headerlink\" title=\"某量化投资有限公司\"></a>某量化投资有限公司</h3><p><strong>量化开发工程师</strong>  2022年7月 – 至今<br>从0到1参与高频量化交易系统的开发，负责交易链路中高性能的通信中间件开发和系统整体的微秒级性能优化。</p>\n<ol>\n<li>负责量化交易系统内的IPC中间件的开发，优化了原先依赖 Domain Socket 的通信方式，借助 Memory Fence 并且合理利用CPU的 Load&#x2F;Store Buffer，实现了完全基于共享内存的无锁编程来实现关键交易路径上的通信。</li>\n<li>负责量化交易链路中关键路径的性能优化，通过对交易主链路上的业务进行算法&#x2F;数据分离以实现模板化改造、对算术运算部分进行CPU缓存友好优化，将业务逻辑内整体穿越时间从80微秒降低至10微秒内。</li>\n</ol>\n<h2 id=\"专业技能\"><a href=\"#专业技能\" class=\"headerlink\" title=\"专业技能\"></a>专业技能</h2><ul>\n<li>熟悉C++ 20的新特性，了解模板编程</li>\n<li>了解无锁编程和缓存友好编程，可以在编程中合理地设计程序以提升缓存的命中率</li>\n<li>了解程序性能优化方式，在整个系统的宏观层面优化和微观测时上都有一定的经验</li>\n<li>其他语言的开发能力，包括Rust、Java、Python等</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"教育背景\"><a href=\"#教育背景\" class=\"headerlink\" title=\"教育背景\"></a>教育背景</h2><p><strong>西安交通大学</strong> Bachelor\n　　　　</p>\n<h2 id=\"工作经历\"><a href=\"#工作经历\" class=\"headerlink\" title=\"工作经历\"></a>工作经历</h2><h3 id=\"阿里巴巴网络技术有限公司\"><a href=\"#阿里巴巴网络技术有限公司\" class=\"headerlink\" title=\"阿里巴巴网络技术有限公司\"></a>阿里巴巴网络技术有限公司</h3><p><strong>服务端开发工程师</strong>  2021年2月 – 2022年7月<br>在工作期间，主要负责供应链业务下商品基础模型开发，以及分布式系统一致性保障的工作。</p>\n<ol>\n<li><p>进行toB的商品基础模型的开发，参与基础商品与货品转换模型的重构。通过改良责任链的设计模式，在重构中降低同tracing调用链的复杂度，优化了10%的程序体积，提升了超过30%的接口响应速度。</p>\n</li>\n<li><p>解决TB级别的数据在分布式系统中一致性问题，屏蔽了数据在分布式环境下的回流异常造成的不一致对业务的影响，优化系统可用性从99.95%优化到99.97%。</p>\n</li>\n<li><p>在降本增效的背景下，清洗对外的同质化服务，清理下线冗余的历史rpc接口超过15%，在保证团队的服务稳定性的情况下降低所负责系统的机器成本超过20%。</p>\n</li>\n</ol>\n<h3 id=\"某量化投资有限公司\"><a href=\"#某量化投资有限公司\" class=\"headerlink\" title=\"某量化投资有限公司\"></a>某量化投资有限公司</h3><p><strong>量化开发工程师</strong>  2022年7月 – 至今<br>从0到1参与高频量化交易系统的开发，负责交易链路中高性能的通信中间件开发和系统整体的微秒级性能优化。</p>\n<ol>\n<li>负责量化交易系统内的IPC中间件的开发，优化了原先依赖 Domain Socket 的通信方式，借助 Memory Fence 并且合理利用CPU的 Load&#x2F;Store Buffer，实现了完全基于共享内存的无锁编程来实现关键交易路径上的通信。</li>\n<li>负责量化交易链路中关键路径的性能优化，通过对交易主链路上的业务进行算法&#x2F;数据分离以实现模板化改造、对算术运算部分进行CPU缓存友好优化，将业务逻辑内整体穿越时间从80微秒降低至10微秒内。</li>\n</ol>\n<h2 id=\"专业技能\"><a href=\"#专业技能\" class=\"headerlink\" title=\"专业技能\"></a>专业技能</h2><ul>\n<li>熟悉C++ 20的新特性，了解模板编程</li>\n<li>了解无锁编程和缓存友好编程，可以在编程中合理地设计程序以提升缓存的命中率</li>\n<li>了解程序性能优化方式，在整个系统的宏观层面优化和微观测时上都有一定的经验</li>\n<li>其他语言的开发能力，包括Rust、Java、Python等</li>\n</ul>\n"}],"Post":[{"title":"设计模式（一）-- 责任链","date":"2023-12-16T12:55:02.000Z","_content":"> 亦称：职责链模式、命令链、CoR、Chain of Command、Chain of Responsibility\n\n写文章之前先自我提出问题：\n\n1. 什么场景下适合用责任链模式？\n2. 责任链模式和观察者模式的区别\n3. 责任链模式适合与什么其他设计模式组合在一起？\n\n责任链模式是一种将请求沿着处理者链依次进行发送的设计模式。系统收到请求后，在链上的每个处理者均可对请求进行处理，或将其传递给链上的下个处理者。每个处理者都作为链上一个可活动的节点，使得责任链模式相较于if-else的分支语句，具有了更好的灵活性和扩展性。\n# 背景\n在商品上架的审批流系统的开发过程中，有着供应商、商品品控人员、上架风控人员等多种角色参与这一流程，并在其中进行着有先后依赖顺序的不同任务。这一流程会与其他系统（角色权限系统、商品库存系统等）具有深度耦合。\n在设计之初有着足够简单的业务流程：\n\n1. 供应商发起上架流程审批，成功则进入2，不成功重新发起1\n2. 商品品控人员进行商品品控达标度进行检查，成功进入3，不成功返回1\n3. 上架风控人员对上架的营销规则进行检查，成功上架，不成功返回1\n\n在这个业务流程中，因为足够简单，所以可以用简单的if语句完成所有的分支判断。单如果随着业务复杂度的增加，引入新角色，供应商资质管理员，新的流程的分支会变多：\n\n1. 供应商发起上架流程审批，成功则进入2，不成功重新发起1\n2. 商品品控人员进行商品质量达标度进行检查，成功进入4，部分成功进入3，完全不成功返回1\n3. 供应商资质管理员对供应商的资质进行检查，成功进入4，不成功返回1\n4. 上架风控人员对上架的营销规则进行检查，成功上架，不成功返回1\n\n在这个流程中，虽然只增加了一个角色和部分简单逻辑，但对原本if语句的冲击是很大的，为了兼容新的角色需要在多处进行改动，于是在迭代的过程中，势必会出现这样一种局面：\n\n1. 在审批流中的代码本来就已经混乱不堪，之后每次新增功能都会使其更加臃肿。\n2. 对审批流中的某个检查步骤进行修改时会影响其他的检查步骤。\n3. 当希望复用这些审核逻辑来保护其他系统组件时，只需要复制部分逻辑就足够，但会面对所需的部分逻辑与整体审批流耦合得太深而很难剥离出来的问题。\n# 解决方案\n与许多其他行为设计模式一样，责任链会将特定行为转换为被称作处理者的独立对象。\n\n- 在上述示例中，每个检查步骤都可被抽取为仅有单个方法的类，提供检查操作。\n- 请求及其数据则会被作为参数传递给该方法。\n\n责任链模式将这些处理者连成一条链，链上的每个处理者都有一个成员变量来保存对于下一处理者的引用。\n\n- 除了处理请求外，处理者还负责沿着链传递请求。\n- 请求会在链上移动，直至所有处理者都有机会对请求进行处理。\n\n最重要的是：处理者可以决定要不要沿着链继续传递请求，这样可以高效地取消所有后续处理步骤。\n还有一种稍微不同的更经典的方式，处理者接收到请求后自行决定是否能够对其进行处理。\n\n- 如果自己能够处理，处理者就不再继续传递请求。\n- 在这种情况下，每个请求要么最多有一个处理者对其进行处理，要么没有任何处理者对其进行处理\n\n连成链的方式比较多样，可以用UML中展示的那样，一个处理对象使用SetNext()引用下一个处理对象。 也可以使用array或者list存储所有处理对象，使用循环方式遍历。\n\n- 对于第二种方式，感觉有些像观察者模式。\n- 两者具体实现、目的都差不多。主要区别在于：\n   - 观察者模式中的处理对象功能可能完全无关，观察者模式主要负责将信息传递给处理对象即可\n   - 责任链模式的处理对象功能一般相似，另外责任链模式也关注请求是否正确被处理\n\n![image.png](/images/pattern-1.png)\n责任链模式的核心在于将处理对象整理成链路。\n# 适用场景\n\n- 程序需要使用不同方式处理请求\n   - 将多个处理者连接成一条链。接收到请求后，“询问” 每个处理者是否能对其进行处理。这样所有处理者都有机会来处理请求。\n- 当必须按顺序执行多个处理者时，可以使用该模式。\n   - 无论你以何种顺序将处理者连接成一条链，所有请求都会严格按照顺序通过链上的处理者。\n- 如果所需处理者及其顺序必须在运行时进行改变，可以使用责任链模式。\n   - 如果在处理者类中有对引用成员变量的设定方法，能动态地插入和移除处理者，或者改变其顺序。\n# 实现步骤\n\n1. 声明处理者接口并提供请求处理方法的签名。\n   - 确定客户端如何将请求数据传递给方法。 最灵活的方式是将请求转换为对象， 然后将其以参数的形式传递给处理函数。\n2. 为了消除具体处理者中的重复代码，可以根据处理者接口创建抽象处理者基类。\n   - 该类需要有一个成员变量来存储指向链上下一个处理者的引用。如果需要在运行时对链进行改变，需要定义一个设定方法来修改引用成员变量的值。\n   - 还可以提供处理方法的默认行为。如果还有剩余对象，默认行为直接将请求传递给下个对象。具体处理者可以通过调用父对象的方法来使用这一行为。\n3. 依次创建具体处理者子类并实现其处理方法。 每个处理者在接收到请求后都必须做出两个决定：\n   - 是否自行处理这个请求\n   - 是否将该请求沿着链进行传递\n4. 客户端可以自行组装链，或者从其他对象处获得预先组装好的链。\n   - 在后一种情况下，需要实现工厂类来根据配置或环境设置来创建链\n5. 客户端可以触发链中的任一处理者，不仅仅是第一个。请求将通过链进行传递，直至某个处理者拒绝继续传递，或者请求到达链尾。\n6. 由于链的动态性，客户端需要处理以下情况：\n   - 部分请求可能无法到达链尾\n   - 其他请求可能直到链尾都未被处理\n# 优缺点\n优点：\n\n- 可以控制请求处理的顺序。\n- 单一职责原则。解耦了发起操作和执行操作的类。\n- 开闭原则。 可以在不更改现有代码的情况下在程序中新增处理者。\n\n缺点：\n\n- 部分请求最终可能都未被处理。\n# 与其它模式的关系\n\n- 责任链模式、命令模式、中介者模式和观察者模式用于处理请求发送者和接收者之间的不同连接方式：\n   - 责任链模式按照顺序将请求动态传递给一系列的潜在接收者。\n   - 命令模式在发送者和请求者之间建立单向连接。\n   - 中介者模式清除了发送者和请求者之间的直接连接，强制它们通过一个中介对象进行间接沟通。\n   - 观察者模式允许接收者动态地订阅或取消接收请求。\n- 责任链可以和组合模式结合使用\n   - 叶组件接收到请求后，将请求沿包含全体父组件的链一直传递至对象树的底部。\n- 责任链上的处理器可使用命令模式实现\n   - 可以对由请求代表的同一个上下文对象执行许多不同的操作。\n   - 或者，请求自身就是一个命令对象。可以对一系列不同对象组成的链执行相同的操作。\n- 责任链和装饰模式的类结构非常相似。 两者都依赖递归组合将需要执行的操作传递给对象。两者也有几点不同\n   - 责任链上的处理器可以相互独立地执行，还可以随时停止传递请求\n   - 各种装饰可以在遵循基本接口的情况下扩展对象的行为\n   - 装饰无法中断请求的传递\n# 示例\n```cpp\n#include <iostream>\n#include <string>\n\n// 定义处理者接口\nclass Approver {\npublic:\nvirtual void processRequest(const std::string& request) = 0;\nvirtual ~Approver() {}\n};\n\n// 创建抽象处理者基类\nclass BaseApprover : public Approver {\nprivate:\nApprover* nextApprover;\n\npublic:\nBaseApprover() : nextApprover(nullptr) {}\n\n// 设置下一个处理者\nvoid setNextApprover(Approver* next) {\n    nextApprover = next;\n}\n\n// 处理请求的默认行为\nvoid processRequest(const std::string& request) override {\n    if (nextApprover != nullptr) {\n        nextApprover->processRequest(request);\n    } else {\n        std::cout << \"Request not handled by any approver.\" << std::endl;\n    }\n}\n};\n\n// 具体处理者子类：商品品控人员\nclass QualityControlApprover : public BaseApprover {\npublic:\nvoid processRequest(const std::string& request) override {\n    if (request == \"QualityCheck\") {\n        std::cout << \"QualityControlApprover handles the request.\" << std::endl;\n    } else {\n        BaseApprover::processRequest(request);\n    }\n}\n};\n\n// 具体处理者子类：供应商资质管理员\nclass SupplierQualificationApprover : public BaseApprover {\npublic:\nvoid processRequest(const std::string& request) override {\n    if (request == \"SupplierQualificationCheck\") {\n        std::cout << \"SupplierQualificationApprover handles the request.\" << std::endl;\n    } else {\n        BaseApprover::processRequest(request);\n    }\n}\n};\n\n// 具体处理者子类：上架风控人员\nclass RiskControlApprover : public BaseApprover {\npublic:\nvoid processRequest(const std::string& request) override {\n    if (request == \"MarketingRuleCheck\") {\n        std::cout << \"RiskControlApprover handles the request and approves the product for shelf.\" << std::endl;\n    } else {\n        BaseApprover::processRequest(request);\n    }\n}\n};\n\nint main() {\n    // 创建责任链\n    QualityControlApprover qualityControlApprover;\n    SupplierQualificationApprover supplierQualificationApprover;\n    RiskControlApprover riskControlApprover;\n\n    // 设置责任链顺序\n    qualityControlApprover.setNextApprover(&supplierQualificationApprover);\n    supplierQualificationApprover.setNextApprover(&riskControlApprover);\n\n    // 模拟商品上架流程\n    std::cout << \"Scenario 1:\" << std::endl;\n    qualityControlApprover.processRequest(\"QualityCheck\");\n\n    std::cout << \"\\nScenario 2:\" << std::endl;\n    qualityControlApprover.processRequest(\"SupplierQualificationCheck\");\n\n    std::cout << \"\\nScenario 3:\" << std::endl;\n    qualityControlApprover.processRequest(\"MarketingRuleCheck\");\n\n    std::cout << \"\\nScenario 4:\" << std::endl;\n    qualityControlApprover.processRequest(\"SomeOtherCheck\");\n\n    return 0;\n}\n\n```\n\n\n","source":"_posts/Chain-of-responsibility.md","raw":"---\ntitle: 设计模式（一）-- 责任链\ndate: 2023-12-16 20:55:02\ntags: design pattern\n---\n> 亦称：职责链模式、命令链、CoR、Chain of Command、Chain of Responsibility\n\n写文章之前先自我提出问题：\n\n1. 什么场景下适合用责任链模式？\n2. 责任链模式和观察者模式的区别\n3. 责任链模式适合与什么其他设计模式组合在一起？\n\n责任链模式是一种将请求沿着处理者链依次进行发送的设计模式。系统收到请求后，在链上的每个处理者均可对请求进行处理，或将其传递给链上的下个处理者。每个处理者都作为链上一个可活动的节点，使得责任链模式相较于if-else的分支语句，具有了更好的灵活性和扩展性。\n# 背景\n在商品上架的审批流系统的开发过程中，有着供应商、商品品控人员、上架风控人员等多种角色参与这一流程，并在其中进行着有先后依赖顺序的不同任务。这一流程会与其他系统（角色权限系统、商品库存系统等）具有深度耦合。\n在设计之初有着足够简单的业务流程：\n\n1. 供应商发起上架流程审批，成功则进入2，不成功重新发起1\n2. 商品品控人员进行商品品控达标度进行检查，成功进入3，不成功返回1\n3. 上架风控人员对上架的营销规则进行检查，成功上架，不成功返回1\n\n在这个业务流程中，因为足够简单，所以可以用简单的if语句完成所有的分支判断。单如果随着业务复杂度的增加，引入新角色，供应商资质管理员，新的流程的分支会变多：\n\n1. 供应商发起上架流程审批，成功则进入2，不成功重新发起1\n2. 商品品控人员进行商品质量达标度进行检查，成功进入4，部分成功进入3，完全不成功返回1\n3. 供应商资质管理员对供应商的资质进行检查，成功进入4，不成功返回1\n4. 上架风控人员对上架的营销规则进行检查，成功上架，不成功返回1\n\n在这个流程中，虽然只增加了一个角色和部分简单逻辑，但对原本if语句的冲击是很大的，为了兼容新的角色需要在多处进行改动，于是在迭代的过程中，势必会出现这样一种局面：\n\n1. 在审批流中的代码本来就已经混乱不堪，之后每次新增功能都会使其更加臃肿。\n2. 对审批流中的某个检查步骤进行修改时会影响其他的检查步骤。\n3. 当希望复用这些审核逻辑来保护其他系统组件时，只需要复制部分逻辑就足够，但会面对所需的部分逻辑与整体审批流耦合得太深而很难剥离出来的问题。\n# 解决方案\n与许多其他行为设计模式一样，责任链会将特定行为转换为被称作处理者的独立对象。\n\n- 在上述示例中，每个检查步骤都可被抽取为仅有单个方法的类，提供检查操作。\n- 请求及其数据则会被作为参数传递给该方法。\n\n责任链模式将这些处理者连成一条链，链上的每个处理者都有一个成员变量来保存对于下一处理者的引用。\n\n- 除了处理请求外，处理者还负责沿着链传递请求。\n- 请求会在链上移动，直至所有处理者都有机会对请求进行处理。\n\n最重要的是：处理者可以决定要不要沿着链继续传递请求，这样可以高效地取消所有后续处理步骤。\n还有一种稍微不同的更经典的方式，处理者接收到请求后自行决定是否能够对其进行处理。\n\n- 如果自己能够处理，处理者就不再继续传递请求。\n- 在这种情况下，每个请求要么最多有一个处理者对其进行处理，要么没有任何处理者对其进行处理\n\n连成链的方式比较多样，可以用UML中展示的那样，一个处理对象使用SetNext()引用下一个处理对象。 也可以使用array或者list存储所有处理对象，使用循环方式遍历。\n\n- 对于第二种方式，感觉有些像观察者模式。\n- 两者具体实现、目的都差不多。主要区别在于：\n   - 观察者模式中的处理对象功能可能完全无关，观察者模式主要负责将信息传递给处理对象即可\n   - 责任链模式的处理对象功能一般相似，另外责任链模式也关注请求是否正确被处理\n\n![image.png](/images/pattern-1.png)\n责任链模式的核心在于将处理对象整理成链路。\n# 适用场景\n\n- 程序需要使用不同方式处理请求\n   - 将多个处理者连接成一条链。接收到请求后，“询问” 每个处理者是否能对其进行处理。这样所有处理者都有机会来处理请求。\n- 当必须按顺序执行多个处理者时，可以使用该模式。\n   - 无论你以何种顺序将处理者连接成一条链，所有请求都会严格按照顺序通过链上的处理者。\n- 如果所需处理者及其顺序必须在运行时进行改变，可以使用责任链模式。\n   - 如果在处理者类中有对引用成员变量的设定方法，能动态地插入和移除处理者，或者改变其顺序。\n# 实现步骤\n\n1. 声明处理者接口并提供请求处理方法的签名。\n   - 确定客户端如何将请求数据传递给方法。 最灵活的方式是将请求转换为对象， 然后将其以参数的形式传递给处理函数。\n2. 为了消除具体处理者中的重复代码，可以根据处理者接口创建抽象处理者基类。\n   - 该类需要有一个成员变量来存储指向链上下一个处理者的引用。如果需要在运行时对链进行改变，需要定义一个设定方法来修改引用成员变量的值。\n   - 还可以提供处理方法的默认行为。如果还有剩余对象，默认行为直接将请求传递给下个对象。具体处理者可以通过调用父对象的方法来使用这一行为。\n3. 依次创建具体处理者子类并实现其处理方法。 每个处理者在接收到请求后都必须做出两个决定：\n   - 是否自行处理这个请求\n   - 是否将该请求沿着链进行传递\n4. 客户端可以自行组装链，或者从其他对象处获得预先组装好的链。\n   - 在后一种情况下，需要实现工厂类来根据配置或环境设置来创建链\n5. 客户端可以触发链中的任一处理者，不仅仅是第一个。请求将通过链进行传递，直至某个处理者拒绝继续传递，或者请求到达链尾。\n6. 由于链的动态性，客户端需要处理以下情况：\n   - 部分请求可能无法到达链尾\n   - 其他请求可能直到链尾都未被处理\n# 优缺点\n优点：\n\n- 可以控制请求处理的顺序。\n- 单一职责原则。解耦了发起操作和执行操作的类。\n- 开闭原则。 可以在不更改现有代码的情况下在程序中新增处理者。\n\n缺点：\n\n- 部分请求最终可能都未被处理。\n# 与其它模式的关系\n\n- 责任链模式、命令模式、中介者模式和观察者模式用于处理请求发送者和接收者之间的不同连接方式：\n   - 责任链模式按照顺序将请求动态传递给一系列的潜在接收者。\n   - 命令模式在发送者和请求者之间建立单向连接。\n   - 中介者模式清除了发送者和请求者之间的直接连接，强制它们通过一个中介对象进行间接沟通。\n   - 观察者模式允许接收者动态地订阅或取消接收请求。\n- 责任链可以和组合模式结合使用\n   - 叶组件接收到请求后，将请求沿包含全体父组件的链一直传递至对象树的底部。\n- 责任链上的处理器可使用命令模式实现\n   - 可以对由请求代表的同一个上下文对象执行许多不同的操作。\n   - 或者，请求自身就是一个命令对象。可以对一系列不同对象组成的链执行相同的操作。\n- 责任链和装饰模式的类结构非常相似。 两者都依赖递归组合将需要执行的操作传递给对象。两者也有几点不同\n   - 责任链上的处理器可以相互独立地执行，还可以随时停止传递请求\n   - 各种装饰可以在遵循基本接口的情况下扩展对象的行为\n   - 装饰无法中断请求的传递\n# 示例\n```cpp\n#include <iostream>\n#include <string>\n\n// 定义处理者接口\nclass Approver {\npublic:\nvirtual void processRequest(const std::string& request) = 0;\nvirtual ~Approver() {}\n};\n\n// 创建抽象处理者基类\nclass BaseApprover : public Approver {\nprivate:\nApprover* nextApprover;\n\npublic:\nBaseApprover() : nextApprover(nullptr) {}\n\n// 设置下一个处理者\nvoid setNextApprover(Approver* next) {\n    nextApprover = next;\n}\n\n// 处理请求的默认行为\nvoid processRequest(const std::string& request) override {\n    if (nextApprover != nullptr) {\n        nextApprover->processRequest(request);\n    } else {\n        std::cout << \"Request not handled by any approver.\" << std::endl;\n    }\n}\n};\n\n// 具体处理者子类：商品品控人员\nclass QualityControlApprover : public BaseApprover {\npublic:\nvoid processRequest(const std::string& request) override {\n    if (request == \"QualityCheck\") {\n        std::cout << \"QualityControlApprover handles the request.\" << std::endl;\n    } else {\n        BaseApprover::processRequest(request);\n    }\n}\n};\n\n// 具体处理者子类：供应商资质管理员\nclass SupplierQualificationApprover : public BaseApprover {\npublic:\nvoid processRequest(const std::string& request) override {\n    if (request == \"SupplierQualificationCheck\") {\n        std::cout << \"SupplierQualificationApprover handles the request.\" << std::endl;\n    } else {\n        BaseApprover::processRequest(request);\n    }\n}\n};\n\n// 具体处理者子类：上架风控人员\nclass RiskControlApprover : public BaseApprover {\npublic:\nvoid processRequest(const std::string& request) override {\n    if (request == \"MarketingRuleCheck\") {\n        std::cout << \"RiskControlApprover handles the request and approves the product for shelf.\" << std::endl;\n    } else {\n        BaseApprover::processRequest(request);\n    }\n}\n};\n\nint main() {\n    // 创建责任链\n    QualityControlApprover qualityControlApprover;\n    SupplierQualificationApprover supplierQualificationApprover;\n    RiskControlApprover riskControlApprover;\n\n    // 设置责任链顺序\n    qualityControlApprover.setNextApprover(&supplierQualificationApprover);\n    supplierQualificationApprover.setNextApprover(&riskControlApprover);\n\n    // 模拟商品上架流程\n    std::cout << \"Scenario 1:\" << std::endl;\n    qualityControlApprover.processRequest(\"QualityCheck\");\n\n    std::cout << \"\\nScenario 2:\" << std::endl;\n    qualityControlApprover.processRequest(\"SupplierQualificationCheck\");\n\n    std::cout << \"\\nScenario 3:\" << std::endl;\n    qualityControlApprover.processRequest(\"MarketingRuleCheck\");\n\n    std::cout << \"\\nScenario 4:\" << std::endl;\n    qualityControlApprover.processRequest(\"SomeOtherCheck\");\n\n    return 0;\n}\n\n```\n\n\n","slug":"Chain-of-responsibility","published":1,"updated":"2023-12-16T13:04:21.172Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clrhz6rwf00010ox533q1ciw5","content":"<blockquote>\n<p>亦称：职责链模式、命令链、CoR、Chain of Command、Chain of Responsibility</p>\n</blockquote>\n<p>写文章之前先自我提出问题：</p>\n<ol>\n<li>什么场景下适合用责任链模式？</li>\n<li>责任链模式和观察者模式的区别</li>\n<li>责任链模式适合与什么其他设计模式组合在一起？</li>\n</ol>\n<p>责任链模式是一种将请求沿着处理者链依次进行发送的设计模式。系统收到请求后，在链上的每个处理者均可对请求进行处理，或将其传递给链上的下个处理者。每个处理者都作为链上一个可活动的节点，使得责任链模式相较于if-else的分支语句，具有了更好的灵活性和扩展性。</p>\n<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>在商品上架的审批流系统的开发过程中，有着供应商、商品品控人员、上架风控人员等多种角色参与这一流程，并在其中进行着有先后依赖顺序的不同任务。这一流程会与其他系统（角色权限系统、商品库存系统等）具有深度耦合。<br>在设计之初有着足够简单的业务流程：</p>\n<ol>\n<li>供应商发起上架流程审批，成功则进入2，不成功重新发起1</li>\n<li>商品品控人员进行商品品控达标度进行检查，成功进入3，不成功返回1</li>\n<li>上架风控人员对上架的营销规则进行检查，成功上架，不成功返回1</li>\n</ol>\n<p>在这个业务流程中，因为足够简单，所以可以用简单的if语句完成所有的分支判断。单如果随着业务复杂度的增加，引入新角色，供应商资质管理员，新的流程的分支会变多：</p>\n<ol>\n<li>供应商发起上架流程审批，成功则进入2，不成功重新发起1</li>\n<li>商品品控人员进行商品质量达标度进行检查，成功进入4，部分成功进入3，完全不成功返回1</li>\n<li>供应商资质管理员对供应商的资质进行检查，成功进入4，不成功返回1</li>\n<li>上架风控人员对上架的营销规则进行检查，成功上架，不成功返回1</li>\n</ol>\n<p>在这个流程中，虽然只增加了一个角色和部分简单逻辑，但对原本if语句的冲击是很大的，为了兼容新的角色需要在多处进行改动，于是在迭代的过程中，势必会出现这样一种局面：</p>\n<ol>\n<li>在审批流中的代码本来就已经混乱不堪，之后每次新增功能都会使其更加臃肿。</li>\n<li>对审批流中的某个检查步骤进行修改时会影响其他的检查步骤。</li>\n<li>当希望复用这些审核逻辑来保护其他系统组件时，只需要复制部分逻辑就足够，但会面对所需的部分逻辑与整体审批流耦合得太深而很难剥离出来的问题。</li>\n</ol>\n<h1 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h1><p>与许多其他行为设计模式一样，责任链会将特定行为转换为被称作处理者的独立对象。</p>\n<ul>\n<li>在上述示例中，每个检查步骤都可被抽取为仅有单个方法的类，提供检查操作。</li>\n<li>请求及其数据则会被作为参数传递给该方法。</li>\n</ul>\n<p>责任链模式将这些处理者连成一条链，链上的每个处理者都有一个成员变量来保存对于下一处理者的引用。</p>\n<ul>\n<li>除了处理请求外，处理者还负责沿着链传递请求。</li>\n<li>请求会在链上移动，直至所有处理者都有机会对请求进行处理。</li>\n</ul>\n<p>最重要的是：处理者可以决定要不要沿着链继续传递请求，这样可以高效地取消所有后续处理步骤。<br>还有一种稍微不同的更经典的方式，处理者接收到请求后自行决定是否能够对其进行处理。</p>\n<ul>\n<li>如果自己能够处理，处理者就不再继续传递请求。</li>\n<li>在这种情况下，每个请求要么最多有一个处理者对其进行处理，要么没有任何处理者对其进行处理</li>\n</ul>\n<p>连成链的方式比较多样，可以用UML中展示的那样，一个处理对象使用SetNext()引用下一个处理对象。 也可以使用array或者list存储所有处理对象，使用循环方式遍历。</p>\n<ul>\n<li>对于第二种方式，感觉有些像观察者模式。</li>\n<li>两者具体实现、目的都差不多。主要区别在于：<ul>\n<li>观察者模式中的处理对象功能可能完全无关，观察者模式主要负责将信息传递给处理对象即可</li>\n<li>责任链模式的处理对象功能一般相似，另外责任链模式也关注请求是否正确被处理</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/pattern-1.png\" alt=\"image.png\"><br>责任链模式的核心在于将处理对象整理成链路。</p>\n<h1 id=\"适用场景\"><a href=\"#适用场景\" class=\"headerlink\" title=\"适用场景\"></a>适用场景</h1><ul>\n<li>程序需要使用不同方式处理请求<ul>\n<li>将多个处理者连接成一条链。接收到请求后，“询问” 每个处理者是否能对其进行处理。这样所有处理者都有机会来处理请求。</li>\n</ul>\n</li>\n<li>当必须按顺序执行多个处理者时，可以使用该模式。<ul>\n<li>无论你以何种顺序将处理者连接成一条链，所有请求都会严格按照顺序通过链上的处理者。</li>\n</ul>\n</li>\n<li>如果所需处理者及其顺序必须在运行时进行改变，可以使用责任链模式。<ul>\n<li>如果在处理者类中有对引用成员变量的设定方法，能动态地插入和移除处理者，或者改变其顺序。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"实现步骤\"><a href=\"#实现步骤\" class=\"headerlink\" title=\"实现步骤\"></a>实现步骤</h1><ol>\n<li>声明处理者接口并提供请求处理方法的签名。<ul>\n<li>确定客户端如何将请求数据传递给方法。 最灵活的方式是将请求转换为对象， 然后将其以参数的形式传递给处理函数。</li>\n</ul>\n</li>\n<li>为了消除具体处理者中的重复代码，可以根据处理者接口创建抽象处理者基类。<ul>\n<li>该类需要有一个成员变量来存储指向链上下一个处理者的引用。如果需要在运行时对链进行改变，需要定义一个设定方法来修改引用成员变量的值。</li>\n<li>还可以提供处理方法的默认行为。如果还有剩余对象，默认行为直接将请求传递给下个对象。具体处理者可以通过调用父对象的方法来使用这一行为。</li>\n</ul>\n</li>\n<li>依次创建具体处理者子类并实现其处理方法。 每个处理者在接收到请求后都必须做出两个决定：<ul>\n<li>是否自行处理这个请求</li>\n<li>是否将该请求沿着链进行传递</li>\n</ul>\n</li>\n<li>客户端可以自行组装链，或者从其他对象处获得预先组装好的链。<ul>\n<li>在后一种情况下，需要实现工厂类来根据配置或环境设置来创建链</li>\n</ul>\n</li>\n<li>客户端可以触发链中的任一处理者，不仅仅是第一个。请求将通过链进行传递，直至某个处理者拒绝继续传递，或者请求到达链尾。</li>\n<li>由于链的动态性，客户端需要处理以下情况：<ul>\n<li>部分请求可能无法到达链尾</li>\n<li>其他请求可能直到链尾都未被处理</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"优缺点\"><a href=\"#优缺点\" class=\"headerlink\" title=\"优缺点\"></a>优缺点</h1><p>优点：</p>\n<ul>\n<li>可以控制请求处理的顺序。</li>\n<li>单一职责原则。解耦了发起操作和执行操作的类。</li>\n<li>开闭原则。 可以在不更改现有代码的情况下在程序中新增处理者。</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>部分请求最终可能都未被处理。</li>\n</ul>\n<h1 id=\"与其它模式的关系\"><a href=\"#与其它模式的关系\" class=\"headerlink\" title=\"与其它模式的关系\"></a>与其它模式的关系</h1><ul>\n<li>责任链模式、命令模式、中介者模式和观察者模式用于处理请求发送者和接收者之间的不同连接方式：<ul>\n<li>责任链模式按照顺序将请求动态传递给一系列的潜在接收者。</li>\n<li>命令模式在发送者和请求者之间建立单向连接。</li>\n<li>中介者模式清除了发送者和请求者之间的直接连接，强制它们通过一个中介对象进行间接沟通。</li>\n<li>观察者模式允许接收者动态地订阅或取消接收请求。</li>\n</ul>\n</li>\n<li>责任链可以和组合模式结合使用<ul>\n<li>叶组件接收到请求后，将请求沿包含全体父组件的链一直传递至对象树的底部。</li>\n</ul>\n</li>\n<li>责任链上的处理器可使用命令模式实现<ul>\n<li>可以对由请求代表的同一个上下文对象执行许多不同的操作。</li>\n<li>或者，请求自身就是一个命令对象。可以对一系列不同对象组成的链执行相同的操作。</li>\n</ul>\n</li>\n<li>责任链和装饰模式的类结构非常相似。 两者都依赖递归组合将需要执行的操作传递给对象。两者也有几点不同<ul>\n<li>责任链上的处理器可以相互独立地执行，还可以随时停止传递请求</li>\n<li>各种装饰可以在遵循基本接口的情况下扩展对象的行为</li>\n<li>装饰无法中断请求的传递</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h1><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;string&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 定义处理者接口</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Approver</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"type\">void</span> <span class=\"title\">processRequest</span><span class=\"params\">(<span class=\"type\">const</span> std::string&amp; request)</span> </span>= <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">virtual</span> ~<span class=\"built_in\">Approver</span>() &#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 创建抽象处理者基类</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">BaseApprover</span> : <span class=\"keyword\">public</span> Approver &#123;</span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">Approver* nextApprover;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\"><span class=\"built_in\">BaseApprover</span>() : <span class=\"built_in\">nextApprover</span>(<span class=\"literal\">nullptr</span>) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 设置下一个处理者</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">setNextApprover</span><span class=\"params\">(Approver* next)</span> </span>&#123;</span><br><span class=\"line\">    nextApprover = next;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 处理请求的默认行为</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">processRequest</span><span class=\"params\">(<span class=\"type\">const</span> std::string&amp; request)</span> <span class=\"keyword\">override</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (nextApprover != <span class=\"literal\">nullptr</span>) &#123;</span><br><span class=\"line\">        nextApprover-&gt;<span class=\"built_in\">processRequest</span>(request);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; <span class=\"string\">&quot;Request not handled by any approver.&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体处理者子类：商品品控人员</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">QualityControlApprover</span> : <span class=\"keyword\">public</span> BaseApprover &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">processRequest</span><span class=\"params\">(<span class=\"type\">const</span> std::string&amp; request)</span> <span class=\"keyword\">override</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (request == <span class=\"string\">&quot;QualityCheck&quot;</span>) &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; <span class=\"string\">&quot;QualityControlApprover handles the request.&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        BaseApprover::<span class=\"built_in\">processRequest</span>(request);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体处理者子类：供应商资质管理员</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">SupplierQualificationApprover</span> : <span class=\"keyword\">public</span> BaseApprover &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">processRequest</span><span class=\"params\">(<span class=\"type\">const</span> std::string&amp; request)</span> <span class=\"keyword\">override</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (request == <span class=\"string\">&quot;SupplierQualificationCheck&quot;</span>) &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; <span class=\"string\">&quot;SupplierQualificationApprover handles the request.&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        BaseApprover::<span class=\"built_in\">processRequest</span>(request);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体处理者子类：上架风控人员</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">RiskControlApprover</span> : <span class=\"keyword\">public</span> BaseApprover &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">processRequest</span><span class=\"params\">(<span class=\"type\">const</span> std::string&amp; request)</span> <span class=\"keyword\">override</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (request == <span class=\"string\">&quot;MarketingRuleCheck&quot;</span>) &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; <span class=\"string\">&quot;RiskControlApprover handles the request and approves the product for shelf.&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        BaseApprover::<span class=\"built_in\">processRequest</span>(request);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 创建责任链</span></span><br><span class=\"line\">    QualityControlApprover qualityControlApprover;</span><br><span class=\"line\">    SupplierQualificationApprover supplierQualificationApprover;</span><br><span class=\"line\">    RiskControlApprover riskControlApprover;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 设置责任链顺序</span></span><br><span class=\"line\">    qualityControlApprover.<span class=\"built_in\">setNextApprover</span>(&amp;supplierQualificationApprover);</span><br><span class=\"line\">    supplierQualificationApprover.<span class=\"built_in\">setNextApprover</span>(&amp;riskControlApprover);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 模拟商品上架流程</span></span><br><span class=\"line\">    std::cout &lt;&lt; <span class=\"string\">&quot;Scenario 1:&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    qualityControlApprover.<span class=\"built_in\">processRequest</span>(<span class=\"string\">&quot;QualityCheck&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    std::cout &lt;&lt; <span class=\"string\">&quot;\\nScenario 2:&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    qualityControlApprover.<span class=\"built_in\">processRequest</span>(<span class=\"string\">&quot;SupplierQualificationCheck&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    std::cout &lt;&lt; <span class=\"string\">&quot;\\nScenario 3:&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    qualityControlApprover.<span class=\"built_in\">processRequest</span>(<span class=\"string\">&quot;MarketingRuleCheck&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    std::cout &lt;&lt; <span class=\"string\">&quot;\\nScenario 4:&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    qualityControlApprover.<span class=\"built_in\">processRequest</span>(<span class=\"string\">&quot;SomeOtherCheck&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>亦称：职责链模式、命令链、CoR、Chain of Command、Chain of Responsibility</p>\n</blockquote>\n<p>写文章之前先自我提出问题：</p>\n<ol>\n<li>什么场景下适合用责任链模式？</li>\n<li>责任链模式和观察者模式的区别</li>\n<li>责任链模式适合与什么其他设计模式组合在一起？</li>\n</ol>\n<p>责任链模式是一种将请求沿着处理者链依次进行发送的设计模式。系统收到请求后，在链上的每个处理者均可对请求进行处理，或将其传递给链上的下个处理者。每个处理者都作为链上一个可活动的节点，使得责任链模式相较于if-else的分支语句，具有了更好的灵活性和扩展性。</p>\n<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>在商品上架的审批流系统的开发过程中，有着供应商、商品品控人员、上架风控人员等多种角色参与这一流程，并在其中进行着有先后依赖顺序的不同任务。这一流程会与其他系统（角色权限系统、商品库存系统等）具有深度耦合。<br>在设计之初有着足够简单的业务流程：</p>\n<ol>\n<li>供应商发起上架流程审批，成功则进入2，不成功重新发起1</li>\n<li>商品品控人员进行商品品控达标度进行检查，成功进入3，不成功返回1</li>\n<li>上架风控人员对上架的营销规则进行检查，成功上架，不成功返回1</li>\n</ol>\n<p>在这个业务流程中，因为足够简单，所以可以用简单的if语句完成所有的分支判断。单如果随着业务复杂度的增加，引入新角色，供应商资质管理员，新的流程的分支会变多：</p>\n<ol>\n<li>供应商发起上架流程审批，成功则进入2，不成功重新发起1</li>\n<li>商品品控人员进行商品质量达标度进行检查，成功进入4，部分成功进入3，完全不成功返回1</li>\n<li>供应商资质管理员对供应商的资质进行检查，成功进入4，不成功返回1</li>\n<li>上架风控人员对上架的营销规则进行检查，成功上架，不成功返回1</li>\n</ol>\n<p>在这个流程中，虽然只增加了一个角色和部分简单逻辑，但对原本if语句的冲击是很大的，为了兼容新的角色需要在多处进行改动，于是在迭代的过程中，势必会出现这样一种局面：</p>\n<ol>\n<li>在审批流中的代码本来就已经混乱不堪，之后每次新增功能都会使其更加臃肿。</li>\n<li>对审批流中的某个检查步骤进行修改时会影响其他的检查步骤。</li>\n<li>当希望复用这些审核逻辑来保护其他系统组件时，只需要复制部分逻辑就足够，但会面对所需的部分逻辑与整体审批流耦合得太深而很难剥离出来的问题。</li>\n</ol>\n<h1 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h1><p>与许多其他行为设计模式一样，责任链会将特定行为转换为被称作处理者的独立对象。</p>\n<ul>\n<li>在上述示例中，每个检查步骤都可被抽取为仅有单个方法的类，提供检查操作。</li>\n<li>请求及其数据则会被作为参数传递给该方法。</li>\n</ul>\n<p>责任链模式将这些处理者连成一条链，链上的每个处理者都有一个成员变量来保存对于下一处理者的引用。</p>\n<ul>\n<li>除了处理请求外，处理者还负责沿着链传递请求。</li>\n<li>请求会在链上移动，直至所有处理者都有机会对请求进行处理。</li>\n</ul>\n<p>最重要的是：处理者可以决定要不要沿着链继续传递请求，这样可以高效地取消所有后续处理步骤。<br>还有一种稍微不同的更经典的方式，处理者接收到请求后自行决定是否能够对其进行处理。</p>\n<ul>\n<li>如果自己能够处理，处理者就不再继续传递请求。</li>\n<li>在这种情况下，每个请求要么最多有一个处理者对其进行处理，要么没有任何处理者对其进行处理</li>\n</ul>\n<p>连成链的方式比较多样，可以用UML中展示的那样，一个处理对象使用SetNext()引用下一个处理对象。 也可以使用array或者list存储所有处理对象，使用循环方式遍历。</p>\n<ul>\n<li>对于第二种方式，感觉有些像观察者模式。</li>\n<li>两者具体实现、目的都差不多。主要区别在于：<ul>\n<li>观察者模式中的处理对象功能可能完全无关，观察者模式主要负责将信息传递给处理对象即可</li>\n<li>责任链模式的处理对象功能一般相似，另外责任链模式也关注请求是否正确被处理</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/pattern-1.png\" alt=\"image.png\"><br>责任链模式的核心在于将处理对象整理成链路。</p>\n<h1 id=\"适用场景\"><a href=\"#适用场景\" class=\"headerlink\" title=\"适用场景\"></a>适用场景</h1><ul>\n<li>程序需要使用不同方式处理请求<ul>\n<li>将多个处理者连接成一条链。接收到请求后，“询问” 每个处理者是否能对其进行处理。这样所有处理者都有机会来处理请求。</li>\n</ul>\n</li>\n<li>当必须按顺序执行多个处理者时，可以使用该模式。<ul>\n<li>无论你以何种顺序将处理者连接成一条链，所有请求都会严格按照顺序通过链上的处理者。</li>\n</ul>\n</li>\n<li>如果所需处理者及其顺序必须在运行时进行改变，可以使用责任链模式。<ul>\n<li>如果在处理者类中有对引用成员变量的设定方法，能动态地插入和移除处理者，或者改变其顺序。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"实现步骤\"><a href=\"#实现步骤\" class=\"headerlink\" title=\"实现步骤\"></a>实现步骤</h1><ol>\n<li>声明处理者接口并提供请求处理方法的签名。<ul>\n<li>确定客户端如何将请求数据传递给方法。 最灵活的方式是将请求转换为对象， 然后将其以参数的形式传递给处理函数。</li>\n</ul>\n</li>\n<li>为了消除具体处理者中的重复代码，可以根据处理者接口创建抽象处理者基类。<ul>\n<li>该类需要有一个成员变量来存储指向链上下一个处理者的引用。如果需要在运行时对链进行改变，需要定义一个设定方法来修改引用成员变量的值。</li>\n<li>还可以提供处理方法的默认行为。如果还有剩余对象，默认行为直接将请求传递给下个对象。具体处理者可以通过调用父对象的方法来使用这一行为。</li>\n</ul>\n</li>\n<li>依次创建具体处理者子类并实现其处理方法。 每个处理者在接收到请求后都必须做出两个决定：<ul>\n<li>是否自行处理这个请求</li>\n<li>是否将该请求沿着链进行传递</li>\n</ul>\n</li>\n<li>客户端可以自行组装链，或者从其他对象处获得预先组装好的链。<ul>\n<li>在后一种情况下，需要实现工厂类来根据配置或环境设置来创建链</li>\n</ul>\n</li>\n<li>客户端可以触发链中的任一处理者，不仅仅是第一个。请求将通过链进行传递，直至某个处理者拒绝继续传递，或者请求到达链尾。</li>\n<li>由于链的动态性，客户端需要处理以下情况：<ul>\n<li>部分请求可能无法到达链尾</li>\n<li>其他请求可能直到链尾都未被处理</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"优缺点\"><a href=\"#优缺点\" class=\"headerlink\" title=\"优缺点\"></a>优缺点</h1><p>优点：</p>\n<ul>\n<li>可以控制请求处理的顺序。</li>\n<li>单一职责原则。解耦了发起操作和执行操作的类。</li>\n<li>开闭原则。 可以在不更改现有代码的情况下在程序中新增处理者。</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>部分请求最终可能都未被处理。</li>\n</ul>\n<h1 id=\"与其它模式的关系\"><a href=\"#与其它模式的关系\" class=\"headerlink\" title=\"与其它模式的关系\"></a>与其它模式的关系</h1><ul>\n<li>责任链模式、命令模式、中介者模式和观察者模式用于处理请求发送者和接收者之间的不同连接方式：<ul>\n<li>责任链模式按照顺序将请求动态传递给一系列的潜在接收者。</li>\n<li>命令模式在发送者和请求者之间建立单向连接。</li>\n<li>中介者模式清除了发送者和请求者之间的直接连接，强制它们通过一个中介对象进行间接沟通。</li>\n<li>观察者模式允许接收者动态地订阅或取消接收请求。</li>\n</ul>\n</li>\n<li>责任链可以和组合模式结合使用<ul>\n<li>叶组件接收到请求后，将请求沿包含全体父组件的链一直传递至对象树的底部。</li>\n</ul>\n</li>\n<li>责任链上的处理器可使用命令模式实现<ul>\n<li>可以对由请求代表的同一个上下文对象执行许多不同的操作。</li>\n<li>或者，请求自身就是一个命令对象。可以对一系列不同对象组成的链执行相同的操作。</li>\n</ul>\n</li>\n<li>责任链和装饰模式的类结构非常相似。 两者都依赖递归组合将需要执行的操作传递给对象。两者也有几点不同<ul>\n<li>责任链上的处理器可以相互独立地执行，还可以随时停止传递请求</li>\n<li>各种装饰可以在遵循基本接口的情况下扩展对象的行为</li>\n<li>装饰无法中断请求的传递</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h1><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;string&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 定义处理者接口</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Approver</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"type\">void</span> <span class=\"title\">processRequest</span><span class=\"params\">(<span class=\"type\">const</span> std::string&amp; request)</span> </span>= <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">virtual</span> ~<span class=\"built_in\">Approver</span>() &#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 创建抽象处理者基类</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">BaseApprover</span> : <span class=\"keyword\">public</span> Approver &#123;</span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">Approver* nextApprover;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\"><span class=\"built_in\">BaseApprover</span>() : <span class=\"built_in\">nextApprover</span>(<span class=\"literal\">nullptr</span>) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 设置下一个处理者</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">setNextApprover</span><span class=\"params\">(Approver* next)</span> </span>&#123;</span><br><span class=\"line\">    nextApprover = next;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 处理请求的默认行为</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">processRequest</span><span class=\"params\">(<span class=\"type\">const</span> std::string&amp; request)</span> <span class=\"keyword\">override</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (nextApprover != <span class=\"literal\">nullptr</span>) &#123;</span><br><span class=\"line\">        nextApprover-&gt;<span class=\"built_in\">processRequest</span>(request);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; <span class=\"string\">&quot;Request not handled by any approver.&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体处理者子类：商品品控人员</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">QualityControlApprover</span> : <span class=\"keyword\">public</span> BaseApprover &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">processRequest</span><span class=\"params\">(<span class=\"type\">const</span> std::string&amp; request)</span> <span class=\"keyword\">override</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (request == <span class=\"string\">&quot;QualityCheck&quot;</span>) &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; <span class=\"string\">&quot;QualityControlApprover handles the request.&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        BaseApprover::<span class=\"built_in\">processRequest</span>(request);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体处理者子类：供应商资质管理员</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">SupplierQualificationApprover</span> : <span class=\"keyword\">public</span> BaseApprover &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">processRequest</span><span class=\"params\">(<span class=\"type\">const</span> std::string&amp; request)</span> <span class=\"keyword\">override</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (request == <span class=\"string\">&quot;SupplierQualificationCheck&quot;</span>) &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; <span class=\"string\">&quot;SupplierQualificationApprover handles the request.&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        BaseApprover::<span class=\"built_in\">processRequest</span>(request);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 具体处理者子类：上架风控人员</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">RiskControlApprover</span> : <span class=\"keyword\">public</span> BaseApprover &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">processRequest</span><span class=\"params\">(<span class=\"type\">const</span> std::string&amp; request)</span> <span class=\"keyword\">override</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (request == <span class=\"string\">&quot;MarketingRuleCheck&quot;</span>) &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; <span class=\"string\">&quot;RiskControlApprover handles the request and approves the product for shelf.&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        BaseApprover::<span class=\"built_in\">processRequest</span>(request);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 创建责任链</span></span><br><span class=\"line\">    QualityControlApprover qualityControlApprover;</span><br><span class=\"line\">    SupplierQualificationApprover supplierQualificationApprover;</span><br><span class=\"line\">    RiskControlApprover riskControlApprover;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 设置责任链顺序</span></span><br><span class=\"line\">    qualityControlApprover.<span class=\"built_in\">setNextApprover</span>(&amp;supplierQualificationApprover);</span><br><span class=\"line\">    supplierQualificationApprover.<span class=\"built_in\">setNextApprover</span>(&amp;riskControlApprover);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 模拟商品上架流程</span></span><br><span class=\"line\">    std::cout &lt;&lt; <span class=\"string\">&quot;Scenario 1:&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    qualityControlApprover.<span class=\"built_in\">processRequest</span>(<span class=\"string\">&quot;QualityCheck&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    std::cout &lt;&lt; <span class=\"string\">&quot;\\nScenario 2:&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    qualityControlApprover.<span class=\"built_in\">processRequest</span>(<span class=\"string\">&quot;SupplierQualificationCheck&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    std::cout &lt;&lt; <span class=\"string\">&quot;\\nScenario 3:&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    qualityControlApprover.<span class=\"built_in\">processRequest</span>(<span class=\"string\">&quot;MarketingRuleCheck&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    std::cout &lt;&lt; <span class=\"string\">&quot;\\nScenario 4:&quot;</span> &lt;&lt; std::endl;</span><br><span class=\"line\">    qualityControlApprover.<span class=\"built_in\">processRequest</span>(<span class=\"string\">&quot;SomeOtherCheck&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n"},{"title":"模版编程技巧(一)--CRTP","date":"2023-12-08T10:24:34.000Z","_content":"CRTP（Curiously Recurring Template Pattern）是一种模板的编程模式，基本思想是在一个类模板中将派生类作为模板参数传递给基类，从而实现多态的编程技巧。\n# 1 基于虚函数实现的动态多态\n如下面的代码所示，C++ 通过类的继承与虚函数的动态绑定，实现了多态。这种特性，使得我们能够用基类的指针，访问子类的实例。例如我们可以实现一个名为 Shape 的基类，以及 Square, Circle 等子类，并通过在子类中重载虚函数 printArea，实现不同形状的面积输出。而后我们可以通过访问 Shape_List 类的实例中存有 Shape 指针的数组，让所有形状都打印一遍。\n```\n// 基类\nclass Shape {\npublic:\n    // 虚函数，实现多态\n    virtual void printArea() const {\n        std::cout << \"Shape Area\" << std::endl;\n    }\n\n    // 基类可能包含其他的成员函数或数据成员\n};\n\n// 派生类1\nclass Circle : public Shape {\npublic:\n    Circle(double radius) : radius(radius) {}\n\n    // 重写基类的虚函数\n    void printArea() const override {\n        std::cout << \"Circle Area: \" << 3.14159 * radius * radius << std::endl;\n    }\n\nprivate:\n    double radius;\n};\n\n// 派生类2\nclass Square : public Shape {\npublic:\n    Square(double side) : side(side) {}\n\n    // 重写基类的虚函数\n    void printArea() const override {\n        std::cout << \"Square Area: \" << side * side << std::endl;\n    }\n\nprivate:\n    double side;\n};\n```\n但是问题是在每次执行 shape->printArea() 的时候，系统会检查 shape 指向的实例实际的类型，然后调用对应类型的 printArea 函数。这一步骤需要通过查询虚函数表（vtable）来实现；由于实际 shape 指向对象的类型在运行时才确定（而不是在编译时就确定），所以这种方式称为动态绑定（或者运行时绑定）。\n因为每次都需要查询虚函数表，所以动态绑定会降低程序的执行效率。为了兼顾多态与效率，于是使用Curiously Recurring Template Pattern 这一概念改写程序。\n# 2 基于模板实现的静态多态\n为了在编译时绑定，我们就需要放弃 C++ 的虚函数机制，而只是在基类和子类中实现同名的函数；同时，为了在编译时确定类型，我们就需要将子类的名字在编译时提前传给基类，因此，我们需要用到 C++ 的模板。所以概括的说，静态多态的核心思路是用模板在静态编译期获得子类的类名以避开查虚函数表。\n```\n#include <iostream>\n\n// 基类模板\ntemplate <typename T>\nclass Shape {\npublic:\n    // 模板函数，实现静态多态\n    void printArea() const {\n        static_cast<T const*>(this)->printAreaImpl();\n    }\n\n    // 重载++运算符，用于对派生类中的参数进行自增\n    T& operator++() {\n        static_cast<T*>(this)->increment();\n        return *static_cast<T*>(this);\n    }\n};\n\n// 派生类1\nclass Circle : public Shape<Circle> {\npublic:\n    Circle(double radius) : radius(radius) {}\n\n    // 派生类实现具体的printArea函数\n    void printAreaImpl() const {\n        std::cout << \"Circle Area: \" << 3.14159 * radius * radius << std::endl;\n    }\n\n    // 自增半径\n    void increment() {\n        ++radius;\n    }\n\nprivate:\n    double radius;\n};\n\n// 派生类2\nclass Square : public Shape<Square> {\npublic:\n    Square(double side) : side(side) {}\n\n    // 派生类实现具体的printArea函数\n    void printAreaImpl() const {\n        std::cout << \"Square Area: \" << side * side << std::endl;\n    }\n\n    // 自增边长\n    void increment() {\n        ++side;\n    }\n\nprivate:\n    double side;\n};\n\nint main() {\n    Circle circle(5.0);\n    Square square(4.0);\n\n    // 调用基类模板函数，实现静态多态\n    circle.printArea();\n    square.printArea();\n\n    // 使用++运算符对派生类中的参数进行自增\n    ++circle;\n    ++square;\n\n    // 再次调用基类模板函数，查看自增后的结果\n    circle.printArea();\n    square.printArea();\n\n    return 0;\n}\n\n```\n\n在这个例子中，Shape 是一个模板类，它有一个模板函数 printArea。然后，Circle 和 Square 分别是 Shape 的派生类，并在各自的类中实现了 printAreaImpl 函数并且重载了 ++ 运算符。通过CRTP，Shape 的模板函数 printArea 能够调用正确的实现，++ 运算符也能正确的调用，实现了静态多态。在运行时，不需要虚函数表，而是在编译时就完成了函数调用的解析。\n# 3 基于虚函数和模板混合的多态实现\n虽然上文基于模版也实现了可用的静态多态，但是还存在问题。\n如果是基于虚函数实现的多态，由于不同的子类指针，Circle*，Square*等指针可以很轻易地传给基类Shape*，这样可以在容器中vector<Shape*>很容易存下一系列子类指针，但是在CRTP模式下则不行，Shape<Circle>*，Shape<Square>*完全是不同类型的指针，是无法在一个容器中存放他们的。\n事实上， CRTP 本质上是为了解决多态存在的要查虚函数表的慢动态绑定而引入的，而事实上，动态绑定慢，通常是因为多级继承；如果继承很短，那么查虚函数表的开销实际上也没多大。\n在之前举出的例子里，我们运用 CRTP，完全消除了动态绑定；但与此同时，我们也在某种意义上损失了多态性。现在我们希望二者兼顾：保留多态性，同时降低多级继承带来的虚函数表查询开销。答案也很简单：让 CRTP 的模板类继承一个非模板的基类——这相当于这个非模板的基类会有多个平级的不同的子类。这样就可以兼顾多态的抽象性和动态绑定的性能性，具体的示例如下。\n```\n#include <iostream>\n#include <vector>\n\nusing std::cout; \nusing std::endl;\nusing std::vector;\n\nclass Shape {\n public:\n    virtual void printArea () const = 0;\n    virtual ~Shape() {}\n};\n\ntemplate <typename T>\nclass Shape_CRTP: public Shape {\n public:\n    void printArea() const override{\n        static_cast<T const*>(this)->printAreaImpl();\n    }\n    \n};\n\nclass Circle: public Shape_CRTP<Circle> {\npublic:\n    Circle(double radius) : radius(radius) {}\n\n    // 派生类实现具体的printArea函数\n    void printAreaImpl() const {\n        std::cout << \"Circle Area: \" << 3.14159 * radius * radius << std::endl;\n    }\nprivate:\n    double radius;\n};\n\n// 派生类2\nclass Square : public Shape_CRTP<Square> {\npublic:\n    Square(double side) : side(side) {}\n\n    // 派生类实现具体的printArea函数\n    void printAreaImpl() const {\n        std::cout << \"Square Area: \" << side * side << std::endl;\n    }\nprivate:\n    double side;\n};\n\nint main () {\n    vector<Shape*> list;\n    list.push_back(new Circle(1));\n    list.push_back(new Square(1));\n    for (auto iter{list.begin()}; iter != list.end(); ++iter) {\n        (*iter)->printArea();\n    }\n    for (auto iter{list.begin()}; iter != list.end(); ++iter) {\n        delete (*iter);\n    }\n    return 0;\n}\n```\n","source":"_posts/Template-programming-1.md","raw":"---\ntitle: 模版编程技巧(一)--CRTP\ndate: 2023-12-08 18:24:34\ntags: Cpp\n---\nCRTP（Curiously Recurring Template Pattern）是一种模板的编程模式，基本思想是在一个类模板中将派生类作为模板参数传递给基类，从而实现多态的编程技巧。\n# 1 基于虚函数实现的动态多态\n如下面的代码所示，C++ 通过类的继承与虚函数的动态绑定，实现了多态。这种特性，使得我们能够用基类的指针，访问子类的实例。例如我们可以实现一个名为 Shape 的基类，以及 Square, Circle 等子类，并通过在子类中重载虚函数 printArea，实现不同形状的面积输出。而后我们可以通过访问 Shape_List 类的实例中存有 Shape 指针的数组，让所有形状都打印一遍。\n```\n// 基类\nclass Shape {\npublic:\n    // 虚函数，实现多态\n    virtual void printArea() const {\n        std::cout << \"Shape Area\" << std::endl;\n    }\n\n    // 基类可能包含其他的成员函数或数据成员\n};\n\n// 派生类1\nclass Circle : public Shape {\npublic:\n    Circle(double radius) : radius(radius) {}\n\n    // 重写基类的虚函数\n    void printArea() const override {\n        std::cout << \"Circle Area: \" << 3.14159 * radius * radius << std::endl;\n    }\n\nprivate:\n    double radius;\n};\n\n// 派生类2\nclass Square : public Shape {\npublic:\n    Square(double side) : side(side) {}\n\n    // 重写基类的虚函数\n    void printArea() const override {\n        std::cout << \"Square Area: \" << side * side << std::endl;\n    }\n\nprivate:\n    double side;\n};\n```\n但是问题是在每次执行 shape->printArea() 的时候，系统会检查 shape 指向的实例实际的类型，然后调用对应类型的 printArea 函数。这一步骤需要通过查询虚函数表（vtable）来实现；由于实际 shape 指向对象的类型在运行时才确定（而不是在编译时就确定），所以这种方式称为动态绑定（或者运行时绑定）。\n因为每次都需要查询虚函数表，所以动态绑定会降低程序的执行效率。为了兼顾多态与效率，于是使用Curiously Recurring Template Pattern 这一概念改写程序。\n# 2 基于模板实现的静态多态\n为了在编译时绑定，我们就需要放弃 C++ 的虚函数机制，而只是在基类和子类中实现同名的函数；同时，为了在编译时确定类型，我们就需要将子类的名字在编译时提前传给基类，因此，我们需要用到 C++ 的模板。所以概括的说，静态多态的核心思路是用模板在静态编译期获得子类的类名以避开查虚函数表。\n```\n#include <iostream>\n\n// 基类模板\ntemplate <typename T>\nclass Shape {\npublic:\n    // 模板函数，实现静态多态\n    void printArea() const {\n        static_cast<T const*>(this)->printAreaImpl();\n    }\n\n    // 重载++运算符，用于对派生类中的参数进行自增\n    T& operator++() {\n        static_cast<T*>(this)->increment();\n        return *static_cast<T*>(this);\n    }\n};\n\n// 派生类1\nclass Circle : public Shape<Circle> {\npublic:\n    Circle(double radius) : radius(radius) {}\n\n    // 派生类实现具体的printArea函数\n    void printAreaImpl() const {\n        std::cout << \"Circle Area: \" << 3.14159 * radius * radius << std::endl;\n    }\n\n    // 自增半径\n    void increment() {\n        ++radius;\n    }\n\nprivate:\n    double radius;\n};\n\n// 派生类2\nclass Square : public Shape<Square> {\npublic:\n    Square(double side) : side(side) {}\n\n    // 派生类实现具体的printArea函数\n    void printAreaImpl() const {\n        std::cout << \"Square Area: \" << side * side << std::endl;\n    }\n\n    // 自增边长\n    void increment() {\n        ++side;\n    }\n\nprivate:\n    double side;\n};\n\nint main() {\n    Circle circle(5.0);\n    Square square(4.0);\n\n    // 调用基类模板函数，实现静态多态\n    circle.printArea();\n    square.printArea();\n\n    // 使用++运算符对派生类中的参数进行自增\n    ++circle;\n    ++square;\n\n    // 再次调用基类模板函数，查看自增后的结果\n    circle.printArea();\n    square.printArea();\n\n    return 0;\n}\n\n```\n\n在这个例子中，Shape 是一个模板类，它有一个模板函数 printArea。然后，Circle 和 Square 分别是 Shape 的派生类，并在各自的类中实现了 printAreaImpl 函数并且重载了 ++ 运算符。通过CRTP，Shape 的模板函数 printArea 能够调用正确的实现，++ 运算符也能正确的调用，实现了静态多态。在运行时，不需要虚函数表，而是在编译时就完成了函数调用的解析。\n# 3 基于虚函数和模板混合的多态实现\n虽然上文基于模版也实现了可用的静态多态，但是还存在问题。\n如果是基于虚函数实现的多态，由于不同的子类指针，Circle*，Square*等指针可以很轻易地传给基类Shape*，这样可以在容器中vector<Shape*>很容易存下一系列子类指针，但是在CRTP模式下则不行，Shape<Circle>*，Shape<Square>*完全是不同类型的指针，是无法在一个容器中存放他们的。\n事实上， CRTP 本质上是为了解决多态存在的要查虚函数表的慢动态绑定而引入的，而事实上，动态绑定慢，通常是因为多级继承；如果继承很短，那么查虚函数表的开销实际上也没多大。\n在之前举出的例子里，我们运用 CRTP，完全消除了动态绑定；但与此同时，我们也在某种意义上损失了多态性。现在我们希望二者兼顾：保留多态性，同时降低多级继承带来的虚函数表查询开销。答案也很简单：让 CRTP 的模板类继承一个非模板的基类——这相当于这个非模板的基类会有多个平级的不同的子类。这样就可以兼顾多态的抽象性和动态绑定的性能性，具体的示例如下。\n```\n#include <iostream>\n#include <vector>\n\nusing std::cout; \nusing std::endl;\nusing std::vector;\n\nclass Shape {\n public:\n    virtual void printArea () const = 0;\n    virtual ~Shape() {}\n};\n\ntemplate <typename T>\nclass Shape_CRTP: public Shape {\n public:\n    void printArea() const override{\n        static_cast<T const*>(this)->printAreaImpl();\n    }\n    \n};\n\nclass Circle: public Shape_CRTP<Circle> {\npublic:\n    Circle(double radius) : radius(radius) {}\n\n    // 派生类实现具体的printArea函数\n    void printAreaImpl() const {\n        std::cout << \"Circle Area: \" << 3.14159 * radius * radius << std::endl;\n    }\nprivate:\n    double radius;\n};\n\n// 派生类2\nclass Square : public Shape_CRTP<Square> {\npublic:\n    Square(double side) : side(side) {}\n\n    // 派生类实现具体的printArea函数\n    void printAreaImpl() const {\n        std::cout << \"Square Area: \" << side * side << std::endl;\n    }\nprivate:\n    double side;\n};\n\nint main () {\n    vector<Shape*> list;\n    list.push_back(new Circle(1));\n    list.push_back(new Square(1));\n    for (auto iter{list.begin()}; iter != list.end(); ++iter) {\n        (*iter)->printArea();\n    }\n    for (auto iter{list.begin()}; iter != list.end(); ++iter) {\n        delete (*iter);\n    }\n    return 0;\n}\n```\n","slug":"Template-programming-1","published":1,"updated":"2023-12-11T15:13:09.473Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clrhz6rws000a0ox546afb3zn","content":"<p>CRTP（Curiously Recurring Template Pattern）是一种模板的编程模式，基本思想是在一个类模板中将派生类作为模板参数传递给基类，从而实现多态的编程技巧。</p>\n<h1 id=\"1-基于虚函数实现的动态多态\"><a href=\"#1-基于虚函数实现的动态多态\" class=\"headerlink\" title=\"1 基于虚函数实现的动态多态\"></a>1 基于虚函数实现的动态多态</h1><p>如下面的代码所示，C++ 通过类的继承与虚函数的动态绑定，实现了多态。这种特性，使得我们能够用基类的指针，访问子类的实例。例如我们可以实现一个名为 Shape 的基类，以及 Square, Circle 等子类，并通过在子类中重载虚函数 printArea，实现不同形状的面积输出。而后我们可以通过访问 Shape_List 类的实例中存有 Shape 指针的数组，让所有形状都打印一遍。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 基类</span><br><span class=\"line\">class Shape &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    // 虚函数，实现多态</span><br><span class=\"line\">    virtual void printArea() const &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Shape Area&quot; &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 基类可能包含其他的成员函数或数据成员</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">// 派生类1</span><br><span class=\"line\">class Circle : public Shape &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    Circle(double radius) : radius(radius) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 重写基类的虚函数</span><br><span class=\"line\">    void printArea() const override &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Circle Area: &quot; &lt;&lt; 3.14159 * radius * radius &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private:</span><br><span class=\"line\">    double radius;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">// 派生类2</span><br><span class=\"line\">class Square : public Shape &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    Square(double side) : side(side) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 重写基类的虚函数</span><br><span class=\"line\">    void printArea() const override &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Square Area: &quot; &lt;&lt; side * side &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private:</span><br><span class=\"line\">    double side;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>但是问题是在每次执行 shape-&gt;printArea() 的时候，系统会检查 shape 指向的实例实际的类型，然后调用对应类型的 printArea 函数。这一步骤需要通过查询虚函数表（vtable）来实现；由于实际 shape 指向对象的类型在运行时才确定（而不是在编译时就确定），所以这种方式称为动态绑定（或者运行时绑定）。<br>因为每次都需要查询虚函数表，所以动态绑定会降低程序的执行效率。为了兼顾多态与效率，于是使用Curiously Recurring Template Pattern 这一概念改写程序。</p>\n<h1 id=\"2-基于模板实现的静态多态\"><a href=\"#2-基于模板实现的静态多态\" class=\"headerlink\" title=\"2 基于模板实现的静态多态\"></a>2 基于模板实现的静态多态</h1><p>为了在编译时绑定，我们就需要放弃 C++ 的虚函数机制，而只是在基类和子类中实现同名的函数；同时，为了在编译时确定类型，我们就需要将子类的名字在编译时提前传给基类，因此，我们需要用到 C++ 的模板。所以概括的说，静态多态的核心思路是用模板在静态编译期获得子类的类名以避开查虚函数表。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">// 基类模板</span><br><span class=\"line\">template &lt;typename T&gt;</span><br><span class=\"line\">class Shape &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    // 模板函数，实现静态多态</span><br><span class=\"line\">    void printArea() const &#123;</span><br><span class=\"line\">        static_cast&lt;T const*&gt;(this)-&gt;printAreaImpl();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 重载++运算符，用于对派生类中的参数进行自增</span><br><span class=\"line\">    T&amp; operator++() &#123;</span><br><span class=\"line\">        static_cast&lt;T*&gt;(this)-&gt;increment();</span><br><span class=\"line\">        return *static_cast&lt;T*&gt;(this);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">// 派生类1</span><br><span class=\"line\">class Circle : public Shape&lt;Circle&gt; &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    Circle(double radius) : radius(radius) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 派生类实现具体的printArea函数</span><br><span class=\"line\">    void printAreaImpl() const &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Circle Area: &quot; &lt;&lt; 3.14159 * radius * radius &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 自增半径</span><br><span class=\"line\">    void increment() &#123;</span><br><span class=\"line\">        ++radius;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private:</span><br><span class=\"line\">    double radius;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">// 派生类2</span><br><span class=\"line\">class Square : public Shape&lt;Square&gt; &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    Square(double side) : side(side) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 派生类实现具体的printArea函数</span><br><span class=\"line\">    void printAreaImpl() const &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Square Area: &quot; &lt;&lt; side * side &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 自增边长</span><br><span class=\"line\">    void increment() &#123;</span><br><span class=\"line\">        ++side;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private:</span><br><span class=\"line\">    double side;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">int main() &#123;</span><br><span class=\"line\">    Circle circle(5.0);</span><br><span class=\"line\">    Square square(4.0);</span><br><span class=\"line\"></span><br><span class=\"line\">    // 调用基类模板函数，实现静态多态</span><br><span class=\"line\">    circle.printArea();</span><br><span class=\"line\">    square.printArea();</span><br><span class=\"line\"></span><br><span class=\"line\">    // 使用++运算符对派生类中的参数进行自增</span><br><span class=\"line\">    ++circle;</span><br><span class=\"line\">    ++square;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 再次调用基类模板函数，查看自增后的结果</span><br><span class=\"line\">    circle.printArea();</span><br><span class=\"line\">    square.printArea();</span><br><span class=\"line\"></span><br><span class=\"line\">    return 0;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>在这个例子中，Shape 是一个模板类，它有一个模板函数 printArea。然后，Circle 和 Square 分别是 Shape 的派生类，并在各自的类中实现了 printAreaImpl 函数并且重载了 ++ 运算符。通过CRTP，Shape 的模板函数 printArea 能够调用正确的实现，++ 运算符也能正确的调用，实现了静态多态。在运行时，不需要虚函数表，而是在编译时就完成了函数调用的解析。</p>\n<h1 id=\"3-基于虚函数和模板混合的多态实现\"><a href=\"#3-基于虚函数和模板混合的多态实现\" class=\"headerlink\" title=\"3 基于虚函数和模板混合的多态实现\"></a>3 基于虚函数和模板混合的多态实现</h1><p>虽然上文基于模版也实现了可用的静态多态，但是还存在问题。<br>如果是基于虚函数实现的多态，由于不同的子类指针，Circle<em>，Square</em>等指针可以很轻易地传给基类Shape*，这样可以在容器中vector&lt;Shape*&gt;很容易存下一系列子类指针，但是在CRTP模式下则不行，Shape<Circle>*，Shape<Square>*完全是不同类型的指针，是无法在一个容器中存放他们的。<br>事实上， CRTP 本质上是为了解决多态存在的要查虚函数表的慢动态绑定而引入的，而事实上，动态绑定慢，通常是因为多级继承；如果继承很短，那么查虚函数表的开销实际上也没多大。<br>在之前举出的例子里，我们运用 CRTP，完全消除了动态绑定；但与此同时，我们也在某种意义上损失了多态性。现在我们希望二者兼顾：保留多态性，同时降低多级继承带来的虚函数表查询开销。答案也很简单：让 CRTP 的模板类继承一个非模板的基类——这相当于这个非模板的基类会有多个平级的不同的子类。这样就可以兼顾多态的抽象性和动态绑定的性能性，具体的示例如下。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\">#include &lt;vector&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">using std::cout; </span><br><span class=\"line\">using std::endl;</span><br><span class=\"line\">using std::vector;</span><br><span class=\"line\"></span><br><span class=\"line\">class Shape &#123;</span><br><span class=\"line\"> public:</span><br><span class=\"line\">    virtual void printArea () const = 0;</span><br><span class=\"line\">    virtual ~Shape() &#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">template &lt;typename T&gt;</span><br><span class=\"line\">class Shape_CRTP: public Shape &#123;</span><br><span class=\"line\"> public:</span><br><span class=\"line\">    void printArea() const override&#123;</span><br><span class=\"line\">        static_cast&lt;T const*&gt;(this)-&gt;printAreaImpl();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">class Circle: public Shape_CRTP&lt;Circle&gt; &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    Circle(double radius) : radius(radius) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 派生类实现具体的printArea函数</span><br><span class=\"line\">    void printAreaImpl() const &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Circle Area: &quot; &lt;&lt; 3.14159 * radius * radius &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">private:</span><br><span class=\"line\">    double radius;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">// 派生类2</span><br><span class=\"line\">class Square : public Shape_CRTP&lt;Square&gt; &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    Square(double side) : side(side) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 派生类实现具体的printArea函数</span><br><span class=\"line\">    void printAreaImpl() const &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Square Area: &quot; &lt;&lt; side * side &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">private:</span><br><span class=\"line\">    double side;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">int main () &#123;</span><br><span class=\"line\">    vector&lt;Shape*&gt; list;</span><br><span class=\"line\">    list.push_back(new Circle(1));</span><br><span class=\"line\">    list.push_back(new Square(1));</span><br><span class=\"line\">    for (auto iter&#123;list.begin()&#125;; iter != list.end(); ++iter) &#123;</span><br><span class=\"line\">        (*iter)-&gt;printArea();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    for (auto iter&#123;list.begin()&#125;; iter != list.end(); ++iter) &#123;</span><br><span class=\"line\">        delete (*iter);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return 0;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>CRTP（Curiously Recurring Template Pattern）是一种模板的编程模式，基本思想是在一个类模板中将派生类作为模板参数传递给基类，从而实现多态的编程技巧。</p>\n<h1 id=\"1-基于虚函数实现的动态多态\"><a href=\"#1-基于虚函数实现的动态多态\" class=\"headerlink\" title=\"1 基于虚函数实现的动态多态\"></a>1 基于虚函数实现的动态多态</h1><p>如下面的代码所示，C++ 通过类的继承与虚函数的动态绑定，实现了多态。这种特性，使得我们能够用基类的指针，访问子类的实例。例如我们可以实现一个名为 Shape 的基类，以及 Square, Circle 等子类，并通过在子类中重载虚函数 printArea，实现不同形状的面积输出。而后我们可以通过访问 Shape_List 类的实例中存有 Shape 指针的数组，让所有形状都打印一遍。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 基类</span><br><span class=\"line\">class Shape &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    // 虚函数，实现多态</span><br><span class=\"line\">    virtual void printArea() const &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Shape Area&quot; &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 基类可能包含其他的成员函数或数据成员</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">// 派生类1</span><br><span class=\"line\">class Circle : public Shape &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    Circle(double radius) : radius(radius) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 重写基类的虚函数</span><br><span class=\"line\">    void printArea() const override &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Circle Area: &quot; &lt;&lt; 3.14159 * radius * radius &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private:</span><br><span class=\"line\">    double radius;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">// 派生类2</span><br><span class=\"line\">class Square : public Shape &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    Square(double side) : side(side) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 重写基类的虚函数</span><br><span class=\"line\">    void printArea() const override &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Square Area: &quot; &lt;&lt; side * side &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private:</span><br><span class=\"line\">    double side;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>但是问题是在每次执行 shape-&gt;printArea() 的时候，系统会检查 shape 指向的实例实际的类型，然后调用对应类型的 printArea 函数。这一步骤需要通过查询虚函数表（vtable）来实现；由于实际 shape 指向对象的类型在运行时才确定（而不是在编译时就确定），所以这种方式称为动态绑定（或者运行时绑定）。<br>因为每次都需要查询虚函数表，所以动态绑定会降低程序的执行效率。为了兼顾多态与效率，于是使用Curiously Recurring Template Pattern 这一概念改写程序。</p>\n<h1 id=\"2-基于模板实现的静态多态\"><a href=\"#2-基于模板实现的静态多态\" class=\"headerlink\" title=\"2 基于模板实现的静态多态\"></a>2 基于模板实现的静态多态</h1><p>为了在编译时绑定，我们就需要放弃 C++ 的虚函数机制，而只是在基类和子类中实现同名的函数；同时，为了在编译时确定类型，我们就需要将子类的名字在编译时提前传给基类，因此，我们需要用到 C++ 的模板。所以概括的说，静态多态的核心思路是用模板在静态编译期获得子类的类名以避开查虚函数表。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">// 基类模板</span><br><span class=\"line\">template &lt;typename T&gt;</span><br><span class=\"line\">class Shape &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    // 模板函数，实现静态多态</span><br><span class=\"line\">    void printArea() const &#123;</span><br><span class=\"line\">        static_cast&lt;T const*&gt;(this)-&gt;printAreaImpl();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 重载++运算符，用于对派生类中的参数进行自增</span><br><span class=\"line\">    T&amp; operator++() &#123;</span><br><span class=\"line\">        static_cast&lt;T*&gt;(this)-&gt;increment();</span><br><span class=\"line\">        return *static_cast&lt;T*&gt;(this);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">// 派生类1</span><br><span class=\"line\">class Circle : public Shape&lt;Circle&gt; &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    Circle(double radius) : radius(radius) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 派生类实现具体的printArea函数</span><br><span class=\"line\">    void printAreaImpl() const &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Circle Area: &quot; &lt;&lt; 3.14159 * radius * radius &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 自增半径</span><br><span class=\"line\">    void increment() &#123;</span><br><span class=\"line\">        ++radius;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private:</span><br><span class=\"line\">    double radius;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">// 派生类2</span><br><span class=\"line\">class Square : public Shape&lt;Square&gt; &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    Square(double side) : side(side) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 派生类实现具体的printArea函数</span><br><span class=\"line\">    void printAreaImpl() const &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Square Area: &quot; &lt;&lt; side * side &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 自增边长</span><br><span class=\"line\">    void increment() &#123;</span><br><span class=\"line\">        ++side;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private:</span><br><span class=\"line\">    double side;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">int main() &#123;</span><br><span class=\"line\">    Circle circle(5.0);</span><br><span class=\"line\">    Square square(4.0);</span><br><span class=\"line\"></span><br><span class=\"line\">    // 调用基类模板函数，实现静态多态</span><br><span class=\"line\">    circle.printArea();</span><br><span class=\"line\">    square.printArea();</span><br><span class=\"line\"></span><br><span class=\"line\">    // 使用++运算符对派生类中的参数进行自增</span><br><span class=\"line\">    ++circle;</span><br><span class=\"line\">    ++square;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 再次调用基类模板函数，查看自增后的结果</span><br><span class=\"line\">    circle.printArea();</span><br><span class=\"line\">    square.printArea();</span><br><span class=\"line\"></span><br><span class=\"line\">    return 0;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>在这个例子中，Shape 是一个模板类，它有一个模板函数 printArea。然后，Circle 和 Square 分别是 Shape 的派生类，并在各自的类中实现了 printAreaImpl 函数并且重载了 ++ 运算符。通过CRTP，Shape 的模板函数 printArea 能够调用正确的实现，++ 运算符也能正确的调用，实现了静态多态。在运行时，不需要虚函数表，而是在编译时就完成了函数调用的解析。</p>\n<h1 id=\"3-基于虚函数和模板混合的多态实现\"><a href=\"#3-基于虚函数和模板混合的多态实现\" class=\"headerlink\" title=\"3 基于虚函数和模板混合的多态实现\"></a>3 基于虚函数和模板混合的多态实现</h1><p>虽然上文基于模版也实现了可用的静态多态，但是还存在问题。<br>如果是基于虚函数实现的多态，由于不同的子类指针，Circle<em>，Square</em>等指针可以很轻易地传给基类Shape*，这样可以在容器中vector&lt;Shape*&gt;很容易存下一系列子类指针，但是在CRTP模式下则不行，Shape<Circle>*，Shape<Square>*完全是不同类型的指针，是无法在一个容器中存放他们的。<br>事实上， CRTP 本质上是为了解决多态存在的要查虚函数表的慢动态绑定而引入的，而事实上，动态绑定慢，通常是因为多级继承；如果继承很短，那么查虚函数表的开销实际上也没多大。<br>在之前举出的例子里，我们运用 CRTP，完全消除了动态绑定；但与此同时，我们也在某种意义上损失了多态性。现在我们希望二者兼顾：保留多态性，同时降低多级继承带来的虚函数表查询开销。答案也很简单：让 CRTP 的模板类继承一个非模板的基类——这相当于这个非模板的基类会有多个平级的不同的子类。这样就可以兼顾多态的抽象性和动态绑定的性能性，具体的示例如下。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\">#include &lt;vector&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">using std::cout; </span><br><span class=\"line\">using std::endl;</span><br><span class=\"line\">using std::vector;</span><br><span class=\"line\"></span><br><span class=\"line\">class Shape &#123;</span><br><span class=\"line\"> public:</span><br><span class=\"line\">    virtual void printArea () const = 0;</span><br><span class=\"line\">    virtual ~Shape() &#123;&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">template &lt;typename T&gt;</span><br><span class=\"line\">class Shape_CRTP: public Shape &#123;</span><br><span class=\"line\"> public:</span><br><span class=\"line\">    void printArea() const override&#123;</span><br><span class=\"line\">        static_cast&lt;T const*&gt;(this)-&gt;printAreaImpl();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">class Circle: public Shape_CRTP&lt;Circle&gt; &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    Circle(double radius) : radius(radius) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 派生类实现具体的printArea函数</span><br><span class=\"line\">    void printAreaImpl() const &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Circle Area: &quot; &lt;&lt; 3.14159 * radius * radius &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">private:</span><br><span class=\"line\">    double radius;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">// 派生类2</span><br><span class=\"line\">class Square : public Shape_CRTP&lt;Square&gt; &#123;</span><br><span class=\"line\">public:</span><br><span class=\"line\">    Square(double side) : side(side) &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 派生类实现具体的printArea函数</span><br><span class=\"line\">    void printAreaImpl() const &#123;</span><br><span class=\"line\">        std::cout &lt;&lt; &quot;Square Area: &quot; &lt;&lt; side * side &lt;&lt; std::endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">private:</span><br><span class=\"line\">    double side;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">int main () &#123;</span><br><span class=\"line\">    vector&lt;Shape*&gt; list;</span><br><span class=\"line\">    list.push_back(new Circle(1));</span><br><span class=\"line\">    list.push_back(new Square(1));</span><br><span class=\"line\">    for (auto iter&#123;list.begin()&#125;; iter != list.end(); ++iter) &#123;</span><br><span class=\"line\">        (*iter)-&gt;printArea();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    for (auto iter&#123;list.begin()&#125;; iter != list.end(); ++iter) &#123;</span><br><span class=\"line\">        delete (*iter);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return 0;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n"},{"title":"线程安全的循环队列","date":"2023-12-28T05:30:34.000Z","_content":"\n尝试了和ChatGtp进行合作开发,使用合适的prompt逐步修正结果，得到一个初步符合我们预期的循环队列。\n# 1 需求的自然语言描述\n用C++ 20的语言标准，实现线程安全的循环队列，提供详细注释\n具体要求如下：\n1、环形队列要支持阻塞读和非阻塞读，阻塞写和非阻塞写\n2、支持模板，存放的数据类型可以自定义\n3、代码风格使用google C++风格\n4、在开发中尽可能提高队列的性能，并说明采取了哪些手段提高性能，说明理由\n# 2 Gpt第一轮尝试\n## 2.1 Gpt给出的结果\n```cpp\n#include <iostream>\n#include <queue>\n#include <mutex>\n#include <condition_variable>\n#include <thread>\n\n// 线程安全的循环队列模板\ntemplate <typename T>\nclass ThreadSafeQueue {\npublic:\n    explicit ThreadSafeQueue(size_t capacity) : capacity_(capacity) {}\n\n    // 阻塞写入队列\n    void Enqueue(const T& item) {\n        std::unique_lock<std::mutex> lock(mutex_);\n        // 使用条件变量等待队列不满\n        notFull_.wait(lock, [this] { return queue_.size() < capacity_; });\n        queue_.push(item);\n        lock.unlock();\n        // 通知等待的线程队列不为空\n        notEmpty_.notify_one();\n    }\n\n    // 非阻塞写入队列\n    bool TryEnqueue(const T& item) {\n        std::lock_guard<std::mutex> lock(mutex_);\n        if (queue_.size() < capacity_) {\n            queue_.push(item);\n            // 通知等待的线程队列不为空\n            notEmpty_.notify_one();\n            return true;\n        }\n        return false;\n    }\n\n    // 阻塞读取队列\n    T Dequeue() {\n        std::unique_lock<std::mutex> lock(mutex_);\n        // 使用条件变量等待队列不空\n        notEmpty_.wait(lock, [this] { return !queue_.empty(); });\n        T item = queue_.front();\n        queue_.pop();\n        lock.unlock();\n        // 通知等待的线程队列不满\n        notFull_.notify_one();\n        return item;\n    }\n\n    // 非阻塞读取队列\n    bool TryDequeue(T& item) {\n        std::lock_guard<std::mutex> lock(mutex_);\n        if (!queue_.empty()) {\n            item = queue_.front();\n            queue_.pop();\n            // 通知等待的线程队列不满\n            notFull_.notify_one();\n            return true;\n        }\n        return false;\n    }\n\nprivate:\n    size_t capacity_;\n    std::queue<T> queue_;\n    std::mutex mutex_;\n    std::condition_variable notFull_;\n    std::condition_variable notEmpty_;\n};\n```\n## 2.2 对代码的分析\n代码最低限度地实现了我们提出的需求，比如阻塞/非阻塞读写、支持模板、代码风格等。但是代码中存在着许多显而易见的问题。\n\n1. 可能是我使用的“队列”一词对gpt造成了先入为主的印象，导致它在数据结构上采用了deque的结构，当deque需要增长时，它会分配一个新的内存块，并将其链接到现有的块，这样一个动态的结构天生会对内存的分配存在开销，偏离了我们提出的高性能的目的。\n2. gpt在代码设计中，为了保障线程安全的要求，使用了互斥锁，这一块是可以优化的，可以通过原子变量的CAS操作来规避掉锁的开销。\n# 3 Gpt的第二轮尝试\n## 3.1 对功能修改的描述\n```cpp\n目前代码存在一些问题，考虑针对以下点进行优化：\n1.由于采用deque的数据结构，导致存在动态分配内存的开销\n2.mutex互斥锁的存在降低了效率，能否通过原子变量实现无锁操作\n```\n## 3.2 Gpt给出的结果\n```cpp\n#include <iostream>\n#include <vector>\n#include <atomic>\n#include <condition_variable>\n#include <thread>\n\ntemplate <typename T>\nclass ThreadSafeQueue {\npublic:\n    explicit ThreadSafeQueue(size_t capacity) : capacity_(capacity), head_(0), tail_(0) {\n        data_.resize(capacity);\n    }\n\n    // 阻塞写入队列\n    void Enqueue(const T& item) {\n        while (true) {\n            size_t currentTail = tail_.load(std::memory_order_relaxed);\n            size_t nextTail = (currentTail + 1) % capacity_;\n\n            if (nextTail != head_.load(std::memory_order_acquire)) {\n                data_[currentTail] = item;\n                tail_.store(nextTail, std::memory_order_release);\n                return;\n            }\n            // 队列已满，等待\n            std::this_thread::yield();\n        }\n    }\n\n    // 非阻塞写入队列\n    bool TryEnqueue(const T& item) {\n        size_t currentTail = tail_.load(std::memory_order_relaxed);\n        size_t nextTail = (currentTail + 1) % capacity_;\n\n        if (nextTail != head_.load(std::memory_order_acquire)) {\n            data_[currentTail] = item;\n            tail_.store(nextTail, std::memory_order_release);\n            return true;\n        }\n        return false;\n    }\n\n    // 阻塞读取队列\n    T Dequeue() {\n        while (true) {\n            size_t currentHead = head_.load(std::memory_order_relaxed);\n            size_t currentTail = tail_.load(std::memory_order_acquire);\n\n            if (currentHead != currentTail) {\n                T item = data_[currentHead];\n                head_.store((currentHead + 1) % capacity_, std::memory_order_release);\n                return item;\n            }\n            // 队列为空，等待\n            std::this_thread::yield();\n        }\n    }\n\n    // 非阻塞读取队列\n    bool TryDequeue(T& item) {\n        size_t currentHead = head_.load(std::memory_order_relaxed);\n        size_t currentTail = tail_.load(std::memory_order_acquire);\n\n        if (currentHead != currentTail) {\n            item = data_[currentHead];\n            head_.store((currentHead + 1) % capacity_, std::memory_order_release);\n            return true;\n        }\n        return false;\n    }\n\nprivate:\n    size_t capacity_;\n    std::vector<T> data_;\n    std::atomic<size_t> head_;\n    std::atomic<size_t> tail_;\n};\n```\n## 3.3 对代码的分析\n从这轮优化中粗看，gpt已经修复了上文中提到的两个问题，使用了std::atomic来管理head_和tail_，并通过原子操作实现队列的无锁操作。在阻塞写入和读取的过程中，移除了两个条件变量，使用std::this_thread::yield()来让出CPU。\n可以简单分析一下，这轮优化过程中使用到的一些知识点：\n### 3.3.1 为什么舍弃条件变量\n**std::condition_variable** 是 C++ 标准库中的一个多线程同步工具，用于在多个线程之间进行条件同步。采用**condition_variable** 主动来实现线程的等待和唤醒机制显然比盲目地std::this_thread::yield()让出时间片更为合理，如果在阻塞写或者阻塞读的情况下，有可能造成频繁的线程切换，造成开销。\n但是**condition_variable** 必须搭配mutex使用，在我们限定无锁编程的情况下，**condition_variable** 显然是无法被采用的，所以被舍弃了。\n### 3.3.2 阻塞写时安全性论证\n```cpp\nvoid Enqueue(const T& item) {\n    while (true) {\n        size_t currentTail = tail_.load(std::memory_order_relaxed);\n        size_t nextTail = (currentTail + 1) % capacity_;\n        if (nextTail != head_.load(std::memory_order_acquire)) {\n            data_[currentTail] = item;\n            tail_.store(nextTail, std::memory_order_release);\n            return;\n        }\n        // 队列已满，等待\n        std::this_thread::yield();\n    }\n}\n```\n这是gpt给出的代码，如我们提示的那样使用上了原子变量，试图通过内存序来保障读写之间的安全性。但是很明显，这段代码是在多写情况下是线程不安全的。\n**错误一：**\n下面的两行代码之间不是原子的，多个线程在同一时刻可能读取相同的 tail_ 值，然后计算出相同的 nextTail，这可能导致它们尝试在相同的位置写入数据，从而导致数据覆盖。\n```cpp\nsize_t currentTail = tail_.load(std::memory_order_relaxed);\nsize_t nextTail = (currentTail + 1) % capacity_;\n```\n**错误二：**\n虽然 head_ 的加载使用了 memory_order_acquire，但是在实际的操作中，其他线程可能在这段时间内修改了 head_ 的值，导致脏读的出现，从而导致判断错误。\n```cpp\nif (nextTail != head_.load(std::memory_order_acquire)) {\n\tdata_[currentTail] = item;\n\t// something else\n}\n```\n所以从上面指出的这两个错误来看，这部分代码存在着比较致命的问题。\n# 4 Gpt的第三轮尝试\n## 4.1 对功能修改的描述\n```cpp\n目前代码存在一些问题，考虑针对以下点进行优化：\n1.目前代码面对多线程写入的场景时，因为临界区的存在，存在不安全的问题，考虑用CAS操作进行优化\n```\n## 4.2 Gpt给出的结果\n```cpp\n#include <iostream>\n#include <vector>\n#include <atomic>\n#include <condition_variable>\n#include <thread>\n\ntemplate <typename T>\nclass ThreadSafeQueue {\npublic:\n    explicit ThreadSafeQueue(size_t capacity) : capacity_(capacity), head_(0), tail_(0) {\n        data_.resize(capacity);\n    }\n\n    // 阻塞写入队列\n    void Enqueue(const T& item) {\n        size_t currentTail;\n        size_t nextTail;\n\n        do {\n            currentTail = tail_.load(std::memory_order_relaxed);\n            nextTail = (currentTail + 1) % capacity_;\n\n            if (nextTail == head_.load(std::memory_order_acquire)) {\n                // 队列已满，等待\n                std::this_thread::yield();\n                continue;\n            }\n\n            // 尝试使用CAS进行原子操作\n        } while (!tail_.compare_exchange_weak(currentTail, nextTail, std::memory_order_acq_rel));\n\n        // CAS成功，可以进行写入操作\n        data_[currentTail] = item;\n    }\n\n    // 非阻塞写入队列\n    bool TryEnqueue(const T& item) {\n        size_t currentTail = tail_.load(std::memory_order_relaxed);\n        size_t nextTail = (currentTail + 1) % capacity_;\n\n        if (nextTail == head_.load(std::memory_order_acquire))\n            return false;\n\n        if (tail_.compare_exchange_weak(currentTail, nextTail, std::memory_order_acq_rel)) {\n            // CAS成功，可以进行写入操作\n            data_[currentTail] = item;\n            return true;\n        }\n\n        return false;\n    }\n\n    // 阻塞读取队列\n    T Dequeue() {\n        size_t currentHead;\n        size_t currentTail;\n\n        do {\n            currentHead = head_.load(std::memory_order_relaxed);\n            currentTail = tail_.load(std::memory_order_acquire);\n\n            if (currentHead == currentTail) {\n                // 队列为空，等待\n                std::this_thread::yield();\n                continue;\n            }\n\n            // 尝试使用CAS进行原子操作\n        } while (!head_.compare_exchange_weak(currentHead, (currentHead + 1) % capacity_, std::memory_order_acq_rel));\n\n        // CAS成功，可以进行读取操作\n        return data_[currentHead];\n    }\n\n    // 非阻塞读取队列\n    bool TryDequeue(T& item) {\n        size_t currentHead = head_.load(std::memory_order_relaxed);\n        size_t currentTail = tail_.load(std::memory_order_acquire);\n\n        if (currentHead == currentTail)\n            return false;\n\n        if (head_.compare_exchange_weak(currentHead, (currentHead + 1) % capacity_, std::memory_order_acq_rel)) {\n            // CAS成功，可以进行读取操作\n            item = data_[currentHead];\n            return true;\n        }\n\n        return false;\n    }\n\nprivate:\n    size_t capacity_;\n    std::vector<T> data_;\n    std::atomic<size_t> head_;\n    std::atomic<size_t> tail_;\n};\n\n```\n## 4.3 对代码的分析\n我们回到上文中有问题的函数，经过更新之后的代码片段如下所示：\n```cpp\nvoid Enqueue(const T& item) {\n    size_t currentTail;\n    size_t nextTail;\n    do {\n        currentTail = tail_.load(std::memory_order_relaxed);\n        nextTail = (currentTail + 1) % capacity_;\n        if (nextTail == head_.load(std::memory_order_acquire)) {\n            // 队列已满，等待\n            std::this_thread::yield();\n            continue;\n        }\n        // 尝试使用CAS进行原子操作\n    } while (!tail_.compare_exchange_weak(currentTail, nextTail, std::memory_order_acq_rel));\n    // CAS成功，可以进行写入操作\n    data_[currentTail] = item;\n}\n```\n在这个函数内部，如我们提示的那样，将尾指针移动的逻辑包裹在了一个compare_exchange_weak操作的内部，如果当前内存中的tail_变量与我们预期的currentTail不一样，则重新load，重新计算nextTail，如果和预期的一致，则更新tail_为nextTail。","source":"_posts/Thread-safe-circular-queue.md","raw":"---\ntitle: 线程安全的循环队列\ndate: 2023-12-28 13:30:34\ntags: \n- Gpt\n- Cpp\n---\n\n尝试了和ChatGtp进行合作开发,使用合适的prompt逐步修正结果，得到一个初步符合我们预期的循环队列。\n# 1 需求的自然语言描述\n用C++ 20的语言标准，实现线程安全的循环队列，提供详细注释\n具体要求如下：\n1、环形队列要支持阻塞读和非阻塞读，阻塞写和非阻塞写\n2、支持模板，存放的数据类型可以自定义\n3、代码风格使用google C++风格\n4、在开发中尽可能提高队列的性能，并说明采取了哪些手段提高性能，说明理由\n# 2 Gpt第一轮尝试\n## 2.1 Gpt给出的结果\n```cpp\n#include <iostream>\n#include <queue>\n#include <mutex>\n#include <condition_variable>\n#include <thread>\n\n// 线程安全的循环队列模板\ntemplate <typename T>\nclass ThreadSafeQueue {\npublic:\n    explicit ThreadSafeQueue(size_t capacity) : capacity_(capacity) {}\n\n    // 阻塞写入队列\n    void Enqueue(const T& item) {\n        std::unique_lock<std::mutex> lock(mutex_);\n        // 使用条件变量等待队列不满\n        notFull_.wait(lock, [this] { return queue_.size() < capacity_; });\n        queue_.push(item);\n        lock.unlock();\n        // 通知等待的线程队列不为空\n        notEmpty_.notify_one();\n    }\n\n    // 非阻塞写入队列\n    bool TryEnqueue(const T& item) {\n        std::lock_guard<std::mutex> lock(mutex_);\n        if (queue_.size() < capacity_) {\n            queue_.push(item);\n            // 通知等待的线程队列不为空\n            notEmpty_.notify_one();\n            return true;\n        }\n        return false;\n    }\n\n    // 阻塞读取队列\n    T Dequeue() {\n        std::unique_lock<std::mutex> lock(mutex_);\n        // 使用条件变量等待队列不空\n        notEmpty_.wait(lock, [this] { return !queue_.empty(); });\n        T item = queue_.front();\n        queue_.pop();\n        lock.unlock();\n        // 通知等待的线程队列不满\n        notFull_.notify_one();\n        return item;\n    }\n\n    // 非阻塞读取队列\n    bool TryDequeue(T& item) {\n        std::lock_guard<std::mutex> lock(mutex_);\n        if (!queue_.empty()) {\n            item = queue_.front();\n            queue_.pop();\n            // 通知等待的线程队列不满\n            notFull_.notify_one();\n            return true;\n        }\n        return false;\n    }\n\nprivate:\n    size_t capacity_;\n    std::queue<T> queue_;\n    std::mutex mutex_;\n    std::condition_variable notFull_;\n    std::condition_variable notEmpty_;\n};\n```\n## 2.2 对代码的分析\n代码最低限度地实现了我们提出的需求，比如阻塞/非阻塞读写、支持模板、代码风格等。但是代码中存在着许多显而易见的问题。\n\n1. 可能是我使用的“队列”一词对gpt造成了先入为主的印象，导致它在数据结构上采用了deque的结构，当deque需要增长时，它会分配一个新的内存块，并将其链接到现有的块，这样一个动态的结构天生会对内存的分配存在开销，偏离了我们提出的高性能的目的。\n2. gpt在代码设计中，为了保障线程安全的要求，使用了互斥锁，这一块是可以优化的，可以通过原子变量的CAS操作来规避掉锁的开销。\n# 3 Gpt的第二轮尝试\n## 3.1 对功能修改的描述\n```cpp\n目前代码存在一些问题，考虑针对以下点进行优化：\n1.由于采用deque的数据结构，导致存在动态分配内存的开销\n2.mutex互斥锁的存在降低了效率，能否通过原子变量实现无锁操作\n```\n## 3.2 Gpt给出的结果\n```cpp\n#include <iostream>\n#include <vector>\n#include <atomic>\n#include <condition_variable>\n#include <thread>\n\ntemplate <typename T>\nclass ThreadSafeQueue {\npublic:\n    explicit ThreadSafeQueue(size_t capacity) : capacity_(capacity), head_(0), tail_(0) {\n        data_.resize(capacity);\n    }\n\n    // 阻塞写入队列\n    void Enqueue(const T& item) {\n        while (true) {\n            size_t currentTail = tail_.load(std::memory_order_relaxed);\n            size_t nextTail = (currentTail + 1) % capacity_;\n\n            if (nextTail != head_.load(std::memory_order_acquire)) {\n                data_[currentTail] = item;\n                tail_.store(nextTail, std::memory_order_release);\n                return;\n            }\n            // 队列已满，等待\n            std::this_thread::yield();\n        }\n    }\n\n    // 非阻塞写入队列\n    bool TryEnqueue(const T& item) {\n        size_t currentTail = tail_.load(std::memory_order_relaxed);\n        size_t nextTail = (currentTail + 1) % capacity_;\n\n        if (nextTail != head_.load(std::memory_order_acquire)) {\n            data_[currentTail] = item;\n            tail_.store(nextTail, std::memory_order_release);\n            return true;\n        }\n        return false;\n    }\n\n    // 阻塞读取队列\n    T Dequeue() {\n        while (true) {\n            size_t currentHead = head_.load(std::memory_order_relaxed);\n            size_t currentTail = tail_.load(std::memory_order_acquire);\n\n            if (currentHead != currentTail) {\n                T item = data_[currentHead];\n                head_.store((currentHead + 1) % capacity_, std::memory_order_release);\n                return item;\n            }\n            // 队列为空，等待\n            std::this_thread::yield();\n        }\n    }\n\n    // 非阻塞读取队列\n    bool TryDequeue(T& item) {\n        size_t currentHead = head_.load(std::memory_order_relaxed);\n        size_t currentTail = tail_.load(std::memory_order_acquire);\n\n        if (currentHead != currentTail) {\n            item = data_[currentHead];\n            head_.store((currentHead + 1) % capacity_, std::memory_order_release);\n            return true;\n        }\n        return false;\n    }\n\nprivate:\n    size_t capacity_;\n    std::vector<T> data_;\n    std::atomic<size_t> head_;\n    std::atomic<size_t> tail_;\n};\n```\n## 3.3 对代码的分析\n从这轮优化中粗看，gpt已经修复了上文中提到的两个问题，使用了std::atomic来管理head_和tail_，并通过原子操作实现队列的无锁操作。在阻塞写入和读取的过程中，移除了两个条件变量，使用std::this_thread::yield()来让出CPU。\n可以简单分析一下，这轮优化过程中使用到的一些知识点：\n### 3.3.1 为什么舍弃条件变量\n**std::condition_variable** 是 C++ 标准库中的一个多线程同步工具，用于在多个线程之间进行条件同步。采用**condition_variable** 主动来实现线程的等待和唤醒机制显然比盲目地std::this_thread::yield()让出时间片更为合理，如果在阻塞写或者阻塞读的情况下，有可能造成频繁的线程切换，造成开销。\n但是**condition_variable** 必须搭配mutex使用，在我们限定无锁编程的情况下，**condition_variable** 显然是无法被采用的，所以被舍弃了。\n### 3.3.2 阻塞写时安全性论证\n```cpp\nvoid Enqueue(const T& item) {\n    while (true) {\n        size_t currentTail = tail_.load(std::memory_order_relaxed);\n        size_t nextTail = (currentTail + 1) % capacity_;\n        if (nextTail != head_.load(std::memory_order_acquire)) {\n            data_[currentTail] = item;\n            tail_.store(nextTail, std::memory_order_release);\n            return;\n        }\n        // 队列已满，等待\n        std::this_thread::yield();\n    }\n}\n```\n这是gpt给出的代码，如我们提示的那样使用上了原子变量，试图通过内存序来保障读写之间的安全性。但是很明显，这段代码是在多写情况下是线程不安全的。\n**错误一：**\n下面的两行代码之间不是原子的，多个线程在同一时刻可能读取相同的 tail_ 值，然后计算出相同的 nextTail，这可能导致它们尝试在相同的位置写入数据，从而导致数据覆盖。\n```cpp\nsize_t currentTail = tail_.load(std::memory_order_relaxed);\nsize_t nextTail = (currentTail + 1) % capacity_;\n```\n**错误二：**\n虽然 head_ 的加载使用了 memory_order_acquire，但是在实际的操作中，其他线程可能在这段时间内修改了 head_ 的值，导致脏读的出现，从而导致判断错误。\n```cpp\nif (nextTail != head_.load(std::memory_order_acquire)) {\n\tdata_[currentTail] = item;\n\t// something else\n}\n```\n所以从上面指出的这两个错误来看，这部分代码存在着比较致命的问题。\n# 4 Gpt的第三轮尝试\n## 4.1 对功能修改的描述\n```cpp\n目前代码存在一些问题，考虑针对以下点进行优化：\n1.目前代码面对多线程写入的场景时，因为临界区的存在，存在不安全的问题，考虑用CAS操作进行优化\n```\n## 4.2 Gpt给出的结果\n```cpp\n#include <iostream>\n#include <vector>\n#include <atomic>\n#include <condition_variable>\n#include <thread>\n\ntemplate <typename T>\nclass ThreadSafeQueue {\npublic:\n    explicit ThreadSafeQueue(size_t capacity) : capacity_(capacity), head_(0), tail_(0) {\n        data_.resize(capacity);\n    }\n\n    // 阻塞写入队列\n    void Enqueue(const T& item) {\n        size_t currentTail;\n        size_t nextTail;\n\n        do {\n            currentTail = tail_.load(std::memory_order_relaxed);\n            nextTail = (currentTail + 1) % capacity_;\n\n            if (nextTail == head_.load(std::memory_order_acquire)) {\n                // 队列已满，等待\n                std::this_thread::yield();\n                continue;\n            }\n\n            // 尝试使用CAS进行原子操作\n        } while (!tail_.compare_exchange_weak(currentTail, nextTail, std::memory_order_acq_rel));\n\n        // CAS成功，可以进行写入操作\n        data_[currentTail] = item;\n    }\n\n    // 非阻塞写入队列\n    bool TryEnqueue(const T& item) {\n        size_t currentTail = tail_.load(std::memory_order_relaxed);\n        size_t nextTail = (currentTail + 1) % capacity_;\n\n        if (nextTail == head_.load(std::memory_order_acquire))\n            return false;\n\n        if (tail_.compare_exchange_weak(currentTail, nextTail, std::memory_order_acq_rel)) {\n            // CAS成功，可以进行写入操作\n            data_[currentTail] = item;\n            return true;\n        }\n\n        return false;\n    }\n\n    // 阻塞读取队列\n    T Dequeue() {\n        size_t currentHead;\n        size_t currentTail;\n\n        do {\n            currentHead = head_.load(std::memory_order_relaxed);\n            currentTail = tail_.load(std::memory_order_acquire);\n\n            if (currentHead == currentTail) {\n                // 队列为空，等待\n                std::this_thread::yield();\n                continue;\n            }\n\n            // 尝试使用CAS进行原子操作\n        } while (!head_.compare_exchange_weak(currentHead, (currentHead + 1) % capacity_, std::memory_order_acq_rel));\n\n        // CAS成功，可以进行读取操作\n        return data_[currentHead];\n    }\n\n    // 非阻塞读取队列\n    bool TryDequeue(T& item) {\n        size_t currentHead = head_.load(std::memory_order_relaxed);\n        size_t currentTail = tail_.load(std::memory_order_acquire);\n\n        if (currentHead == currentTail)\n            return false;\n\n        if (head_.compare_exchange_weak(currentHead, (currentHead + 1) % capacity_, std::memory_order_acq_rel)) {\n            // CAS成功，可以进行读取操作\n            item = data_[currentHead];\n            return true;\n        }\n\n        return false;\n    }\n\nprivate:\n    size_t capacity_;\n    std::vector<T> data_;\n    std::atomic<size_t> head_;\n    std::atomic<size_t> tail_;\n};\n\n```\n## 4.3 对代码的分析\n我们回到上文中有问题的函数，经过更新之后的代码片段如下所示：\n```cpp\nvoid Enqueue(const T& item) {\n    size_t currentTail;\n    size_t nextTail;\n    do {\n        currentTail = tail_.load(std::memory_order_relaxed);\n        nextTail = (currentTail + 1) % capacity_;\n        if (nextTail == head_.load(std::memory_order_acquire)) {\n            // 队列已满，等待\n            std::this_thread::yield();\n            continue;\n        }\n        // 尝试使用CAS进行原子操作\n    } while (!tail_.compare_exchange_weak(currentTail, nextTail, std::memory_order_acq_rel));\n    // CAS成功，可以进行写入操作\n    data_[currentTail] = item;\n}\n```\n在这个函数内部，如我们提示的那样，将尾指针移动的逻辑包裹在了一个compare_exchange_weak操作的内部，如果当前内存中的tail_变量与我们预期的currentTail不一样，则重新load，重新计算nextTail，如果和预期的一致，则更新tail_为nextTail。","slug":"Thread-safe-circular-queue","published":1,"updated":"2024-01-19T01:22:42.463Z","_id":"clrhz6rwv000d0ox53yrbdp5h","comments":1,"layout":"post","photos":[],"link":"","content":"<p>尝试了和ChatGtp进行合作开发,使用合适的prompt逐步修正结果，得到一个初步符合我们预期的循环队列。</p>\n<h1 id=\"1-需求的自然语言描述\"><a href=\"#1-需求的自然语言描述\" class=\"headerlink\" title=\"1 需求的自然语言描述\"></a>1 需求的自然语言描述</h1><p>用C++ 20的语言标准，实现线程安全的循环队列，提供详细注释<br>具体要求如下：<br>1、环形队列要支持阻塞读和非阻塞读，阻塞写和非阻塞写<br>2、支持模板，存放的数据类型可以自定义<br>3、代码风格使用google C++风格<br>4、在开发中尽可能提高队列的性能，并说明采取了哪些手段提高性能，说明理由</p>\n<h1 id=\"2-Gpt第一轮尝试\"><a href=\"#2-Gpt第一轮尝试\" class=\"headerlink\" title=\"2 Gpt第一轮尝试\"></a>2 Gpt第一轮尝试</h1><h2 id=\"2-1-Gpt给出的结果\"><a href=\"#2-1-Gpt给出的结果\" class=\"headerlink\" title=\"2.1 Gpt给出的结果\"></a>2.1 Gpt给出的结果</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;queue&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;mutex&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;condition_variable&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;thread&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 线程安全的循环队列模板</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">ThreadSafeQueue</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">explicit</span> <span class=\"title\">ThreadSafeQueue</span><span class=\"params\">(<span class=\"type\">size_t</span> capacity)</span> : capacity_(capacity) &#123;</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 阻塞写入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">Enqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"comment\">// 使用条件变量等待队列不满</span></span><br><span class=\"line\">        notFull_.<span class=\"built_in\">wait</span>(lock, [<span class=\"keyword\">this</span>] &#123; <span class=\"keyword\">return</span> queue_.<span class=\"built_in\">size</span>() &lt; capacity_; &#125;);</span><br><span class=\"line\">        queue_.<span class=\"built_in\">push</span>(item);</span><br><span class=\"line\">        lock.<span class=\"built_in\">unlock</span>();</span><br><span class=\"line\">        <span class=\"comment\">// 通知等待的线程队列不为空</span></span><br><span class=\"line\">        notEmpty_.<span class=\"built_in\">notify_one</span>();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 非阻塞写入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">TryEnqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"function\">std::lock_guard&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (queue_.<span class=\"built_in\">size</span>() &lt; capacity_) &#123;</span><br><span class=\"line\">            queue_.<span class=\"built_in\">push</span>(item);</span><br><span class=\"line\">            <span class=\"comment\">// 通知等待的线程队列不为空</span></span><br><span class=\"line\">            notEmpty_.<span class=\"built_in\">notify_one</span>();</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 阻塞读取队列</span></span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">Dequeue</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"comment\">// 使用条件变量等待队列不空</span></span><br><span class=\"line\">        notEmpty_.<span class=\"built_in\">wait</span>(lock, [<span class=\"keyword\">this</span>] &#123; <span class=\"keyword\">return</span> !queue_.<span class=\"built_in\">empty</span>(); &#125;);</span><br><span class=\"line\">        T item = queue_.<span class=\"built_in\">front</span>();</span><br><span class=\"line\">        queue_.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">        lock.<span class=\"built_in\">unlock</span>();</span><br><span class=\"line\">        <span class=\"comment\">// 通知等待的线程队列不满</span></span><br><span class=\"line\">        notFull_.<span class=\"built_in\">notify_one</span>();</span><br><span class=\"line\">        <span class=\"keyword\">return</span> item;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 非阻塞读取队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">TryDequeue</span><span class=\"params\">(T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"function\">std::lock_guard&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!queue_.<span class=\"built_in\">empty</span>()) &#123;</span><br><span class=\"line\">            item = queue_.<span class=\"built_in\">front</span>();</span><br><span class=\"line\">            queue_.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">            <span class=\"comment\">// 通知等待的线程队列不满</span></span><br><span class=\"line\">            notFull_.<span class=\"built_in\">notify_one</span>();</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"type\">size_t</span> capacity_;</span><br><span class=\"line\">    std::queue&lt;T&gt; queue_;</span><br><span class=\"line\">    std::mutex mutex_;</span><br><span class=\"line\">    std::condition_variable notFull_;</span><br><span class=\"line\">    std::condition_variable notEmpty_;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-2-对代码的分析\"><a href=\"#2-2-对代码的分析\" class=\"headerlink\" title=\"2.2 对代码的分析\"></a>2.2 对代码的分析</h2><p>代码最低限度地实现了我们提出的需求，比如阻塞&#x2F;非阻塞读写、支持模板、代码风格等。但是代码中存在着许多显而易见的问题。</p>\n<ol>\n<li>可能是我使用的“队列”一词对gpt造成了先入为主的印象，导致它在数据结构上采用了deque的结构，当deque需要增长时，它会分配一个新的内存块，并将其链接到现有的块，这样一个动态的结构天生会对内存的分配存在开销，偏离了我们提出的高性能的目的。</li>\n<li>gpt在代码设计中，为了保障线程安全的要求，使用了互斥锁，这一块是可以优化的，可以通过原子变量的CAS操作来规避掉锁的开销。</li>\n</ol>\n<h1 id=\"3-Gpt的第二轮尝试\"><a href=\"#3-Gpt的第二轮尝试\" class=\"headerlink\" title=\"3 Gpt的第二轮尝试\"></a>3 Gpt的第二轮尝试</h1><h2 id=\"3-1-对功能修改的描述\"><a href=\"#3-1-对功能修改的描述\" class=\"headerlink\" title=\"3.1 对功能修改的描述\"></a>3.1 对功能修改的描述</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">目前代码存在一些问题，考虑针对以下点进行优化：</span><br><span class=\"line\"><span class=\"number\">1.</span>由于采用deque的数据结构，导致存在动态分配内存的开销</span><br><span class=\"line\"><span class=\"number\">2.</span>mutex互斥锁的存在降低了效率，能否通过原子变量实现无锁操作</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-2-Gpt给出的结果\"><a href=\"#3-2-Gpt给出的结果\" class=\"headerlink\" title=\"3.2 Gpt给出的结果\"></a>3.2 Gpt给出的结果</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;vector&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;atomic&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;condition_variable&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;thread&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">ThreadSafeQueue</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">explicit</span> <span class=\"title\">ThreadSafeQueue</span><span class=\"params\">(<span class=\"type\">size_t</span> capacity)</span> : capacity_(capacity), head_(<span class=\"number\">0</span>), tail_(<span class=\"number\">0</span>) &#123;</span></span><br><span class=\"line\">        data_.<span class=\"built_in\">resize</span>(capacity);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 阻塞写入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">Enqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">            <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">            <span class=\"type\">size_t</span> nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (nextTail != head_.<span class=\"built_in\">load</span>(std::memory_order_acquire)) &#123;</span><br><span class=\"line\">                data_[currentTail] = item;</span><br><span class=\"line\">                tail_.<span class=\"built_in\">store</span>(nextTail, std::memory_order_release);</span><br><span class=\"line\">                <span class=\"keyword\">return</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">// 队列已满，等待</span></span><br><span class=\"line\">            std::this_thread::<span class=\"built_in\">yield</span>();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 非阻塞写入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">TryEnqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">        <span class=\"type\">size_t</span> nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (nextTail != head_.<span class=\"built_in\">load</span>(std::memory_order_acquire)) &#123;</span><br><span class=\"line\">            data_[currentTail] = item;</span><br><span class=\"line\">            tail_.<span class=\"built_in\">store</span>(nextTail, std::memory_order_release);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 阻塞读取队列</span></span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">Dequeue</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">            <span class=\"type\">size_t</span> currentHead = head_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">            <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_acquire);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (currentHead != currentTail) &#123;</span><br><span class=\"line\">                T item = data_[currentHead];</span><br><span class=\"line\">                head_.<span class=\"built_in\">store</span>((currentHead + <span class=\"number\">1</span>) % capacity_, std::memory_order_release);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> item;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">// 队列为空，等待</span></span><br><span class=\"line\">            std::this_thread::<span class=\"built_in\">yield</span>();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 非阻塞读取队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">TryDequeue</span><span class=\"params\">(T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentHead = head_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_acquire);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (currentHead != currentTail) &#123;</span><br><span class=\"line\">            item = data_[currentHead];</span><br><span class=\"line\">            head_.<span class=\"built_in\">store</span>((currentHead + <span class=\"number\">1</span>) % capacity_, std::memory_order_release);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"type\">size_t</span> capacity_;</span><br><span class=\"line\">    std::vector&lt;T&gt; data_;</span><br><span class=\"line\">    std::atomic&lt;<span class=\"type\">size_t</span>&gt; head_;</span><br><span class=\"line\">    std::atomic&lt;<span class=\"type\">size_t</span>&gt; tail_;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-3-对代码的分析\"><a href=\"#3-3-对代码的分析\" class=\"headerlink\" title=\"3.3 对代码的分析\"></a>3.3 对代码的分析</h2><p>从这轮优化中粗看，gpt已经修复了上文中提到的两个问题，使用了std::atomic来管理head_和tail_，并通过原子操作实现队列的无锁操作。在阻塞写入和读取的过程中，移除了两个条件变量，使用std::this_thread::yield()来让出CPU。<br>可以简单分析一下，这轮优化过程中使用到的一些知识点：</p>\n<h3 id=\"3-3-1-为什么舍弃条件变量\"><a href=\"#3-3-1-为什么舍弃条件变量\" class=\"headerlink\" title=\"3.3.1 为什么舍弃条件变量\"></a>3.3.1 为什么舍弃条件变量</h3><p><strong>std::condition_variable</strong> 是 C++ 标准库中的一个多线程同步工具，用于在多个线程之间进行条件同步。采用<strong>condition_variable</strong> 主动来实现线程的等待和唤醒机制显然比盲目地std::this_thread::yield()让出时间片更为合理，如果在阻塞写或者阻塞读的情况下，有可能造成频繁的线程切换，造成开销。<br>但是<strong>condition_variable</strong> 必须搭配mutex使用，在我们限定无锁编程的情况下，<strong>condition_variable</strong> 显然是无法被采用的，所以被舍弃了。</p>\n<h3 id=\"3-3-2-阻塞写时安全性论证\"><a href=\"#3-3-2-阻塞写时安全性论证\" class=\"headerlink\" title=\"3.3.2 阻塞写时安全性论证\"></a>3.3.2 阻塞写时安全性论证</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">Enqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">        <span class=\"type\">size_t</span> nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (nextTail != head_.<span class=\"built_in\">load</span>(std::memory_order_acquire)) &#123;</span><br><span class=\"line\">            data_[currentTail] = item;</span><br><span class=\"line\">            tail_.<span class=\"built_in\">store</span>(nextTail, std::memory_order_release);</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 队列已满，等待</span></span><br><span class=\"line\">        std::this_thread::<span class=\"built_in\">yield</span>();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这是gpt给出的代码，如我们提示的那样使用上了原子变量，试图通过内存序来保障读写之间的安全性。但是很明显，这段代码是在多写情况下是线程不安全的。<br><strong>错误一：</strong><br>下面的两行代码之间不是原子的，多个线程在同一时刻可能读取相同的 tail_ 值，然后计算出相同的 nextTail，这可能导致它们尝试在相同的位置写入数据，从而导致数据覆盖。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\"><span class=\"type\">size_t</span> nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br></pre></td></tr></table></figure>\n<p><strong>错误二：</strong><br>虽然 head_ 的加载使用了 memory_order_acquire，但是在实际的操作中，其他线程可能在这段时间内修改了 head_ 的值，导致脏读的出现，从而导致判断错误。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (nextTail != head_.<span class=\"built_in\">load</span>(std::memory_order_acquire)) &#123;</span><br><span class=\"line\">\tdata_[currentTail] = item;</span><br><span class=\"line\">\t<span class=\"comment\">// something else</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>所以从上面指出的这两个错误来看，这部分代码存在着比较致命的问题。</p>\n<h1 id=\"4-Gpt的第三轮尝试\"><a href=\"#4-Gpt的第三轮尝试\" class=\"headerlink\" title=\"4 Gpt的第三轮尝试\"></a>4 Gpt的第三轮尝试</h1><h2 id=\"4-1-对功能修改的描述\"><a href=\"#4-1-对功能修改的描述\" class=\"headerlink\" title=\"4.1 对功能修改的描述\"></a>4.1 对功能修改的描述</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">目前代码存在一些问题，考虑针对以下点进行优化：</span><br><span class=\"line\"><span class=\"number\">1.</span>目前代码面对多线程写入的场景时，因为临界区的存在，存在不安全的问题，考虑用CAS操作进行优化</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-2-Gpt给出的结果\"><a href=\"#4-2-Gpt给出的结果\" class=\"headerlink\" title=\"4.2 Gpt给出的结果\"></a>4.2 Gpt给出的结果</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;vector&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;atomic&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;condition_variable&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;thread&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">ThreadSafeQueue</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">explicit</span> <span class=\"title\">ThreadSafeQueue</span><span class=\"params\">(<span class=\"type\">size_t</span> capacity)</span> : capacity_(capacity), head_(<span class=\"number\">0</span>), tail_(<span class=\"number\">0</span>) &#123;</span></span><br><span class=\"line\">        data_.<span class=\"built_in\">resize</span>(capacity);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 阻塞写入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">Enqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> nextTail;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">do</span> &#123;</span><br><span class=\"line\">            currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">            nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (nextTail == head_.<span class=\"built_in\">load</span>(std::memory_order_acquire)) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 队列已满，等待</span></span><br><span class=\"line\">                std::this_thread::<span class=\"built_in\">yield</span>();</span><br><span class=\"line\">                <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">// 尝试使用CAS进行原子操作</span></span><br><span class=\"line\">        &#125; <span class=\"keyword\">while</span> (!tail_.<span class=\"built_in\">compare_exchange_weak</span>(currentTail, nextTail, std::memory_order_acq_rel));</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// CAS成功，可以进行写入操作</span></span><br><span class=\"line\">        data_[currentTail] = item;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 非阻塞写入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">TryEnqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">        <span class=\"type\">size_t</span> nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (nextTail == head_.<span class=\"built_in\">load</span>(std::memory_order_acquire))</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (tail_.<span class=\"built_in\">compare_exchange_weak</span>(currentTail, nextTail, std::memory_order_acq_rel)) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// CAS成功，可以进行写入操作</span></span><br><span class=\"line\">            data_[currentTail] = item;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 阻塞读取队列</span></span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">Dequeue</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentHead;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">do</span> &#123;</span><br><span class=\"line\">            currentHead = head_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">            currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_acquire);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (currentHead == currentTail) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 队列为空，等待</span></span><br><span class=\"line\">                std::this_thread::<span class=\"built_in\">yield</span>();</span><br><span class=\"line\">                <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">// 尝试使用CAS进行原子操作</span></span><br><span class=\"line\">        &#125; <span class=\"keyword\">while</span> (!head_.<span class=\"built_in\">compare_exchange_weak</span>(currentHead, (currentHead + <span class=\"number\">1</span>) % capacity_, std::memory_order_acq_rel));</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// CAS成功，可以进行读取操作</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> data_[currentHead];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 非阻塞读取队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">TryDequeue</span><span class=\"params\">(T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentHead = head_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_acquire);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (currentHead == currentTail)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (head_.<span class=\"built_in\">compare_exchange_weak</span>(currentHead, (currentHead + <span class=\"number\">1</span>) % capacity_, std::memory_order_acq_rel)) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// CAS成功，可以进行读取操作</span></span><br><span class=\"line\">            item = data_[currentHead];</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"type\">size_t</span> capacity_;</span><br><span class=\"line\">    std::vector&lt;T&gt; data_;</span><br><span class=\"line\">    std::atomic&lt;<span class=\"type\">size_t</span>&gt; head_;</span><br><span class=\"line\">    std::atomic&lt;<span class=\"type\">size_t</span>&gt; tail_;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h2 id=\"4-3-对代码的分析\"><a href=\"#4-3-对代码的分析\" class=\"headerlink\" title=\"4.3 对代码的分析\"></a>4.3 对代码的分析</h2><p>我们回到上文中有问题的函数，经过更新之后的代码片段如下所示：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">Enqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"type\">size_t</span> currentTail;</span><br><span class=\"line\">    <span class=\"type\">size_t</span> nextTail;</span><br><span class=\"line\">    <span class=\"keyword\">do</span> &#123;</span><br><span class=\"line\">        currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">        nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (nextTail == head_.<span class=\"built_in\">load</span>(std::memory_order_acquire)) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 队列已满，等待</span></span><br><span class=\"line\">            std::this_thread::<span class=\"built_in\">yield</span>();</span><br><span class=\"line\">            <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 尝试使用CAS进行原子操作</span></span><br><span class=\"line\">    &#125; <span class=\"keyword\">while</span> (!tail_.<span class=\"built_in\">compare_exchange_weak</span>(currentTail, nextTail, std::memory_order_acq_rel));</span><br><span class=\"line\">    <span class=\"comment\">// CAS成功，可以进行写入操作</span></span><br><span class=\"line\">    data_[currentTail] = item;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在这个函数内部，如我们提示的那样，将尾指针移动的逻辑包裹在了一个compare_exchange_weak操作的内部，如果当前内存中的tail_变量与我们预期的currentTail不一样，则重新load，重新计算nextTail，如果和预期的一致，则更新tail_为nextTail。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>尝试了和ChatGtp进行合作开发,使用合适的prompt逐步修正结果，得到一个初步符合我们预期的循环队列。</p>\n<h1 id=\"1-需求的自然语言描述\"><a href=\"#1-需求的自然语言描述\" class=\"headerlink\" title=\"1 需求的自然语言描述\"></a>1 需求的自然语言描述</h1><p>用C++ 20的语言标准，实现线程安全的循环队列，提供详细注释<br>具体要求如下：<br>1、环形队列要支持阻塞读和非阻塞读，阻塞写和非阻塞写<br>2、支持模板，存放的数据类型可以自定义<br>3、代码风格使用google C++风格<br>4、在开发中尽可能提高队列的性能，并说明采取了哪些手段提高性能，说明理由</p>\n<h1 id=\"2-Gpt第一轮尝试\"><a href=\"#2-Gpt第一轮尝试\" class=\"headerlink\" title=\"2 Gpt第一轮尝试\"></a>2 Gpt第一轮尝试</h1><h2 id=\"2-1-Gpt给出的结果\"><a href=\"#2-1-Gpt给出的结果\" class=\"headerlink\" title=\"2.1 Gpt给出的结果\"></a>2.1 Gpt给出的结果</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;queue&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;mutex&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;condition_variable&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;thread&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 线程安全的循环队列模板</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">ThreadSafeQueue</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">explicit</span> <span class=\"title\">ThreadSafeQueue</span><span class=\"params\">(<span class=\"type\">size_t</span> capacity)</span> : capacity_(capacity) &#123;</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 阻塞写入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">Enqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"comment\">// 使用条件变量等待队列不满</span></span><br><span class=\"line\">        notFull_.<span class=\"built_in\">wait</span>(lock, [<span class=\"keyword\">this</span>] &#123; <span class=\"keyword\">return</span> queue_.<span class=\"built_in\">size</span>() &lt; capacity_; &#125;);</span><br><span class=\"line\">        queue_.<span class=\"built_in\">push</span>(item);</span><br><span class=\"line\">        lock.<span class=\"built_in\">unlock</span>();</span><br><span class=\"line\">        <span class=\"comment\">// 通知等待的线程队列不为空</span></span><br><span class=\"line\">        notEmpty_.<span class=\"built_in\">notify_one</span>();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 非阻塞写入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">TryEnqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"function\">std::lock_guard&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (queue_.<span class=\"built_in\">size</span>() &lt; capacity_) &#123;</span><br><span class=\"line\">            queue_.<span class=\"built_in\">push</span>(item);</span><br><span class=\"line\">            <span class=\"comment\">// 通知等待的线程队列不为空</span></span><br><span class=\"line\">            notEmpty_.<span class=\"built_in\">notify_one</span>();</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 阻塞读取队列</span></span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">Dequeue</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"function\">std::unique_lock&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"comment\">// 使用条件变量等待队列不空</span></span><br><span class=\"line\">        notEmpty_.<span class=\"built_in\">wait</span>(lock, [<span class=\"keyword\">this</span>] &#123; <span class=\"keyword\">return</span> !queue_.<span class=\"built_in\">empty</span>(); &#125;);</span><br><span class=\"line\">        T item = queue_.<span class=\"built_in\">front</span>();</span><br><span class=\"line\">        queue_.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">        lock.<span class=\"built_in\">unlock</span>();</span><br><span class=\"line\">        <span class=\"comment\">// 通知等待的线程队列不满</span></span><br><span class=\"line\">        notFull_.<span class=\"built_in\">notify_one</span>();</span><br><span class=\"line\">        <span class=\"keyword\">return</span> item;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 非阻塞读取队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">TryDequeue</span><span class=\"params\">(T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"function\">std::lock_guard&lt;std::mutex&gt; <span class=\"title\">lock</span><span class=\"params\">(mutex_)</span></span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!queue_.<span class=\"built_in\">empty</span>()) &#123;</span><br><span class=\"line\">            item = queue_.<span class=\"built_in\">front</span>();</span><br><span class=\"line\">            queue_.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">            <span class=\"comment\">// 通知等待的线程队列不满</span></span><br><span class=\"line\">            notFull_.<span class=\"built_in\">notify_one</span>();</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"type\">size_t</span> capacity_;</span><br><span class=\"line\">    std::queue&lt;T&gt; queue_;</span><br><span class=\"line\">    std::mutex mutex_;</span><br><span class=\"line\">    std::condition_variable notFull_;</span><br><span class=\"line\">    std::condition_variable notEmpty_;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-2-对代码的分析\"><a href=\"#2-2-对代码的分析\" class=\"headerlink\" title=\"2.2 对代码的分析\"></a>2.2 对代码的分析</h2><p>代码最低限度地实现了我们提出的需求，比如阻塞&#x2F;非阻塞读写、支持模板、代码风格等。但是代码中存在着许多显而易见的问题。</p>\n<ol>\n<li>可能是我使用的“队列”一词对gpt造成了先入为主的印象，导致它在数据结构上采用了deque的结构，当deque需要增长时，它会分配一个新的内存块，并将其链接到现有的块，这样一个动态的结构天生会对内存的分配存在开销，偏离了我们提出的高性能的目的。</li>\n<li>gpt在代码设计中，为了保障线程安全的要求，使用了互斥锁，这一块是可以优化的，可以通过原子变量的CAS操作来规避掉锁的开销。</li>\n</ol>\n<h1 id=\"3-Gpt的第二轮尝试\"><a href=\"#3-Gpt的第二轮尝试\" class=\"headerlink\" title=\"3 Gpt的第二轮尝试\"></a>3 Gpt的第二轮尝试</h1><h2 id=\"3-1-对功能修改的描述\"><a href=\"#3-1-对功能修改的描述\" class=\"headerlink\" title=\"3.1 对功能修改的描述\"></a>3.1 对功能修改的描述</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">目前代码存在一些问题，考虑针对以下点进行优化：</span><br><span class=\"line\"><span class=\"number\">1.</span>由于采用deque的数据结构，导致存在动态分配内存的开销</span><br><span class=\"line\"><span class=\"number\">2.</span>mutex互斥锁的存在降低了效率，能否通过原子变量实现无锁操作</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-2-Gpt给出的结果\"><a href=\"#3-2-Gpt给出的结果\" class=\"headerlink\" title=\"3.2 Gpt给出的结果\"></a>3.2 Gpt给出的结果</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;vector&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;atomic&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;condition_variable&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;thread&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">ThreadSafeQueue</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">explicit</span> <span class=\"title\">ThreadSafeQueue</span><span class=\"params\">(<span class=\"type\">size_t</span> capacity)</span> : capacity_(capacity), head_(<span class=\"number\">0</span>), tail_(<span class=\"number\">0</span>) &#123;</span></span><br><span class=\"line\">        data_.<span class=\"built_in\">resize</span>(capacity);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 阻塞写入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">Enqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">            <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">            <span class=\"type\">size_t</span> nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (nextTail != head_.<span class=\"built_in\">load</span>(std::memory_order_acquire)) &#123;</span><br><span class=\"line\">                data_[currentTail] = item;</span><br><span class=\"line\">                tail_.<span class=\"built_in\">store</span>(nextTail, std::memory_order_release);</span><br><span class=\"line\">                <span class=\"keyword\">return</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">// 队列已满，等待</span></span><br><span class=\"line\">            std::this_thread::<span class=\"built_in\">yield</span>();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 非阻塞写入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">TryEnqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">        <span class=\"type\">size_t</span> nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (nextTail != head_.<span class=\"built_in\">load</span>(std::memory_order_acquire)) &#123;</span><br><span class=\"line\">            data_[currentTail] = item;</span><br><span class=\"line\">            tail_.<span class=\"built_in\">store</span>(nextTail, std::memory_order_release);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 阻塞读取队列</span></span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">Dequeue</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">            <span class=\"type\">size_t</span> currentHead = head_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">            <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_acquire);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (currentHead != currentTail) &#123;</span><br><span class=\"line\">                T item = data_[currentHead];</span><br><span class=\"line\">                head_.<span class=\"built_in\">store</span>((currentHead + <span class=\"number\">1</span>) % capacity_, std::memory_order_release);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> item;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">// 队列为空，等待</span></span><br><span class=\"line\">            std::this_thread::<span class=\"built_in\">yield</span>();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 非阻塞读取队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">TryDequeue</span><span class=\"params\">(T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentHead = head_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_acquire);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (currentHead != currentTail) &#123;</span><br><span class=\"line\">            item = data_[currentHead];</span><br><span class=\"line\">            head_.<span class=\"built_in\">store</span>((currentHead + <span class=\"number\">1</span>) % capacity_, std::memory_order_release);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"type\">size_t</span> capacity_;</span><br><span class=\"line\">    std::vector&lt;T&gt; data_;</span><br><span class=\"line\">    std::atomic&lt;<span class=\"type\">size_t</span>&gt; head_;</span><br><span class=\"line\">    std::atomic&lt;<span class=\"type\">size_t</span>&gt; tail_;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-3-对代码的分析\"><a href=\"#3-3-对代码的分析\" class=\"headerlink\" title=\"3.3 对代码的分析\"></a>3.3 对代码的分析</h2><p>从这轮优化中粗看，gpt已经修复了上文中提到的两个问题，使用了std::atomic来管理head_和tail_，并通过原子操作实现队列的无锁操作。在阻塞写入和读取的过程中，移除了两个条件变量，使用std::this_thread::yield()来让出CPU。<br>可以简单分析一下，这轮优化过程中使用到的一些知识点：</p>\n<h3 id=\"3-3-1-为什么舍弃条件变量\"><a href=\"#3-3-1-为什么舍弃条件变量\" class=\"headerlink\" title=\"3.3.1 为什么舍弃条件变量\"></a>3.3.1 为什么舍弃条件变量</h3><p><strong>std::condition_variable</strong> 是 C++ 标准库中的一个多线程同步工具，用于在多个线程之间进行条件同步。采用<strong>condition_variable</strong> 主动来实现线程的等待和唤醒机制显然比盲目地std::this_thread::yield()让出时间片更为合理，如果在阻塞写或者阻塞读的情况下，有可能造成频繁的线程切换，造成开销。<br>但是<strong>condition_variable</strong> 必须搭配mutex使用，在我们限定无锁编程的情况下，<strong>condition_variable</strong> 显然是无法被采用的，所以被舍弃了。</p>\n<h3 id=\"3-3-2-阻塞写时安全性论证\"><a href=\"#3-3-2-阻塞写时安全性论证\" class=\"headerlink\" title=\"3.3.2 阻塞写时安全性论证\"></a>3.3.2 阻塞写时安全性论证</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">Enqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">        <span class=\"type\">size_t</span> nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (nextTail != head_.<span class=\"built_in\">load</span>(std::memory_order_acquire)) &#123;</span><br><span class=\"line\">            data_[currentTail] = item;</span><br><span class=\"line\">            tail_.<span class=\"built_in\">store</span>(nextTail, std::memory_order_release);</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 队列已满，等待</span></span><br><span class=\"line\">        std::this_thread::<span class=\"built_in\">yield</span>();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这是gpt给出的代码，如我们提示的那样使用上了原子变量，试图通过内存序来保障读写之间的安全性。但是很明显，这段代码是在多写情况下是线程不安全的。<br><strong>错误一：</strong><br>下面的两行代码之间不是原子的，多个线程在同一时刻可能读取相同的 tail_ 值，然后计算出相同的 nextTail，这可能导致它们尝试在相同的位置写入数据，从而导致数据覆盖。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\"><span class=\"type\">size_t</span> nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br></pre></td></tr></table></figure>\n<p><strong>错误二：</strong><br>虽然 head_ 的加载使用了 memory_order_acquire，但是在实际的操作中，其他线程可能在这段时间内修改了 head_ 的值，导致脏读的出现，从而导致判断错误。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (nextTail != head_.<span class=\"built_in\">load</span>(std::memory_order_acquire)) &#123;</span><br><span class=\"line\">\tdata_[currentTail] = item;</span><br><span class=\"line\">\t<span class=\"comment\">// something else</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>所以从上面指出的这两个错误来看，这部分代码存在着比较致命的问题。</p>\n<h1 id=\"4-Gpt的第三轮尝试\"><a href=\"#4-Gpt的第三轮尝试\" class=\"headerlink\" title=\"4 Gpt的第三轮尝试\"></a>4 Gpt的第三轮尝试</h1><h2 id=\"4-1-对功能修改的描述\"><a href=\"#4-1-对功能修改的描述\" class=\"headerlink\" title=\"4.1 对功能修改的描述\"></a>4.1 对功能修改的描述</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">目前代码存在一些问题，考虑针对以下点进行优化：</span><br><span class=\"line\"><span class=\"number\">1.</span>目前代码面对多线程写入的场景时，因为临界区的存在，存在不安全的问题，考虑用CAS操作进行优化</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-2-Gpt给出的结果\"><a href=\"#4-2-Gpt给出的结果\" class=\"headerlink\" title=\"4.2 Gpt给出的结果\"></a>4.2 Gpt给出的结果</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;vector&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;atomic&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;condition_variable&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;thread&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">ThreadSafeQueue</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">explicit</span> <span class=\"title\">ThreadSafeQueue</span><span class=\"params\">(<span class=\"type\">size_t</span> capacity)</span> : capacity_(capacity), head_(<span class=\"number\">0</span>), tail_(<span class=\"number\">0</span>) &#123;</span></span><br><span class=\"line\">        data_.<span class=\"built_in\">resize</span>(capacity);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 阻塞写入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">Enqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> nextTail;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">do</span> &#123;</span><br><span class=\"line\">            currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">            nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (nextTail == head_.<span class=\"built_in\">load</span>(std::memory_order_acquire)) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 队列已满，等待</span></span><br><span class=\"line\">                std::this_thread::<span class=\"built_in\">yield</span>();</span><br><span class=\"line\">                <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">// 尝试使用CAS进行原子操作</span></span><br><span class=\"line\">        &#125; <span class=\"keyword\">while</span> (!tail_.<span class=\"built_in\">compare_exchange_weak</span>(currentTail, nextTail, std::memory_order_acq_rel));</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// CAS成功，可以进行写入操作</span></span><br><span class=\"line\">        data_[currentTail] = item;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 非阻塞写入队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">TryEnqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">        <span class=\"type\">size_t</span> nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (nextTail == head_.<span class=\"built_in\">load</span>(std::memory_order_acquire))</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (tail_.<span class=\"built_in\">compare_exchange_weak</span>(currentTail, nextTail, std::memory_order_acq_rel)) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// CAS成功，可以进行写入操作</span></span><br><span class=\"line\">            data_[currentTail] = item;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 阻塞读取队列</span></span><br><span class=\"line\">    <span class=\"function\">T <span class=\"title\">Dequeue</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentHead;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">do</span> &#123;</span><br><span class=\"line\">            currentHead = head_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">            currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_acquire);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (currentHead == currentTail) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 队列为空，等待</span></span><br><span class=\"line\">                std::this_thread::<span class=\"built_in\">yield</span>();</span><br><span class=\"line\">                <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">// 尝试使用CAS进行原子操作</span></span><br><span class=\"line\">        &#125; <span class=\"keyword\">while</span> (!head_.<span class=\"built_in\">compare_exchange_weak</span>(currentHead, (currentHead + <span class=\"number\">1</span>) % capacity_, std::memory_order_acq_rel));</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// CAS成功，可以进行读取操作</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> data_[currentHead];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 非阻塞读取队列</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">TryDequeue</span><span class=\"params\">(T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentHead = head_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">        <span class=\"type\">size_t</span> currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_acquire);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (currentHead == currentTail)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (head_.<span class=\"built_in\">compare_exchange_weak</span>(currentHead, (currentHead + <span class=\"number\">1</span>) % capacity_, std::memory_order_acq_rel)) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// CAS成功，可以进行读取操作</span></span><br><span class=\"line\">            item = data_[currentHead];</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">private</span>:</span><br><span class=\"line\">    <span class=\"type\">size_t</span> capacity_;</span><br><span class=\"line\">    std::vector&lt;T&gt; data_;</span><br><span class=\"line\">    std::atomic&lt;<span class=\"type\">size_t</span>&gt; head_;</span><br><span class=\"line\">    std::atomic&lt;<span class=\"type\">size_t</span>&gt; tail_;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h2 id=\"4-3-对代码的分析\"><a href=\"#4-3-对代码的分析\" class=\"headerlink\" title=\"4.3 对代码的分析\"></a>4.3 对代码的分析</h2><p>我们回到上文中有问题的函数，经过更新之后的代码片段如下所示：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">Enqueue</span><span class=\"params\">(<span class=\"type\">const</span> T&amp; item)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"type\">size_t</span> currentTail;</span><br><span class=\"line\">    <span class=\"type\">size_t</span> nextTail;</span><br><span class=\"line\">    <span class=\"keyword\">do</span> &#123;</span><br><span class=\"line\">        currentTail = tail_.<span class=\"built_in\">load</span>(std::memory_order_relaxed);</span><br><span class=\"line\">        nextTail = (currentTail + <span class=\"number\">1</span>) % capacity_;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (nextTail == head_.<span class=\"built_in\">load</span>(std::memory_order_acquire)) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 队列已满，等待</span></span><br><span class=\"line\">            std::this_thread::<span class=\"built_in\">yield</span>();</span><br><span class=\"line\">            <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 尝试使用CAS进行原子操作</span></span><br><span class=\"line\">    &#125; <span class=\"keyword\">while</span> (!tail_.<span class=\"built_in\">compare_exchange_weak</span>(currentTail, nextTail, std::memory_order_acq_rel));</span><br><span class=\"line\">    <span class=\"comment\">// CAS成功，可以进行写入操作</span></span><br><span class=\"line\">    data_[currentTail] = item;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在这个函数内部，如我们提示的那样，将尾指针移动的逻辑包裹在了一个compare_exchange_weak操作的内部，如果当前内存中的tail_变量与我们预期的currentTail不一样，则重新load，重新计算nextTail，如果和预期的一致，则更新tail_为nextTail。</p>\n"},{"title":"迁移计划","date":"2023-12-01T18:45:20.000Z","_content":"\n由于原本在云服务器上的个人博客的停用，接下来一段时间，计划把过往一段时间时间所产出的文章进行整理和迁移。我计划的迁移内容大致分为以下几个模块：\n\n#### C++语法方面的一些个人笔记\n- ✔C++的一些基础知识回顾（经过整理觉得太过于浅显，有沦为工具手册的嫌疑，遂放弃）\n- C++ 20以上的新特性\n\n#### 计算机体系结构下的读书笔记\n- 共享内存整理\n- 异步事件框架\n- ~~分布式一致性协议（挪到工作中的问题部分）~~\n- rpc框架的实现\n- csapp读书笔记\n- 6.824的lab\n\n#### 探索过的编程模式\n\n- ✔无锁编程（存在一个版本的草稿，但是还需要优化）\n- 并发编程\n- ✔模版编程（存在一个版本的草稿，但是还需要优化）\n- 无分支编程\n- ✔缓存友好编程（存在一个版本的草稿，但是还需要优化）\n- 向量化编程\n\n#### 工作中遇到过的问题\n- linux下的高精度测时问题\n- 超线程导致的效率降低问题\n- grafana大量close_wait拖垮数据库\n- 分布式系统的一致性等级造成的异常\n\n#### 工作中部分项目的总结\n- ~~项目的稳定性治理~~\n- ~~重构项目的技巧与总结~~\n- ✔基于责任链的设计结构的改造\n- 交易系统的性能优化实践\n\n#### 一些常用工具的学习和了解\n- git多路merge算法的实现原理\n- docker的实现原理与使用方法\n","source":"_posts/Todo-plans.md","raw":"---\ntitle: 迁移计划\ndate: 2023-12-02 02:45:20\ntags: Plan\n---\n\n由于原本在云服务器上的个人博客的停用，接下来一段时间，计划把过往一段时间时间所产出的文章进行整理和迁移。我计划的迁移内容大致分为以下几个模块：\n\n#### C++语法方面的一些个人笔记\n- ✔C++的一些基础知识回顾（经过整理觉得太过于浅显，有沦为工具手册的嫌疑，遂放弃）\n- C++ 20以上的新特性\n\n#### 计算机体系结构下的读书笔记\n- 共享内存整理\n- 异步事件框架\n- ~~分布式一致性协议（挪到工作中的问题部分）~~\n- rpc框架的实现\n- csapp读书笔记\n- 6.824的lab\n\n#### 探索过的编程模式\n\n- ✔无锁编程（存在一个版本的草稿，但是还需要优化）\n- 并发编程\n- ✔模版编程（存在一个版本的草稿，但是还需要优化）\n- 无分支编程\n- ✔缓存友好编程（存在一个版本的草稿，但是还需要优化）\n- 向量化编程\n\n#### 工作中遇到过的问题\n- linux下的高精度测时问题\n- 超线程导致的效率降低问题\n- grafana大量close_wait拖垮数据库\n- 分布式系统的一致性等级造成的异常\n\n#### 工作中部分项目的总结\n- ~~项目的稳定性治理~~\n- ~~重构项目的技巧与总结~~\n- ✔基于责任链的设计结构的改造\n- 交易系统的性能优化实践\n\n#### 一些常用工具的学习和了解\n- git多路merge算法的实现原理\n- docker的实现原理与使用方法\n","slug":"Todo-plans","published":1,"updated":"2024-01-30T15:39:28.458Z","_id":"cls01gnk000001ax57sxn64hc","comments":1,"layout":"post","photos":[],"link":"","content":"<p>由于原本在云服务器上的个人博客的停用，接下来一段时间，计划把过往一段时间时间所产出的文章进行整理和迁移。我计划的迁移内容大致分为以下几个模块：</p>\n<h4 id=\"C-语法方面的一些个人笔记\"><a href=\"#C-语法方面的一些个人笔记\" class=\"headerlink\" title=\"C++语法方面的一些个人笔记\"></a>C++语法方面的一些个人笔记</h4><ul>\n<li>✔C++的一些基础知识回顾（经过整理觉得太过于浅显，有沦为工具手册的嫌疑，遂放弃）</li>\n<li>C++ 20以上的新特性</li>\n</ul>\n<h4 id=\"计算机体系结构下的读书笔记\"><a href=\"#计算机体系结构下的读书笔记\" class=\"headerlink\" title=\"计算机体系结构下的读书笔记\"></a>计算机体系结构下的读书笔记</h4><ul>\n<li>共享内存整理</li>\n<li>异步事件框架</li>\n<li><del>分布式一致性协议（挪到工作中的问题部分）</del></li>\n<li>rpc框架的实现</li>\n<li>csapp读书笔记</li>\n<li>6.824的lab</li>\n</ul>\n<h4 id=\"探索过的编程模式\"><a href=\"#探索过的编程模式\" class=\"headerlink\" title=\"探索过的编程模式\"></a>探索过的编程模式</h4><ul>\n<li>✔无锁编程（存在一个版本的草稿，但是还需要优化）</li>\n<li>并发编程</li>\n<li>✔模版编程（存在一个版本的草稿，但是还需要优化）</li>\n<li>无分支编程</li>\n<li>✔缓存友好编程（存在一个版本的草稿，但是还需要优化）</li>\n<li>向量化编程</li>\n</ul>\n<h4 id=\"工作中遇到过的问题\"><a href=\"#工作中遇到过的问题\" class=\"headerlink\" title=\"工作中遇到过的问题\"></a>工作中遇到过的问题</h4><ul>\n<li>linux下的高精度测时问题</li>\n<li>超线程导致的效率降低问题</li>\n<li>grafana大量close_wait拖垮数据库</li>\n<li>分布式系统的一致性等级造成的异常</li>\n</ul>\n<h4 id=\"工作中部分项目的总结\"><a href=\"#工作中部分项目的总结\" class=\"headerlink\" title=\"工作中部分项目的总结\"></a>工作中部分项目的总结</h4><ul>\n<li><del>项目的稳定性治理</del></li>\n<li><del>重构项目的技巧与总结</del></li>\n<li>✔基于责任链的设计结构的改造</li>\n<li>交易系统的性能优化实践</li>\n</ul>\n<h4 id=\"一些常用工具的学习和了解\"><a href=\"#一些常用工具的学习和了解\" class=\"headerlink\" title=\"一些常用工具的学习和了解\"></a>一些常用工具的学习和了解</h4><ul>\n<li>git多路merge算法的实现原理</li>\n<li>docker的实现原理与使用方法</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>由于原本在云服务器上的个人博客的停用，接下来一段时间，计划把过往一段时间时间所产出的文章进行整理和迁移。我计划的迁移内容大致分为以下几个模块：</p>\n<h4 id=\"C-语法方面的一些个人笔记\"><a href=\"#C-语法方面的一些个人笔记\" class=\"headerlink\" title=\"C++语法方面的一些个人笔记\"></a>C++语法方面的一些个人笔记</h4><ul>\n<li>✔C++的一些基础知识回顾（经过整理觉得太过于浅显，有沦为工具手册的嫌疑，遂放弃）</li>\n<li>C++ 20以上的新特性</li>\n</ul>\n<h4 id=\"计算机体系结构下的读书笔记\"><a href=\"#计算机体系结构下的读书笔记\" class=\"headerlink\" title=\"计算机体系结构下的读书笔记\"></a>计算机体系结构下的读书笔记</h4><ul>\n<li>共享内存整理</li>\n<li>异步事件框架</li>\n<li><del>分布式一致性协议（挪到工作中的问题部分）</del></li>\n<li>rpc框架的实现</li>\n<li>csapp读书笔记</li>\n<li>6.824的lab</li>\n</ul>\n<h4 id=\"探索过的编程模式\"><a href=\"#探索过的编程模式\" class=\"headerlink\" title=\"探索过的编程模式\"></a>探索过的编程模式</h4><ul>\n<li>✔无锁编程（存在一个版本的草稿，但是还需要优化）</li>\n<li>并发编程</li>\n<li>✔模版编程（存在一个版本的草稿，但是还需要优化）</li>\n<li>无分支编程</li>\n<li>✔缓存友好编程（存在一个版本的草稿，但是还需要优化）</li>\n<li>向量化编程</li>\n</ul>\n<h4 id=\"工作中遇到过的问题\"><a href=\"#工作中遇到过的问题\" class=\"headerlink\" title=\"工作中遇到过的问题\"></a>工作中遇到过的问题</h4><ul>\n<li>linux下的高精度测时问题</li>\n<li>超线程导致的效率降低问题</li>\n<li>grafana大量close_wait拖垮数据库</li>\n<li>分布式系统的一致性等级造成的异常</li>\n</ul>\n<h4 id=\"工作中部分项目的总结\"><a href=\"#工作中部分项目的总结\" class=\"headerlink\" title=\"工作中部分项目的总结\"></a>工作中部分项目的总结</h4><ul>\n<li><del>项目的稳定性治理</del></li>\n<li><del>重构项目的技巧与总结</del></li>\n<li>✔基于责任链的设计结构的改造</li>\n<li>交易系统的性能优化实践</li>\n</ul>\n<h4 id=\"一些常用工具的学习和了解\"><a href=\"#一些常用工具的学习和了解\" class=\"headerlink\" title=\"一些常用工具的学习和了解\"></a>一些常用工具的学习和了解</h4><ul>\n<li>git多路merge算法的实现原理</li>\n<li>docker的实现原理与使用方法</li>\n</ul>\n"},{"title":"缓存友好编程","date":"2024-01-17T15:32:16.000Z","_content":"本文主要介绍了缓存友好编程的一些基本原则和使用中需要注意的点。\n\n# 1 局部性原理\n在编程过程中，局部性原理的存在是缓存友好编程这一概念存在的基础。局部性原理一般可分为时间局部性和空间局部性。\n时间局部性指的是被引用过一次的内存位置很可能在不远的将来再被多次引用。空间局部性指的是如果一个内存位置被引用了一次，那么程序很可能在不远的将来引用附近的一个内存位置。\n在我们编程中，大量的数据结构存在顺序引用模式，如数组，列表等，这些顺序的数据结构就是空间局部性的主要来源。如果存在循环语句的话，就会对同一指令进行多次执行，这是时间局部性的主要来源。\n# 2 缓存行结构\n继续说空间局部性，为什么会出现空间局部性，是因为处理器存在缓存行的概念。\n缓存行是处理器一次缓存读写操作的最小长度单位。当我们的CPU试图访问一个int类型（4字节）的内存地址时，包含该地址的整个缓存行（32字节）将被加载进我们的Cache。也就是说，一次缓存行的读取相对于我们一个变量的读取，完全是有空间冗余的操作。如果我们在接下来试图访问连续的下一个int值时，可以跳过将缓存行从内存中加载到缓存中中的这个步骤，直接命中缓存。\n这一部分的开销的节省是否有必要，可以从下表发现，从寄存器到主存的逐级cache，访问速度是指数级变化的，极端情况下直接在L1命中缓存和到内存中寻址，相差100倍的时钟周期。\n![image.png](/images/cache-friendly-1.png)\n\n# 3 缓存命中的问题\n### 3.1 代码示例\n在冷缓存，32位机器，32字节缓存行大小的机器下，如下两种代码的便利方式有着大相径庭的缓存命中率。\n```cpp\n//缓存命中率7/8\nint sumarrayrows(int a[M][N])\n{\n\tint i, j, sum = 0;\n\tfor (i = 0; i < M; i++)\n\t\tfor (j = 0; j < N; j++)\n\t\t\tsum += a[i][j];\n\treturn sum;\n}\n\n//缓存命中率0\nint sumarraycols(int a[M][N])\n{\n\tint i, j, sum = 0;\n\tfor (j = 0; j < N; j++)\n\t\tfor (i = 0; i < M; i++)\n\t\t\tsum += a[i][j];\n\treturn sum;\n}\n```\n### 3.2 编程原则\n\n- 保持尽可能小的工作集（时间局部性）\n- 使用小步幅连续寻址（空间局部性）\n# 4 反直觉的False Sharing\n在之前提到的内容中，把数据尽可能地连续放入缓存行，似乎是一种非常高效的便于访问的方法。\n但是事实上，如果不合理地使用缓存，将会出现反直觉地false sharing的问题。\n### 4.1 false sharing的成因\n![image.png](/images/cache-friendly-2.png)\n如图所示，一个运行在处理器 core1上的线程想要更新变量 X 的值，同时另外一个运行在处理器 core2 上的线程想要更新变量 Y 的值。但是，这两个频繁改动的变量都处于同一条缓存行。两个线程就会轮番发送Request For Owner消息（写请求之前的独占声明），占得此缓存行的拥有权。当 core1 取得了拥有权开始更新 X，则 core2 对应的缓存行需要设为 I 状态。当 core2 取得了拥有权开始更新 Y，则 core1 对应的缓存行需要设为 I 状态(失效态)。轮番夺取拥有权不但带来大量的 RFO 消息，而且如果某个线程需要读此行数据时，L1 和 L2 缓存上都是失效数据，只有 L3 缓存上是同步好的数据。从前一篇我们知道，读 L3 的数据非常影响性能。更坏的情况是跨槽读取，L3 都要 miss，只能从内存上加载。\n表面上 X 和 Y 都是被独立线程操作的，而且两操作之间也没有任何关系。只不过它们共享了一个缓存行，但所有竞争冲突都是来源于共享。\n### 4.2 false sharing的解法\n一个解决思路，就是让不同线程操作的对象处于不同的缓存行即可。\n具体方法就是缓存行填充（Padding） 。我们使得可能产生写冲突的对象处于不同的缓存行，就避免了伪共享( 64 位系统超过缓存行的 64 字节也无所谓，只要保证不同线程不操作同一缓存行就可以)。\n\n","source":"_posts/Cache-friendly-programming.md","raw":"---\ntitle: 缓存友好编程\ndate: 2024-01-17 23:32:16\ntags: Cpp\n---\n本文主要介绍了缓存友好编程的一些基本原则和使用中需要注意的点。\n\n# 1 局部性原理\n在编程过程中，局部性原理的存在是缓存友好编程这一概念存在的基础。局部性原理一般可分为时间局部性和空间局部性。\n时间局部性指的是被引用过一次的内存位置很可能在不远的将来再被多次引用。空间局部性指的是如果一个内存位置被引用了一次，那么程序很可能在不远的将来引用附近的一个内存位置。\n在我们编程中，大量的数据结构存在顺序引用模式，如数组，列表等，这些顺序的数据结构就是空间局部性的主要来源。如果存在循环语句的话，就会对同一指令进行多次执行，这是时间局部性的主要来源。\n# 2 缓存行结构\n继续说空间局部性，为什么会出现空间局部性，是因为处理器存在缓存行的概念。\n缓存行是处理器一次缓存读写操作的最小长度单位。当我们的CPU试图访问一个int类型（4字节）的内存地址时，包含该地址的整个缓存行（32字节）将被加载进我们的Cache。也就是说，一次缓存行的读取相对于我们一个变量的读取，完全是有空间冗余的操作。如果我们在接下来试图访问连续的下一个int值时，可以跳过将缓存行从内存中加载到缓存中中的这个步骤，直接命中缓存。\n这一部分的开销的节省是否有必要，可以从下表发现，从寄存器到主存的逐级cache，访问速度是指数级变化的，极端情况下直接在L1命中缓存和到内存中寻址，相差100倍的时钟周期。\n![image.png](/images/cache-friendly-1.png)\n\n# 3 缓存命中的问题\n### 3.1 代码示例\n在冷缓存，32位机器，32字节缓存行大小的机器下，如下两种代码的便利方式有着大相径庭的缓存命中率。\n```cpp\n//缓存命中率7/8\nint sumarrayrows(int a[M][N])\n{\n\tint i, j, sum = 0;\n\tfor (i = 0; i < M; i++)\n\t\tfor (j = 0; j < N; j++)\n\t\t\tsum += a[i][j];\n\treturn sum;\n}\n\n//缓存命中率0\nint sumarraycols(int a[M][N])\n{\n\tint i, j, sum = 0;\n\tfor (j = 0; j < N; j++)\n\t\tfor (i = 0; i < M; i++)\n\t\t\tsum += a[i][j];\n\treturn sum;\n}\n```\n### 3.2 编程原则\n\n- 保持尽可能小的工作集（时间局部性）\n- 使用小步幅连续寻址（空间局部性）\n# 4 反直觉的False Sharing\n在之前提到的内容中，把数据尽可能地连续放入缓存行，似乎是一种非常高效的便于访问的方法。\n但是事实上，如果不合理地使用缓存，将会出现反直觉地false sharing的问题。\n### 4.1 false sharing的成因\n![image.png](/images/cache-friendly-2.png)\n如图所示，一个运行在处理器 core1上的线程想要更新变量 X 的值，同时另外一个运行在处理器 core2 上的线程想要更新变量 Y 的值。但是，这两个频繁改动的变量都处于同一条缓存行。两个线程就会轮番发送Request For Owner消息（写请求之前的独占声明），占得此缓存行的拥有权。当 core1 取得了拥有权开始更新 X，则 core2 对应的缓存行需要设为 I 状态。当 core2 取得了拥有权开始更新 Y，则 core1 对应的缓存行需要设为 I 状态(失效态)。轮番夺取拥有权不但带来大量的 RFO 消息，而且如果某个线程需要读此行数据时，L1 和 L2 缓存上都是失效数据，只有 L3 缓存上是同步好的数据。从前一篇我们知道，读 L3 的数据非常影响性能。更坏的情况是跨槽读取，L3 都要 miss，只能从内存上加载。\n表面上 X 和 Y 都是被独立线程操作的，而且两操作之间也没有任何关系。只不过它们共享了一个缓存行，但所有竞争冲突都是来源于共享。\n### 4.2 false sharing的解法\n一个解决思路，就是让不同线程操作的对象处于不同的缓存行即可。\n具体方法就是缓存行填充（Padding） 。我们使得可能产生写冲突的对象处于不同的缓存行，就避免了伪共享( 64 位系统超过缓存行的 64 字节也无所谓，只要保证不同线程不操作同一缓存行就可以)。\n\n","slug":"Cache-friendly-programming","published":1,"updated":"2024-01-18T02:45:11.477Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cls21ghtm0000ygx533k5a3an","content":"<p>本文主要介绍了缓存友好编程的一些基本原则和使用中需要注意的点。</p>\n<h1 id=\"1-局部性原理\"><a href=\"#1-局部性原理\" class=\"headerlink\" title=\"1 局部性原理\"></a>1 局部性原理</h1><p>在编程过程中，局部性原理的存在是缓存友好编程这一概念存在的基础。局部性原理一般可分为时间局部性和空间局部性。<br>时间局部性指的是被引用过一次的内存位置很可能在不远的将来再被多次引用。空间局部性指的是如果一个内存位置被引用了一次，那么程序很可能在不远的将来引用附近的一个内存位置。<br>在我们编程中，大量的数据结构存在顺序引用模式，如数组，列表等，这些顺序的数据结构就是空间局部性的主要来源。如果存在循环语句的话，就会对同一指令进行多次执行，这是时间局部性的主要来源。</p>\n<h1 id=\"2-缓存行结构\"><a href=\"#2-缓存行结构\" class=\"headerlink\" title=\"2 缓存行结构\"></a>2 缓存行结构</h1><p>继续说空间局部性，为什么会出现空间局部性，是因为处理器存在缓存行的概念。<br>缓存行是处理器一次缓存读写操作的最小长度单位。当我们的CPU试图访问一个int类型（4字节）的内存地址时，包含该地址的整个缓存行（32字节）将被加载进我们的Cache。也就是说，一次缓存行的读取相对于我们一个变量的读取，完全是有空间冗余的操作。如果我们在接下来试图访问连续的下一个int值时，可以跳过将缓存行从内存中加载到缓存中中的这个步骤，直接命中缓存。<br>这一部分的开销的节省是否有必要，可以从下表发现，从寄存器到主存的逐级cache，访问速度是指数级变化的，极端情况下直接在L1命中缓存和到内存中寻址，相差100倍的时钟周期。<br><img src=\"/images/cache-friendly-1.png\" alt=\"image.png\"></p>\n<h1 id=\"3-缓存命中的问题\"><a href=\"#3-缓存命中的问题\" class=\"headerlink\" title=\"3 缓存命中的问题\"></a>3 缓存命中的问题</h1><h3 id=\"3-1-代码示例\"><a href=\"#3-1-代码示例\" class=\"headerlink\" title=\"3.1 代码示例\"></a>3.1 代码示例</h3><p>在冷缓存，32位机器，32字节缓存行大小的机器下，如下两种代码的便利方式有着大相径庭的缓存命中率。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//缓存命中率7/8</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">sumarrayrows</span><span class=\"params\">(<span class=\"type\">int</span> a[M][N])</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"type\">int</span> i, j, sum = <span class=\"number\">0</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; M; i++)</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> (j = <span class=\"number\">0</span>; j &lt; N; j++)</span><br><span class=\"line\">\t\t\tsum += a[i][j];</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> sum;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//缓存命中率0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">sumarraycols</span><span class=\"params\">(<span class=\"type\">int</span> a[M][N])</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"type\">int</span> i, j, sum = <span class=\"number\">0</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> (j = <span class=\"number\">0</span>; j &lt; N; j++)</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; M; i++)</span><br><span class=\"line\">\t\t\tsum += a[i][j];</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> sum;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-2-编程原则\"><a href=\"#3-2-编程原则\" class=\"headerlink\" title=\"3.2 编程原则\"></a>3.2 编程原则</h3><ul>\n<li>保持尽可能小的工作集（时间局部性）</li>\n<li>使用小步幅连续寻址（空间局部性）</li>\n</ul>\n<h1 id=\"4-反直觉的False-Sharing\"><a href=\"#4-反直觉的False-Sharing\" class=\"headerlink\" title=\"4 反直觉的False Sharing\"></a>4 反直觉的False Sharing</h1><p>在之前提到的内容中，把数据尽可能地连续放入缓存行，似乎是一种非常高效的便于访问的方法。<br>但是事实上，如果不合理地使用缓存，将会出现反直觉地false sharing的问题。</p>\n<h3 id=\"4-1-false-sharing的成因\"><a href=\"#4-1-false-sharing的成因\" class=\"headerlink\" title=\"4.1 false sharing的成因\"></a>4.1 false sharing的成因</h3><p><img src=\"/images/cache-friendly-2.png\" alt=\"image.png\"><br>如图所示，一个运行在处理器 core1上的线程想要更新变量 X 的值，同时另外一个运行在处理器 core2 上的线程想要更新变量 Y 的值。但是，这两个频繁改动的变量都处于同一条缓存行。两个线程就会轮番发送Request For Owner消息（写请求之前的独占声明），占得此缓存行的拥有权。当 core1 取得了拥有权开始更新 X，则 core2 对应的缓存行需要设为 I 状态。当 core2 取得了拥有权开始更新 Y，则 core1 对应的缓存行需要设为 I 状态(失效态)。轮番夺取拥有权不但带来大量的 RFO 消息，而且如果某个线程需要读此行数据时，L1 和 L2 缓存上都是失效数据，只有 L3 缓存上是同步好的数据。从前一篇我们知道，读 L3 的数据非常影响性能。更坏的情况是跨槽读取，L3 都要 miss，只能从内存上加载。<br>表面上 X 和 Y 都是被独立线程操作的，而且两操作之间也没有任何关系。只不过它们共享了一个缓存行，但所有竞争冲突都是来源于共享。</p>\n<h3 id=\"4-2-false-sharing的解法\"><a href=\"#4-2-false-sharing的解法\" class=\"headerlink\" title=\"4.2 false sharing的解法\"></a>4.2 false sharing的解法</h3><p>一个解决思路，就是让不同线程操作的对象处于不同的缓存行即可。<br>具体方法就是缓存行填充（Padding） 。我们使得可能产生写冲突的对象处于不同的缓存行，就避免了伪共享( 64 位系统超过缓存行的 64 字节也无所谓，只要保证不同线程不操作同一缓存行就可以)。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>本文主要介绍了缓存友好编程的一些基本原则和使用中需要注意的点。</p>\n<h1 id=\"1-局部性原理\"><a href=\"#1-局部性原理\" class=\"headerlink\" title=\"1 局部性原理\"></a>1 局部性原理</h1><p>在编程过程中，局部性原理的存在是缓存友好编程这一概念存在的基础。局部性原理一般可分为时间局部性和空间局部性。<br>时间局部性指的是被引用过一次的内存位置很可能在不远的将来再被多次引用。空间局部性指的是如果一个内存位置被引用了一次，那么程序很可能在不远的将来引用附近的一个内存位置。<br>在我们编程中，大量的数据结构存在顺序引用模式，如数组，列表等，这些顺序的数据结构就是空间局部性的主要来源。如果存在循环语句的话，就会对同一指令进行多次执行，这是时间局部性的主要来源。</p>\n<h1 id=\"2-缓存行结构\"><a href=\"#2-缓存行结构\" class=\"headerlink\" title=\"2 缓存行结构\"></a>2 缓存行结构</h1><p>继续说空间局部性，为什么会出现空间局部性，是因为处理器存在缓存行的概念。<br>缓存行是处理器一次缓存读写操作的最小长度单位。当我们的CPU试图访问一个int类型（4字节）的内存地址时，包含该地址的整个缓存行（32字节）将被加载进我们的Cache。也就是说，一次缓存行的读取相对于我们一个变量的读取，完全是有空间冗余的操作。如果我们在接下来试图访问连续的下一个int值时，可以跳过将缓存行从内存中加载到缓存中中的这个步骤，直接命中缓存。<br>这一部分的开销的节省是否有必要，可以从下表发现，从寄存器到主存的逐级cache，访问速度是指数级变化的，极端情况下直接在L1命中缓存和到内存中寻址，相差100倍的时钟周期。<br><img src=\"/images/cache-friendly-1.png\" alt=\"image.png\"></p>\n<h1 id=\"3-缓存命中的问题\"><a href=\"#3-缓存命中的问题\" class=\"headerlink\" title=\"3 缓存命中的问题\"></a>3 缓存命中的问题</h1><h3 id=\"3-1-代码示例\"><a href=\"#3-1-代码示例\" class=\"headerlink\" title=\"3.1 代码示例\"></a>3.1 代码示例</h3><p>在冷缓存，32位机器，32字节缓存行大小的机器下，如下两种代码的便利方式有着大相径庭的缓存命中率。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//缓存命中率7/8</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">sumarrayrows</span><span class=\"params\">(<span class=\"type\">int</span> a[M][N])</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"type\">int</span> i, j, sum = <span class=\"number\">0</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; M; i++)</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> (j = <span class=\"number\">0</span>; j &lt; N; j++)</span><br><span class=\"line\">\t\t\tsum += a[i][j];</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> sum;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//缓存命中率0</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">sumarraycols</span><span class=\"params\">(<span class=\"type\">int</span> a[M][N])</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"type\">int</span> i, j, sum = <span class=\"number\">0</span>;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> (j = <span class=\"number\">0</span>; j &lt; N; j++)</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; M; i++)</span><br><span class=\"line\">\t\t\tsum += a[i][j];</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> sum;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-2-编程原则\"><a href=\"#3-2-编程原则\" class=\"headerlink\" title=\"3.2 编程原则\"></a>3.2 编程原则</h3><ul>\n<li>保持尽可能小的工作集（时间局部性）</li>\n<li>使用小步幅连续寻址（空间局部性）</li>\n</ul>\n<h1 id=\"4-反直觉的False-Sharing\"><a href=\"#4-反直觉的False-Sharing\" class=\"headerlink\" title=\"4 反直觉的False Sharing\"></a>4 反直觉的False Sharing</h1><p>在之前提到的内容中，把数据尽可能地连续放入缓存行，似乎是一种非常高效的便于访问的方法。<br>但是事实上，如果不合理地使用缓存，将会出现反直觉地false sharing的问题。</p>\n<h3 id=\"4-1-false-sharing的成因\"><a href=\"#4-1-false-sharing的成因\" class=\"headerlink\" title=\"4.1 false sharing的成因\"></a>4.1 false sharing的成因</h3><p><img src=\"/images/cache-friendly-2.png\" alt=\"image.png\"><br>如图所示，一个运行在处理器 core1上的线程想要更新变量 X 的值，同时另外一个运行在处理器 core2 上的线程想要更新变量 Y 的值。但是，这两个频繁改动的变量都处于同一条缓存行。两个线程就会轮番发送Request For Owner消息（写请求之前的独占声明），占得此缓存行的拥有权。当 core1 取得了拥有权开始更新 X，则 core2 对应的缓存行需要设为 I 状态。当 core2 取得了拥有权开始更新 Y，则 core1 对应的缓存行需要设为 I 状态(失效态)。轮番夺取拥有权不但带来大量的 RFO 消息，而且如果某个线程需要读此行数据时，L1 和 L2 缓存上都是失效数据，只有 L3 缓存上是同步好的数据。从前一篇我们知道，读 L3 的数据非常影响性能。更坏的情况是跨槽读取，L3 都要 miss，只能从内存上加载。<br>表面上 X 和 Y 都是被独立线程操作的，而且两操作之间也没有任何关系。只不过它们共享了一个缓存行，但所有竞争冲突都是来源于共享。</p>\n<h3 id=\"4-2-false-sharing的解法\"><a href=\"#4-2-false-sharing的解法\" class=\"headerlink\" title=\"4.2 false sharing的解法\"></a>4.2 false sharing的解法</h3><p>一个解决思路，就是让不同线程操作的对象处于不同的缓存行即可。<br>具体方法就是缓存行填充（Padding） 。我们使得可能产生写冲突的对象处于不同的缓存行，就避免了伪共享( 64 位系统超过缓存行的 64 字节也无所谓，只要保证不同线程不操作同一缓存行就可以)。</p>\n"},{"title":"C++无锁编程(一)","date":"2023-12-11T15:09:07.000Z","_content":"所谓的无锁编程，真的存在吗？\n# 1 无锁编程的背景\n## 1.1 需要互斥锁的原因\n在传统的多线程、多进程的编程模式中，互斥锁是一种不可或缺的工具。\n在本质上，可以归结为两种原因：\n\n1. 需要安全地并发访问共享资源。\n2. 需要在共享资源上控制访问顺序。\n\n它们都将确保代码在的某些线程不安全部分不会并发执行或者以错误的顺序执行。\n## 1.2 互斥锁存在的问题\n### 1.2.1 互斥锁的本质\n互斥锁本质上作为一个状态值，本身和一个共享资源绑定在一起，逻辑上可以简单将互斥锁理解为如下结构。\n```cpp\nstruct mutex_lock{\n    atomic_t state;\n    object owner;\n    queue waiting_threads;\n}\n```\n在 CPU 的其中一个核上的线程在执行到加锁逻辑时，会根据这个锁的 owner 找到其对应的状态 state 值，会根据当前状态会有两种可能：\n\n1. 如果 state 是未被锁的状态，则当前 CPU 核正常执行该线程接下来的代码，同时修改 state 值为已被锁的状态，并将状态同步给其他 CPU 核；\n2. 如果 state 是已被锁的状态，则当前 CPU 核不再继续往下执行该线程代码，而是将线程加入等待队列wait_threads，等待互斥锁退出后重新被调度。\n\n在第二种情况中，由于state 被锁，所以导致了当前CPU正在执行的线程被挂起，操作系统会给核分配其他活动着的线程的代码来执行，也就产生了“**线程切换**”。\n### 1.2.2 互斥锁带来的开销\n#### 1.2.2.1 互斥锁本身的开销\n使用锁需要额外的资源，例如锁的内存空间，以及用于初始化、销毁、获取和释放锁的 CPU 资源。我们使用锁来保护对共享资源的访问的任何地方，都会有额外的开销。\n#### 1.2.2.2 线程切换的开销\n一次线程切换意味着3us左右的开销（粗略数据，根据不同的CPU规格存在差异）\n**直接开销：**\n\n1. 切换页表全局目录\n2. 切换内核态堆栈\n3. 切换硬件上下文（寄存器内数据，包括下一条指令地址，执行中函数栈顶、栈底地址等）\n4. 刷新TLB（在切换后进行页表查询时将全部击穿TLB）\n\n**间接开销：**\n间接开销主要在于切换之后，各种缓存并不热，速度运行会变慢慢一些。如果始终都在一个CPU上调度还好一些，如果跨CPU的话，之前热起来的TLB、L1、L2、L3因为运行的进程已经变了，所以以局部性原理cache起来的代码、数据也都没有用了，导致新进程穿透到内存的IO会变多。 \n\n感兴趣的同学可以参考这篇文章：\n[https://www.usenix.org/legacy/events/expcs07/papers/2-li.pdf](https://www.usenix.org/legacy/events/expcs07/papers/2-li.pdf)\n# 2 无锁编程原理\n继续回到上文的需要互斥锁的原因往下说，想要完全不存在锁的话，那就要从根源上保证访问共享资源时候不会冲突，这显然是无法做到的。\n所以，身为程序开发者，只能从另外的角度来消除锁的影响。\n## 2.1 从自旋锁说起\n直接针对上面问题出发，我们已经得到了互斥锁的开销来自于线程切换的结论。\n那么如果针对线程切换的开销的话，那就用自旋锁来代替互斥锁。当发生无法抢占锁的时候，拒绝被操作系统调度，用死循环占用核资源。下面是一把非常简单粗暴的自旋锁：\n```cpp\natomic<bool> isLock = false;\nvoid ThreadFunc(){\n    bool expect = flase;\n    while(!isLock.compare_exchange_weak(expect,true)){\n        expect = false;\n    }\n    //do something\n    isLock.store(false);\n}\n\n```\n这种设计存在着一些问题，比如自旋时浪费资源过多等等，但是这些先不重要。重要的是可以先探究一下它作为一把自旋锁，能保证安全的合理性在哪里。\n## 2.2 atomic凭什么保证原子性?\n上面的自旋锁的粗暴实现，有一个很基础的前提，就是 isLock.compare_exchange_weak (expect,true) 这个操作对于多线程的并发操作来说是原子的，是多线程中最小的且不可并行化的操作。C++ 11宣称atomic类型的变量保证了该对象的原子性，那么具体在操作系统层面的实现基础是什么？\n事实上，操作系统对原子性的操作保障无能为力，原子性的保障是来自于硬件层的支持。\n在传统的CPU中，执行一条普通的指令是需要取指、译码、执行、写回结果等许多步骤的，这些指令是可以打断，可以相互穿插的，为了多线程的编程，CPU不得不专门提供一条Test and Exchange指令，把“检测内容，等于xx则修改其值”这样必须两三条指令才能完成的操作整合进一条指令来保障这个 isLock = xx 这个操作不被打断或者穿插。\n## 2.3 如果多核条件下原子性还存在吗？\n但是现代化的CPU都不能单核那么简单的，基本上都是多CPU在并发处理指令，并发处理指令则必定会遇到缓存数据与内存数据之间可能存在不一致的情况：如果线程a和b位于两个不同的CPU核上，那么确定保障了对同一个变量写的原子性吗？\n### 2.3.1 单核心CPU的写策略\n先简单回顾一下单核心CPU的两种写策略：\n\n- **写直达**：CPU每次访问修改数据时，无论数据在不在缓存中，都将修改后的数据同步到内存中，缓存数据与内存数据保持**强一致性**，这种做法影响写操作的性能。\n- **写回**：为了避免每次写操作都要进行数据同步带来的性能损失，写回策略里发生读写操作时：\n   - 如果缓存行中命中了数据，写操作对缓存行中数据进行更新，并标记该缓存行为已修改。\n   - 如果缓存中未命中数据，且数据所对应的缓存行中存放了其他数据：\n      - **若该缓存行被标记为已修改**，读写操作都会将缓存行中现存的数据**写回**内存中，再将当前要获取的数据从内存读到缓存行，写操作对数据进行更新后标记该缓存行为已修改；\n      - **若该缓存行未被标记为已修改**，读写操作都直接将当前要获取的数据从内存读到缓存行。写操作对数据进行更新后标记该缓存行为已修改。\n### 2.3.2 多核心CPU的写策略\n早年的多核CPU是通过锁总线来保障缓存的一致性的，这显然是不太合理的，其他CPU都只能进行等待，过于宽泛的颗粒度导致这个锁效率低下。之后逐渐进化成了写传播模式。\n\n- **写传播：**CPU进行缓存数据更新时需要告知其他CPU\n\n如果出现了多个CPU对同一个数据操作的告知，则要求CPU对同一数据的修改应当保证事务**串行化**，否则会出现问题。\n举个例子：CPU1、CPU2同时修改了数据A，CPU1把修改数据广播给CPU2、CPU3、CPU4，CPU2将修改数据广播给了CPU1、CPU3、CPU4，如果CPU3先接收到了CPU1的修改后接收到了CPU2的修改，而CPU4的接收顺序与3相反，此时3、4中A数据的值就可能不一致了，CPU1、CPU2互相接收对方的修改数据也会导致数据不一致的情况。\nCPU的写传播是通过总线进行传播的，单纯的总线传播是无法保障事务的串行化的，需要依赖于缓存一致性协议（MESI）。\nMESI首先规定了缓存的四种状态：\n\n- _Modified_，已修改\n- _Exclusive_，独占\n- _Shared_，共享\n- _Invalidated_，已失效\n\n![图片_20231214231518.png](/images/lock-free-programming-1.png)\n### 2.3.3 一些其他的引申\n缓存一致性协议确实可以保障多核CPU缓存一致性，但是由于需要广播所以过于低效，所以实际CPU并不会遵守这个协议，为了提高性能CPU实际上存在着 Store Buffer和Invalidate Queue这两个机制，但是这边不进行展开了。\n## 2.4 是否可能存在指令乱序的问题？\n### 2.4.1 跨线程的无依赖指令可能存在乱序\n到目前为止，我们已经从捋清楚了在多核CPU的情况下，对某个atomic变量进行修改操作是原子性的这一事件的声明。接下来我们需要面对另外一个问题：指令乱序。\n```cpp\n//共享变量\nint a, b, c = 0;\n\nvoid thread1() {\n    a = 1;  //1\n    b = a;  //2\n    c = 1;  //3\n}\n\nvoid thread2() {\n    while(c == 0) continue; //4 \n    assert(b == 1); //5\n}\n```\n由于指令重排的存在可能导致1、3、4、5、2的执行顺序的出现。这将超出我们对共享资源上访问顺序的控制。\n### 2.4.2 通过内存屏障解决指令乱序问题\n#### 2.4.2.1 内存屏障概念\n内存屏障就是将内存/缓存的读写操作过程进行分隔。\n缓存和内存之间的操作分为 Store 和 Load 两种。\n\n- Store：将处理器缓存的数据刷新到内存中。\n- Load：将内存存储的数据拷贝到处理器的缓存中。\n\n![图片_20231214231440.png](/images/lock-free-programming-2.png)\n从上表中可以看出来，内存屏障的主要作用就是通过**强制读写内存来间接避免指令重排**。\n所以，在之前那个程序中进行如下更改就可以避免指令重排，强制保障执行顺序为12345：\n```cpp\n//共享变量\nint a, b, c = 0;\n\nvoid thread1() {\n    a = 1;  //1\n    b = a;  //2\n    StoreStoreBarriers();\n    c = 1;  //3\n}\n\nvoid thread2() {\n    while(c == 0) continue; //4 \n    LoadLoadBarriers();\n    assert(b == 1); //5\n}\n```\n#### 2.4.2.2 C++对内存屏障提供的接口\n假设在编程过程中存在大量原子读写操作，如果全部操作都不允许指令重排，也就是严格保证顺序一致性，虽然运行结果很容易符合开发者编程预期，降低了开发难度，但是这样会很大程度影响 CPU 执行性能。\n因此C++ 通过引入内存序接口，提供了控制 CPU 缓存同步的能力给开发者，让内存读写的顺序更加灵活可控。C++ 的内存序允许按照批次保证内存读写顺序，而不必对每一个读写操作保证，也就是说批次和批次之间保持顺序一致性，批次内部保持松散顺序就行。\nC++提供了六种严格度不同的内存序：\n```cpp\ntypedef enum memory_order\n{\n    memory_order_relaxed,\n    memory_order_acquire,\n    memory_order_release,\n    memory_order_consume,\n    memory_order_acq_rel,\n    memory_order_seq_cst,\n} memory_oder;\n```\n**memory_order_relaxed**是最松散的内存序，使用这种内存序的多个内存操作之间同一个线程里还是按照happens-before（happens-before 指的是内存模型中两项操作的顺序关系。例如说操作 A 先于操作 B，也就是说操作 A 发生在操作 B 之前，操作 A 产生的影响能够被操作 B 观察到。这里的「影响」包括：内存中共享变量的值、发送了消息、调用了方法等）的关系执行，但是不同线程之间的执行关系是任意的。\n在以下代码的示例中，使用了**memory_order_relaxed**内存序，执行顺序有可能是0或者42\n```cpp\natomic<int> guard(0);\nint payload = 0;\n\n// 在线程1运行的函数\nvoid thread1()\n{\n    payload = 42;//1\n    guard.store(1, std::memory_order_relaxed);//2\n}\n\n// 在线程2运行的函数\nvoid thread2()\n{\n    if (guard.load(std::memory_order_relaxed) != 0)//3\n    {\n        p = payload;//4\n    }\n}\n```\n**memory_order_seq_cst**在底层同时使用了 StoreStore 屏障和 LoadLoad 屏障来实现，因此保证了内存读写顺序和指令顺序一是致的。这种内存序要严格控制每一次内存读写的顺序，所以执行效率是所有内程序里最低的。顺序一致性序列是完全保证内存读写顺序和指令顺序一致的，所以最终的 p 值为 42。\n```cpp\natomic<int> guard(0);\nint payload = 0;\n\n// 在线程1运行的函数\nvoid thread1()\n{\n    payload = 42;\n    guard.store(1, std::memory_order_seq_cst);\n}\n\n// 在线程2运行的函数\nvoid thread2()\n{\n    if (guard.load(std::memory_order_seq_cst) != 0)\n    {\n        p = payload;\n    }\n}\n```\n**memory_order_release** 和 **memory_order_acquire**是释放和获取序列。\nrelease 底层使用了 StoreStore 屏障，保证在此内存操作之前的所有 Store 操作都不可能重排到此操作之后；也可以理解为这个操作使 CPU 将所有缓存写入了内存，使其他缓存可见。\nacquire 底层使用了 LoadLoad 屏障，保存在此内存操作之后的所有 Load 操作都不可能重排到此操作之前；也可以理解为这个操作使 CPU 将所有抛弃了所有缓存，重新从内存读取数据。\n使用这种内存序，保证了 std::memory_order_release 之前的 Store 操作按一个批次同步到其他缓存，同时 std::memory_order_acquire 之后的 Load 操作按一个批次从内存加载数据到缓存，保证了局部的一致性。\n这种内存序因为是按批次来同步缓存的，所以性能优于顺序一致性序列，但是又没有松散序列高效。\n在下面代码中，就是保证写线程写完之后，读线程才开始读的局部一致性，所以最终的 p 值为 42。\n```cpp\natomic<int> guard(0);\nint payload = 0;\n\n// 在线程1运行的函数\nvoid thread1()\n{\n    payload = 42;\n    guard.store(1, std::memory_order_release);\n}\n\n// 在线程2运行的函数\nvoid thread2()\n{\n    if (guard.load(std::memory_order_acquire) != 0)\n    {\n        p = payload;\n    }\n}\n\n```\n**memory_order_release** 和 **memory_order_consume **是数据依赖序列。\nmemory_order_consume 的底层实现并不使用内存屏障，而是分析数据依赖来保证数据依赖链上的指令的顺序一致性。\n在从内存加载数据到缓存的时候，根据数据依赖链的顺序去加载。写入内存还是使用 memory_order_release 的策略不变。这种内存序在多平台方面，支持不是很好，有一些硬件设备并不支持这种内存序列，因此它会被退化成获取-释放序列。\n\n\n\n","source":"_posts/Lock-free-programming.md","raw":"---\ntitle: C++无锁编程(一)\ndate: 2023-12-11 23:09:07\ntags: Cpp\n---\n所谓的无锁编程，真的存在吗？\n# 1 无锁编程的背景\n## 1.1 需要互斥锁的原因\n在传统的多线程、多进程的编程模式中，互斥锁是一种不可或缺的工具。\n在本质上，可以归结为两种原因：\n\n1. 需要安全地并发访问共享资源。\n2. 需要在共享资源上控制访问顺序。\n\n它们都将确保代码在的某些线程不安全部分不会并发执行或者以错误的顺序执行。\n## 1.2 互斥锁存在的问题\n### 1.2.1 互斥锁的本质\n互斥锁本质上作为一个状态值，本身和一个共享资源绑定在一起，逻辑上可以简单将互斥锁理解为如下结构。\n```cpp\nstruct mutex_lock{\n    atomic_t state;\n    object owner;\n    queue waiting_threads;\n}\n```\n在 CPU 的其中一个核上的线程在执行到加锁逻辑时，会根据这个锁的 owner 找到其对应的状态 state 值，会根据当前状态会有两种可能：\n\n1. 如果 state 是未被锁的状态，则当前 CPU 核正常执行该线程接下来的代码，同时修改 state 值为已被锁的状态，并将状态同步给其他 CPU 核；\n2. 如果 state 是已被锁的状态，则当前 CPU 核不再继续往下执行该线程代码，而是将线程加入等待队列wait_threads，等待互斥锁退出后重新被调度。\n\n在第二种情况中，由于state 被锁，所以导致了当前CPU正在执行的线程被挂起，操作系统会给核分配其他活动着的线程的代码来执行，也就产生了“**线程切换**”。\n### 1.2.2 互斥锁带来的开销\n#### 1.2.2.1 互斥锁本身的开销\n使用锁需要额外的资源，例如锁的内存空间，以及用于初始化、销毁、获取和释放锁的 CPU 资源。我们使用锁来保护对共享资源的访问的任何地方，都会有额外的开销。\n#### 1.2.2.2 线程切换的开销\n一次线程切换意味着3us左右的开销（粗略数据，根据不同的CPU规格存在差异）\n**直接开销：**\n\n1. 切换页表全局目录\n2. 切换内核态堆栈\n3. 切换硬件上下文（寄存器内数据，包括下一条指令地址，执行中函数栈顶、栈底地址等）\n4. 刷新TLB（在切换后进行页表查询时将全部击穿TLB）\n\n**间接开销：**\n间接开销主要在于切换之后，各种缓存并不热，速度运行会变慢慢一些。如果始终都在一个CPU上调度还好一些，如果跨CPU的话，之前热起来的TLB、L1、L2、L3因为运行的进程已经变了，所以以局部性原理cache起来的代码、数据也都没有用了，导致新进程穿透到内存的IO会变多。 \n\n感兴趣的同学可以参考这篇文章：\n[https://www.usenix.org/legacy/events/expcs07/papers/2-li.pdf](https://www.usenix.org/legacy/events/expcs07/papers/2-li.pdf)\n# 2 无锁编程原理\n继续回到上文的需要互斥锁的原因往下说，想要完全不存在锁的话，那就要从根源上保证访问共享资源时候不会冲突，这显然是无法做到的。\n所以，身为程序开发者，只能从另外的角度来消除锁的影响。\n## 2.1 从自旋锁说起\n直接针对上面问题出发，我们已经得到了互斥锁的开销来自于线程切换的结论。\n那么如果针对线程切换的开销的话，那就用自旋锁来代替互斥锁。当发生无法抢占锁的时候，拒绝被操作系统调度，用死循环占用核资源。下面是一把非常简单粗暴的自旋锁：\n```cpp\natomic<bool> isLock = false;\nvoid ThreadFunc(){\n    bool expect = flase;\n    while(!isLock.compare_exchange_weak(expect,true)){\n        expect = false;\n    }\n    //do something\n    isLock.store(false);\n}\n\n```\n这种设计存在着一些问题，比如自旋时浪费资源过多等等，但是这些先不重要。重要的是可以先探究一下它作为一把自旋锁，能保证安全的合理性在哪里。\n## 2.2 atomic凭什么保证原子性?\n上面的自旋锁的粗暴实现，有一个很基础的前提，就是 isLock.compare_exchange_weak (expect,true) 这个操作对于多线程的并发操作来说是原子的，是多线程中最小的且不可并行化的操作。C++ 11宣称atomic类型的变量保证了该对象的原子性，那么具体在操作系统层面的实现基础是什么？\n事实上，操作系统对原子性的操作保障无能为力，原子性的保障是来自于硬件层的支持。\n在传统的CPU中，执行一条普通的指令是需要取指、译码、执行、写回结果等许多步骤的，这些指令是可以打断，可以相互穿插的，为了多线程的编程，CPU不得不专门提供一条Test and Exchange指令，把“检测内容，等于xx则修改其值”这样必须两三条指令才能完成的操作整合进一条指令来保障这个 isLock = xx 这个操作不被打断或者穿插。\n## 2.3 如果多核条件下原子性还存在吗？\n但是现代化的CPU都不能单核那么简单的，基本上都是多CPU在并发处理指令，并发处理指令则必定会遇到缓存数据与内存数据之间可能存在不一致的情况：如果线程a和b位于两个不同的CPU核上，那么确定保障了对同一个变量写的原子性吗？\n### 2.3.1 单核心CPU的写策略\n先简单回顾一下单核心CPU的两种写策略：\n\n- **写直达**：CPU每次访问修改数据时，无论数据在不在缓存中，都将修改后的数据同步到内存中，缓存数据与内存数据保持**强一致性**，这种做法影响写操作的性能。\n- **写回**：为了避免每次写操作都要进行数据同步带来的性能损失，写回策略里发生读写操作时：\n   - 如果缓存行中命中了数据，写操作对缓存行中数据进行更新，并标记该缓存行为已修改。\n   - 如果缓存中未命中数据，且数据所对应的缓存行中存放了其他数据：\n      - **若该缓存行被标记为已修改**，读写操作都会将缓存行中现存的数据**写回**内存中，再将当前要获取的数据从内存读到缓存行，写操作对数据进行更新后标记该缓存行为已修改；\n      - **若该缓存行未被标记为已修改**，读写操作都直接将当前要获取的数据从内存读到缓存行。写操作对数据进行更新后标记该缓存行为已修改。\n### 2.3.2 多核心CPU的写策略\n早年的多核CPU是通过锁总线来保障缓存的一致性的，这显然是不太合理的，其他CPU都只能进行等待，过于宽泛的颗粒度导致这个锁效率低下。之后逐渐进化成了写传播模式。\n\n- **写传播：**CPU进行缓存数据更新时需要告知其他CPU\n\n如果出现了多个CPU对同一个数据操作的告知，则要求CPU对同一数据的修改应当保证事务**串行化**，否则会出现问题。\n举个例子：CPU1、CPU2同时修改了数据A，CPU1把修改数据广播给CPU2、CPU3、CPU4，CPU2将修改数据广播给了CPU1、CPU3、CPU4，如果CPU3先接收到了CPU1的修改后接收到了CPU2的修改，而CPU4的接收顺序与3相反，此时3、4中A数据的值就可能不一致了，CPU1、CPU2互相接收对方的修改数据也会导致数据不一致的情况。\nCPU的写传播是通过总线进行传播的，单纯的总线传播是无法保障事务的串行化的，需要依赖于缓存一致性协议（MESI）。\nMESI首先规定了缓存的四种状态：\n\n- _Modified_，已修改\n- _Exclusive_，独占\n- _Shared_，共享\n- _Invalidated_，已失效\n\n![图片_20231214231518.png](/images/lock-free-programming-1.png)\n### 2.3.3 一些其他的引申\n缓存一致性协议确实可以保障多核CPU缓存一致性，但是由于需要广播所以过于低效，所以实际CPU并不会遵守这个协议，为了提高性能CPU实际上存在着 Store Buffer和Invalidate Queue这两个机制，但是这边不进行展开了。\n## 2.4 是否可能存在指令乱序的问题？\n### 2.4.1 跨线程的无依赖指令可能存在乱序\n到目前为止，我们已经从捋清楚了在多核CPU的情况下，对某个atomic变量进行修改操作是原子性的这一事件的声明。接下来我们需要面对另外一个问题：指令乱序。\n```cpp\n//共享变量\nint a, b, c = 0;\n\nvoid thread1() {\n    a = 1;  //1\n    b = a;  //2\n    c = 1;  //3\n}\n\nvoid thread2() {\n    while(c == 0) continue; //4 \n    assert(b == 1); //5\n}\n```\n由于指令重排的存在可能导致1、3、4、5、2的执行顺序的出现。这将超出我们对共享资源上访问顺序的控制。\n### 2.4.2 通过内存屏障解决指令乱序问题\n#### 2.4.2.1 内存屏障概念\n内存屏障就是将内存/缓存的读写操作过程进行分隔。\n缓存和内存之间的操作分为 Store 和 Load 两种。\n\n- Store：将处理器缓存的数据刷新到内存中。\n- Load：将内存存储的数据拷贝到处理器的缓存中。\n\n![图片_20231214231440.png](/images/lock-free-programming-2.png)\n从上表中可以看出来，内存屏障的主要作用就是通过**强制读写内存来间接避免指令重排**。\n所以，在之前那个程序中进行如下更改就可以避免指令重排，强制保障执行顺序为12345：\n```cpp\n//共享变量\nint a, b, c = 0;\n\nvoid thread1() {\n    a = 1;  //1\n    b = a;  //2\n    StoreStoreBarriers();\n    c = 1;  //3\n}\n\nvoid thread2() {\n    while(c == 0) continue; //4 \n    LoadLoadBarriers();\n    assert(b == 1); //5\n}\n```\n#### 2.4.2.2 C++对内存屏障提供的接口\n假设在编程过程中存在大量原子读写操作，如果全部操作都不允许指令重排，也就是严格保证顺序一致性，虽然运行结果很容易符合开发者编程预期，降低了开发难度，但是这样会很大程度影响 CPU 执行性能。\n因此C++ 通过引入内存序接口，提供了控制 CPU 缓存同步的能力给开发者，让内存读写的顺序更加灵活可控。C++ 的内存序允许按照批次保证内存读写顺序，而不必对每一个读写操作保证，也就是说批次和批次之间保持顺序一致性，批次内部保持松散顺序就行。\nC++提供了六种严格度不同的内存序：\n```cpp\ntypedef enum memory_order\n{\n    memory_order_relaxed,\n    memory_order_acquire,\n    memory_order_release,\n    memory_order_consume,\n    memory_order_acq_rel,\n    memory_order_seq_cst,\n} memory_oder;\n```\n**memory_order_relaxed**是最松散的内存序，使用这种内存序的多个内存操作之间同一个线程里还是按照happens-before（happens-before 指的是内存模型中两项操作的顺序关系。例如说操作 A 先于操作 B，也就是说操作 A 发生在操作 B 之前，操作 A 产生的影响能够被操作 B 观察到。这里的「影响」包括：内存中共享变量的值、发送了消息、调用了方法等）的关系执行，但是不同线程之间的执行关系是任意的。\n在以下代码的示例中，使用了**memory_order_relaxed**内存序，执行顺序有可能是0或者42\n```cpp\natomic<int> guard(0);\nint payload = 0;\n\n// 在线程1运行的函数\nvoid thread1()\n{\n    payload = 42;//1\n    guard.store(1, std::memory_order_relaxed);//2\n}\n\n// 在线程2运行的函数\nvoid thread2()\n{\n    if (guard.load(std::memory_order_relaxed) != 0)//3\n    {\n        p = payload;//4\n    }\n}\n```\n**memory_order_seq_cst**在底层同时使用了 StoreStore 屏障和 LoadLoad 屏障来实现，因此保证了内存读写顺序和指令顺序一是致的。这种内存序要严格控制每一次内存读写的顺序，所以执行效率是所有内程序里最低的。顺序一致性序列是完全保证内存读写顺序和指令顺序一致的，所以最终的 p 值为 42。\n```cpp\natomic<int> guard(0);\nint payload = 0;\n\n// 在线程1运行的函数\nvoid thread1()\n{\n    payload = 42;\n    guard.store(1, std::memory_order_seq_cst);\n}\n\n// 在线程2运行的函数\nvoid thread2()\n{\n    if (guard.load(std::memory_order_seq_cst) != 0)\n    {\n        p = payload;\n    }\n}\n```\n**memory_order_release** 和 **memory_order_acquire**是释放和获取序列。\nrelease 底层使用了 StoreStore 屏障，保证在此内存操作之前的所有 Store 操作都不可能重排到此操作之后；也可以理解为这个操作使 CPU 将所有缓存写入了内存，使其他缓存可见。\nacquire 底层使用了 LoadLoad 屏障，保存在此内存操作之后的所有 Load 操作都不可能重排到此操作之前；也可以理解为这个操作使 CPU 将所有抛弃了所有缓存，重新从内存读取数据。\n使用这种内存序，保证了 std::memory_order_release 之前的 Store 操作按一个批次同步到其他缓存，同时 std::memory_order_acquire 之后的 Load 操作按一个批次从内存加载数据到缓存，保证了局部的一致性。\n这种内存序因为是按批次来同步缓存的，所以性能优于顺序一致性序列，但是又没有松散序列高效。\n在下面代码中，就是保证写线程写完之后，读线程才开始读的局部一致性，所以最终的 p 值为 42。\n```cpp\natomic<int> guard(0);\nint payload = 0;\n\n// 在线程1运行的函数\nvoid thread1()\n{\n    payload = 42;\n    guard.store(1, std::memory_order_release);\n}\n\n// 在线程2运行的函数\nvoid thread2()\n{\n    if (guard.load(std::memory_order_acquire) != 0)\n    {\n        p = payload;\n    }\n}\n\n```\n**memory_order_release** 和 **memory_order_consume **是数据依赖序列。\nmemory_order_consume 的底层实现并不使用内存屏障，而是分析数据依赖来保证数据依赖链上的指令的顺序一致性。\n在从内存加载数据到缓存的时候，根据数据依赖链的顺序去加载。写入内存还是使用 memory_order_release 的策略不变。这种内存序在多平台方面，支持不是很好，有一些硬件设备并不支持这种内存序列，因此它会被退化成获取-释放序列。\n\n\n\n","slug":"Lock-free-programming","published":1,"updated":"2023-12-14T15:18:47.854Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cls21ghtq0001ygx55ii23rhs","content":"<p>所谓的无锁编程，真的存在吗？</p>\n<h1 id=\"1-无锁编程的背景\"><a href=\"#1-无锁编程的背景\" class=\"headerlink\" title=\"1 无锁编程的背景\"></a>1 无锁编程的背景</h1><h2 id=\"1-1-需要互斥锁的原因\"><a href=\"#1-1-需要互斥锁的原因\" class=\"headerlink\" title=\"1.1 需要互斥锁的原因\"></a>1.1 需要互斥锁的原因</h2><p>在传统的多线程、多进程的编程模式中，互斥锁是一种不可或缺的工具。<br>在本质上，可以归结为两种原因：</p>\n<ol>\n<li>需要安全地并发访问共享资源。</li>\n<li>需要在共享资源上控制访问顺序。</li>\n</ol>\n<p>它们都将确保代码在的某些线程不安全部分不会并发执行或者以错误的顺序执行。</p>\n<h2 id=\"1-2-互斥锁存在的问题\"><a href=\"#1-2-互斥锁存在的问题\" class=\"headerlink\" title=\"1.2 互斥锁存在的问题\"></a>1.2 互斥锁存在的问题</h2><h3 id=\"1-2-1-互斥锁的本质\"><a href=\"#1-2-1-互斥锁的本质\" class=\"headerlink\" title=\"1.2.1 互斥锁的本质\"></a>1.2.1 互斥锁的本质</h3><p>互斥锁本质上作为一个状态值，本身和一个共享资源绑定在一起，逻辑上可以简单将互斥锁理解为如下结构。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">struct</span> <span class=\"title class_\">mutex_lock</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">atomic_t</span> state;</span><br><span class=\"line\">    object owner;</span><br><span class=\"line\">    queue waiting_threads;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在 CPU 的其中一个核上的线程在执行到加锁逻辑时，会根据这个锁的 owner 找到其对应的状态 state 值，会根据当前状态会有两种可能：</p>\n<ol>\n<li>如果 state 是未被锁的状态，则当前 CPU 核正常执行该线程接下来的代码，同时修改 state 值为已被锁的状态，并将状态同步给其他 CPU 核；</li>\n<li>如果 state 是已被锁的状态，则当前 CPU 核不再继续往下执行该线程代码，而是将线程加入等待队列wait_threads，等待互斥锁退出后重新被调度。</li>\n</ol>\n<p>在第二种情况中，由于state 被锁，所以导致了当前CPU正在执行的线程被挂起，操作系统会给核分配其他活动着的线程的代码来执行，也就产生了“<strong>线程切换</strong>”。</p>\n<h3 id=\"1-2-2-互斥锁带来的开销\"><a href=\"#1-2-2-互斥锁带来的开销\" class=\"headerlink\" title=\"1.2.2 互斥锁带来的开销\"></a>1.2.2 互斥锁带来的开销</h3><h4 id=\"1-2-2-1-互斥锁本身的开销\"><a href=\"#1-2-2-1-互斥锁本身的开销\" class=\"headerlink\" title=\"1.2.2.1 互斥锁本身的开销\"></a>1.2.2.1 互斥锁本身的开销</h4><p>使用锁需要额外的资源，例如锁的内存空间，以及用于初始化、销毁、获取和释放锁的 CPU 资源。我们使用锁来保护对共享资源的访问的任何地方，都会有额外的开销。</p>\n<h4 id=\"1-2-2-2-线程切换的开销\"><a href=\"#1-2-2-2-线程切换的开销\" class=\"headerlink\" title=\"1.2.2.2 线程切换的开销\"></a>1.2.2.2 线程切换的开销</h4><p>一次线程切换意味着3us左右的开销（粗略数据，根据不同的CPU规格存在差异）<br><strong>直接开销：</strong></p>\n<ol>\n<li>切换页表全局目录</li>\n<li>切换内核态堆栈</li>\n<li>切换硬件上下文（寄存器内数据，包括下一条指令地址，执行中函数栈顶、栈底地址等）</li>\n<li>刷新TLB（在切换后进行页表查询时将全部击穿TLB）</li>\n</ol>\n<p><strong>间接开销：</strong><br>间接开销主要在于切换之后，各种缓存并不热，速度运行会变慢慢一些。如果始终都在一个CPU上调度还好一些，如果跨CPU的话，之前热起来的TLB、L1、L2、L3因为运行的进程已经变了，所以以局部性原理cache起来的代码、数据也都没有用了，导致新进程穿透到内存的IO会变多。 </p>\n<p>感兴趣的同学可以参考这篇文章：<br><a href=\"https://www.usenix.org/legacy/events/expcs07/papers/2-li.pdf\">https://www.usenix.org/legacy/events/expcs07/papers/2-li.pdf</a></p>\n<h1 id=\"2-无锁编程原理\"><a href=\"#2-无锁编程原理\" class=\"headerlink\" title=\"2 无锁编程原理\"></a>2 无锁编程原理</h1><p>继续回到上文的需要互斥锁的原因往下说，想要完全不存在锁的话，那就要从根源上保证访问共享资源时候不会冲突，这显然是无法做到的。<br>所以，身为程序开发者，只能从另外的角度来消除锁的影响。</p>\n<h2 id=\"2-1-从自旋锁说起\"><a href=\"#2-1-从自旋锁说起\" class=\"headerlink\" title=\"2.1 从自旋锁说起\"></a>2.1 从自旋锁说起</h2><p>直接针对上面问题出发，我们已经得到了互斥锁的开销来自于线程切换的结论。<br>那么如果针对线程切换的开销的话，那就用自旋锁来代替互斥锁。当发生无法抢占锁的时候，拒绝被操作系统调度，用死循环占用核资源。下面是一把非常简单粗暴的自旋锁：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">atomic&lt;<span class=\"type\">bool</span>&gt; isLock = <span class=\"literal\">false</span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">ThreadFunc</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">bool</span> expect = flase;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(!isLock.<span class=\"built_in\">compare_exchange_weak</span>(expect,<span class=\"literal\">true</span>))&#123;</span><br><span class=\"line\">        expect = <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//do something</span></span><br><span class=\"line\">    isLock.<span class=\"built_in\">store</span>(<span class=\"literal\">false</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>这种设计存在着一些问题，比如自旋时浪费资源过多等等，但是这些先不重要。重要的是可以先探究一下它作为一把自旋锁，能保证安全的合理性在哪里。</p>\n<h2 id=\"2-2-atomic凭什么保证原子性\"><a href=\"#2-2-atomic凭什么保证原子性\" class=\"headerlink\" title=\"2.2 atomic凭什么保证原子性?\"></a>2.2 atomic凭什么保证原子性?</h2><p>上面的自旋锁的粗暴实现，有一个很基础的前提，就是 isLock.compare_exchange_weak (expect,true) 这个操作对于多线程的并发操作来说是原子的，是多线程中最小的且不可并行化的操作。C++ 11宣称atomic类型的变量保证了该对象的原子性，那么具体在操作系统层面的实现基础是什么？<br>事实上，操作系统对原子性的操作保障无能为力，原子性的保障是来自于硬件层的支持。<br>在传统的CPU中，执行一条普通的指令是需要取指、译码、执行、写回结果等许多步骤的，这些指令是可以打断，可以相互穿插的，为了多线程的编程，CPU不得不专门提供一条Test and Exchange指令，把“检测内容，等于xx则修改其值”这样必须两三条指令才能完成的操作整合进一条指令来保障这个 isLock &#x3D; xx 这个操作不被打断或者穿插。</p>\n<h2 id=\"2-3-如果多核条件下原子性还存在吗？\"><a href=\"#2-3-如果多核条件下原子性还存在吗？\" class=\"headerlink\" title=\"2.3 如果多核条件下原子性还存在吗？\"></a>2.3 如果多核条件下原子性还存在吗？</h2><p>但是现代化的CPU都不能单核那么简单的，基本上都是多CPU在并发处理指令，并发处理指令则必定会遇到缓存数据与内存数据之间可能存在不一致的情况：如果线程a和b位于两个不同的CPU核上，那么确定保障了对同一个变量写的原子性吗？</p>\n<h3 id=\"2-3-1-单核心CPU的写策略\"><a href=\"#2-3-1-单核心CPU的写策略\" class=\"headerlink\" title=\"2.3.1 单核心CPU的写策略\"></a>2.3.1 单核心CPU的写策略</h3><p>先简单回顾一下单核心CPU的两种写策略：</p>\n<ul>\n<li><strong>写直达</strong>：CPU每次访问修改数据时，无论数据在不在缓存中，都将修改后的数据同步到内存中，缓存数据与内存数据保持<strong>强一致性</strong>，这种做法影响写操作的性能。</li>\n<li><strong>写回</strong>：为了避免每次写操作都要进行数据同步带来的性能损失，写回策略里发生读写操作时：<ul>\n<li>如果缓存行中命中了数据，写操作对缓存行中数据进行更新，并标记该缓存行为已修改。</li>\n<li>如果缓存中未命中数据，且数据所对应的缓存行中存放了其他数据：<ul>\n<li><strong>若该缓存行被标记为已修改</strong>，读写操作都会将缓存行中现存的数据<strong>写回</strong>内存中，再将当前要获取的数据从内存读到缓存行，写操作对数据进行更新后标记该缓存行为已修改；</li>\n<li><strong>若该缓存行未被标记为已修改</strong>，读写操作都直接将当前要获取的数据从内存读到缓存行。写操作对数据进行更新后标记该缓存行为已修改。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2-3-2-多核心CPU的写策略\"><a href=\"#2-3-2-多核心CPU的写策略\" class=\"headerlink\" title=\"2.3.2 多核心CPU的写策略\"></a>2.3.2 多核心CPU的写策略</h3><p>早年的多核CPU是通过锁总线来保障缓存的一致性的，这显然是不太合理的，其他CPU都只能进行等待，过于宽泛的颗粒度导致这个锁效率低下。之后逐渐进化成了写传播模式。</p>\n<ul>\n<li><strong>写传播：</strong>CPU进行缓存数据更新时需要告知其他CPU</li>\n</ul>\n<p>如果出现了多个CPU对同一个数据操作的告知，则要求CPU对同一数据的修改应当保证事务<strong>串行化</strong>，否则会出现问题。<br>举个例子：CPU1、CPU2同时修改了数据A，CPU1把修改数据广播给CPU2、CPU3、CPU4，CPU2将修改数据广播给了CPU1、CPU3、CPU4，如果CPU3先接收到了CPU1的修改后接收到了CPU2的修改，而CPU4的接收顺序与3相反，此时3、4中A数据的值就可能不一致了，CPU1、CPU2互相接收对方的修改数据也会导致数据不一致的情况。<br>CPU的写传播是通过总线进行传播的，单纯的总线传播是无法保障事务的串行化的，需要依赖于缓存一致性协议（MESI）。<br>MESI首先规定了缓存的四种状态：</p>\n<ul>\n<li>_Modified_，已修改</li>\n<li>_Exclusive_，独占</li>\n<li>_Shared_，共享</li>\n<li>_Invalidated_，已失效</li>\n</ul>\n<p><img src=\"/images/lock-free-programming-1.png\" alt=\"图片_20231214231518.png\"></p>\n<h3 id=\"2-3-3-一些其他的引申\"><a href=\"#2-3-3-一些其他的引申\" class=\"headerlink\" title=\"2.3.3 一些其他的引申\"></a>2.3.3 一些其他的引申</h3><p>缓存一致性协议确实可以保障多核CPU缓存一致性，但是由于需要广播所以过于低效，所以实际CPU并不会遵守这个协议，为了提高性能CPU实际上存在着 Store Buffer和Invalidate Queue这两个机制，但是这边不进行展开了。</p>\n<h2 id=\"2-4-是否可能存在指令乱序的问题？\"><a href=\"#2-4-是否可能存在指令乱序的问题？\" class=\"headerlink\" title=\"2.4 是否可能存在指令乱序的问题？\"></a>2.4 是否可能存在指令乱序的问题？</h2><h3 id=\"2-4-1-跨线程的无依赖指令可能存在乱序\"><a href=\"#2-4-1-跨线程的无依赖指令可能存在乱序\" class=\"headerlink\" title=\"2.4.1 跨线程的无依赖指令可能存在乱序\"></a>2.4.1 跨线程的无依赖指令可能存在乱序</h3><p>到目前为止，我们已经从捋清楚了在多核CPU的情况下，对某个atomic变量进行修改操作是原子性的这一事件的声明。接下来我们需要面对另外一个问题：指令乱序。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//共享变量</span></span><br><span class=\"line\"><span class=\"type\">int</span> a, b, c = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread1</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    a = <span class=\"number\">1</span>;  <span class=\"comment\">//1</span></span><br><span class=\"line\">    b = a;  <span class=\"comment\">//2</span></span><br><span class=\"line\">    c = <span class=\"number\">1</span>;  <span class=\"comment\">//3</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread2</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(c == <span class=\"number\">0</span>) <span class=\"keyword\">continue</span>; <span class=\"comment\">//4 </span></span><br><span class=\"line\">    <span class=\"built_in\">assert</span>(b == <span class=\"number\">1</span>); <span class=\"comment\">//5</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>由于指令重排的存在可能导致1、3、4、5、2的执行顺序的出现。这将超出我们对共享资源上访问顺序的控制。</p>\n<h3 id=\"2-4-2-通过内存屏障解决指令乱序问题\"><a href=\"#2-4-2-通过内存屏障解决指令乱序问题\" class=\"headerlink\" title=\"2.4.2 通过内存屏障解决指令乱序问题\"></a>2.4.2 通过内存屏障解决指令乱序问题</h3><h4 id=\"2-4-2-1-内存屏障概念\"><a href=\"#2-4-2-1-内存屏障概念\" class=\"headerlink\" title=\"2.4.2.1 内存屏障概念\"></a>2.4.2.1 内存屏障概念</h4><p>内存屏障就是将内存&#x2F;缓存的读写操作过程进行分隔。<br>缓存和内存之间的操作分为 Store 和 Load 两种。</p>\n<ul>\n<li>Store：将处理器缓存的数据刷新到内存中。</li>\n<li>Load：将内存存储的数据拷贝到处理器的缓存中。</li>\n</ul>\n<p><img src=\"/images/lock-free-programming-2.png\" alt=\"图片_20231214231440.png\"><br>从上表中可以看出来，内存屏障的主要作用就是通过<strong>强制读写内存来间接避免指令重排</strong>。<br>所以，在之前那个程序中进行如下更改就可以避免指令重排，强制保障执行顺序为12345：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//共享变量</span></span><br><span class=\"line\"><span class=\"type\">int</span> a, b, c = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread1</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    a = <span class=\"number\">1</span>;  <span class=\"comment\">//1</span></span><br><span class=\"line\">    b = a;  <span class=\"comment\">//2</span></span><br><span class=\"line\">    <span class=\"built_in\">StoreStoreBarriers</span>();</span><br><span class=\"line\">    c = <span class=\"number\">1</span>;  <span class=\"comment\">//3</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread2</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(c == <span class=\"number\">0</span>) <span class=\"keyword\">continue</span>; <span class=\"comment\">//4 </span></span><br><span class=\"line\">    <span class=\"built_in\">LoadLoadBarriers</span>();</span><br><span class=\"line\">    <span class=\"built_in\">assert</span>(b == <span class=\"number\">1</span>); <span class=\"comment\">//5</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-4-2-2-C-对内存屏障提供的接口\"><a href=\"#2-4-2-2-C-对内存屏障提供的接口\" class=\"headerlink\" title=\"2.4.2.2 C++对内存屏障提供的接口\"></a>2.4.2.2 C++对内存屏障提供的接口</h4><p>假设在编程过程中存在大量原子读写操作，如果全部操作都不允许指令重排，也就是严格保证顺序一致性，虽然运行结果很容易符合开发者编程预期，降低了开发难度，但是这样会很大程度影响 CPU 执行性能。<br>因此C++ 通过引入内存序接口，提供了控制 CPU 缓存同步的能力给开发者，让内存读写的顺序更加灵活可控。C++ 的内存序允许按照批次保证内存读写顺序，而不必对每一个读写操作保证，也就是说批次和批次之间保持顺序一致性，批次内部保持松散顺序就行。<br>C++提供了六种严格度不同的内存序：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">enum</span> <span class=\"title class_\">memory_order</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    memory_order_relaxed,</span><br><span class=\"line\">    memory_order_acquire,</span><br><span class=\"line\">    memory_order_release,</span><br><span class=\"line\">    memory_order_consume,</span><br><span class=\"line\">    memory_order_acq_rel,</span><br><span class=\"line\">    memory_order_seq_cst,</span><br><span class=\"line\">&#125; memory_oder;</span><br></pre></td></tr></table></figure>\n<p><strong>memory_order_relaxed</strong>是最松散的内存序，使用这种内存序的多个内存操作之间同一个线程里还是按照happens-before（happens-before 指的是内存模型中两项操作的顺序关系。例如说操作 A 先于操作 B，也就是说操作 A 发生在操作 B 之前，操作 A 产生的影响能够被操作 B 观察到。这里的「影响」包括：内存中共享变量的值、发送了消息、调用了方法等）的关系执行，但是不同线程之间的执行关系是任意的。<br>在以下代码的示例中，使用了<strong>memory_order_relaxed</strong>内存序，执行顺序有可能是0或者42</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">atomic&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">guard</span><span class=\"params\">(<span class=\"number\">0</span>)</span></span>;</span><br><span class=\"line\"><span class=\"type\">int</span> payload = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 在线程1运行的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread1</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    payload = <span class=\"number\">42</span>;<span class=\"comment\">//1</span></span><br><span class=\"line\">    guard.<span class=\"built_in\">store</span>(<span class=\"number\">1</span>, std::memory_order_relaxed);<span class=\"comment\">//2</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 在线程2运行的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread2</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (guard.<span class=\"built_in\">load</span>(std::memory_order_relaxed) != <span class=\"number\">0</span>)<span class=\"comment\">//3</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        p = payload;<span class=\"comment\">//4</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>memory_order_seq_cst</strong>在底层同时使用了 StoreStore 屏障和 LoadLoad 屏障来实现，因此保证了内存读写顺序和指令顺序一是致的。这种内存序要严格控制每一次内存读写的顺序，所以执行效率是所有内程序里最低的。顺序一致性序列是完全保证内存读写顺序和指令顺序一致的，所以最终的 p 值为 42。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">atomic&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">guard</span><span class=\"params\">(<span class=\"number\">0</span>)</span></span>;</span><br><span class=\"line\"><span class=\"type\">int</span> payload = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 在线程1运行的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread1</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    payload = <span class=\"number\">42</span>;</span><br><span class=\"line\">    guard.<span class=\"built_in\">store</span>(<span class=\"number\">1</span>, std::memory_order_seq_cst);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 在线程2运行的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread2</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (guard.<span class=\"built_in\">load</span>(std::memory_order_seq_cst) != <span class=\"number\">0</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        p = payload;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>memory_order_release</strong> 和 <strong>memory_order_acquire</strong>是释放和获取序列。<br>release 底层使用了 StoreStore 屏障，保证在此内存操作之前的所有 Store 操作都不可能重排到此操作之后；也可以理解为这个操作使 CPU 将所有缓存写入了内存，使其他缓存可见。<br>acquire 底层使用了 LoadLoad 屏障，保存在此内存操作之后的所有 Load 操作都不可能重排到此操作之前；也可以理解为这个操作使 CPU 将所有抛弃了所有缓存，重新从内存读取数据。<br>使用这种内存序，保证了 std::memory_order_release 之前的 Store 操作按一个批次同步到其他缓存，同时 std::memory_order_acquire 之后的 Load 操作按一个批次从内存加载数据到缓存，保证了局部的一致性。<br>这种内存序因为是按批次来同步缓存的，所以性能优于顺序一致性序列，但是又没有松散序列高效。<br>在下面代码中，就是保证写线程写完之后，读线程才开始读的局部一致性，所以最终的 p 值为 42。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">atomic&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">guard</span><span class=\"params\">(<span class=\"number\">0</span>)</span></span>;</span><br><span class=\"line\"><span class=\"type\">int</span> payload = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 在线程1运行的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread1</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    payload = <span class=\"number\">42</span>;</span><br><span class=\"line\">    guard.<span class=\"built_in\">store</span>(<span class=\"number\">1</span>, std::memory_order_release);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 在线程2运行的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread2</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (guard.<span class=\"built_in\">load</span>(std::memory_order_acquire) != <span class=\"number\">0</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        p = payload;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p><strong>memory_order_release</strong> 和 **memory_order_consume **是数据依赖序列。<br>memory_order_consume 的底层实现并不使用内存屏障，而是分析数据依赖来保证数据依赖链上的指令的顺序一致性。<br>在从内存加载数据到缓存的时候，根据数据依赖链的顺序去加载。写入内存还是使用 memory_order_release 的策略不变。这种内存序在多平台方面，支持不是很好，有一些硬件设备并不支持这种内存序列，因此它会被退化成获取-释放序列。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>所谓的无锁编程，真的存在吗？</p>\n<h1 id=\"1-无锁编程的背景\"><a href=\"#1-无锁编程的背景\" class=\"headerlink\" title=\"1 无锁编程的背景\"></a>1 无锁编程的背景</h1><h2 id=\"1-1-需要互斥锁的原因\"><a href=\"#1-1-需要互斥锁的原因\" class=\"headerlink\" title=\"1.1 需要互斥锁的原因\"></a>1.1 需要互斥锁的原因</h2><p>在传统的多线程、多进程的编程模式中，互斥锁是一种不可或缺的工具。<br>在本质上，可以归结为两种原因：</p>\n<ol>\n<li>需要安全地并发访问共享资源。</li>\n<li>需要在共享资源上控制访问顺序。</li>\n</ol>\n<p>它们都将确保代码在的某些线程不安全部分不会并发执行或者以错误的顺序执行。</p>\n<h2 id=\"1-2-互斥锁存在的问题\"><a href=\"#1-2-互斥锁存在的问题\" class=\"headerlink\" title=\"1.2 互斥锁存在的问题\"></a>1.2 互斥锁存在的问题</h2><h3 id=\"1-2-1-互斥锁的本质\"><a href=\"#1-2-1-互斥锁的本质\" class=\"headerlink\" title=\"1.2.1 互斥锁的本质\"></a>1.2.1 互斥锁的本质</h3><p>互斥锁本质上作为一个状态值，本身和一个共享资源绑定在一起，逻辑上可以简单将互斥锁理解为如下结构。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">struct</span> <span class=\"title class_\">mutex_lock</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">atomic_t</span> state;</span><br><span class=\"line\">    object owner;</span><br><span class=\"line\">    queue waiting_threads;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在 CPU 的其中一个核上的线程在执行到加锁逻辑时，会根据这个锁的 owner 找到其对应的状态 state 值，会根据当前状态会有两种可能：</p>\n<ol>\n<li>如果 state 是未被锁的状态，则当前 CPU 核正常执行该线程接下来的代码，同时修改 state 值为已被锁的状态，并将状态同步给其他 CPU 核；</li>\n<li>如果 state 是已被锁的状态，则当前 CPU 核不再继续往下执行该线程代码，而是将线程加入等待队列wait_threads，等待互斥锁退出后重新被调度。</li>\n</ol>\n<p>在第二种情况中，由于state 被锁，所以导致了当前CPU正在执行的线程被挂起，操作系统会给核分配其他活动着的线程的代码来执行，也就产生了“<strong>线程切换</strong>”。</p>\n<h3 id=\"1-2-2-互斥锁带来的开销\"><a href=\"#1-2-2-互斥锁带来的开销\" class=\"headerlink\" title=\"1.2.2 互斥锁带来的开销\"></a>1.2.2 互斥锁带来的开销</h3><h4 id=\"1-2-2-1-互斥锁本身的开销\"><a href=\"#1-2-2-1-互斥锁本身的开销\" class=\"headerlink\" title=\"1.2.2.1 互斥锁本身的开销\"></a>1.2.2.1 互斥锁本身的开销</h4><p>使用锁需要额外的资源，例如锁的内存空间，以及用于初始化、销毁、获取和释放锁的 CPU 资源。我们使用锁来保护对共享资源的访问的任何地方，都会有额外的开销。</p>\n<h4 id=\"1-2-2-2-线程切换的开销\"><a href=\"#1-2-2-2-线程切换的开销\" class=\"headerlink\" title=\"1.2.2.2 线程切换的开销\"></a>1.2.2.2 线程切换的开销</h4><p>一次线程切换意味着3us左右的开销（粗略数据，根据不同的CPU规格存在差异）<br><strong>直接开销：</strong></p>\n<ol>\n<li>切换页表全局目录</li>\n<li>切换内核态堆栈</li>\n<li>切换硬件上下文（寄存器内数据，包括下一条指令地址，执行中函数栈顶、栈底地址等）</li>\n<li>刷新TLB（在切换后进行页表查询时将全部击穿TLB）</li>\n</ol>\n<p><strong>间接开销：</strong><br>间接开销主要在于切换之后，各种缓存并不热，速度运行会变慢慢一些。如果始终都在一个CPU上调度还好一些，如果跨CPU的话，之前热起来的TLB、L1、L2、L3因为运行的进程已经变了，所以以局部性原理cache起来的代码、数据也都没有用了，导致新进程穿透到内存的IO会变多。 </p>\n<p>感兴趣的同学可以参考这篇文章：<br><a href=\"https://www.usenix.org/legacy/events/expcs07/papers/2-li.pdf\">https://www.usenix.org/legacy/events/expcs07/papers/2-li.pdf</a></p>\n<h1 id=\"2-无锁编程原理\"><a href=\"#2-无锁编程原理\" class=\"headerlink\" title=\"2 无锁编程原理\"></a>2 无锁编程原理</h1><p>继续回到上文的需要互斥锁的原因往下说，想要完全不存在锁的话，那就要从根源上保证访问共享资源时候不会冲突，这显然是无法做到的。<br>所以，身为程序开发者，只能从另外的角度来消除锁的影响。</p>\n<h2 id=\"2-1-从自旋锁说起\"><a href=\"#2-1-从自旋锁说起\" class=\"headerlink\" title=\"2.1 从自旋锁说起\"></a>2.1 从自旋锁说起</h2><p>直接针对上面问题出发，我们已经得到了互斥锁的开销来自于线程切换的结论。<br>那么如果针对线程切换的开销的话，那就用自旋锁来代替互斥锁。当发生无法抢占锁的时候，拒绝被操作系统调度，用死循环占用核资源。下面是一把非常简单粗暴的自旋锁：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">atomic&lt;<span class=\"type\">bool</span>&gt; isLock = <span class=\"literal\">false</span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">ThreadFunc</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">bool</span> expect = flase;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(!isLock.<span class=\"built_in\">compare_exchange_weak</span>(expect,<span class=\"literal\">true</span>))&#123;</span><br><span class=\"line\">        expect = <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//do something</span></span><br><span class=\"line\">    isLock.<span class=\"built_in\">store</span>(<span class=\"literal\">false</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>这种设计存在着一些问题，比如自旋时浪费资源过多等等，但是这些先不重要。重要的是可以先探究一下它作为一把自旋锁，能保证安全的合理性在哪里。</p>\n<h2 id=\"2-2-atomic凭什么保证原子性\"><a href=\"#2-2-atomic凭什么保证原子性\" class=\"headerlink\" title=\"2.2 atomic凭什么保证原子性?\"></a>2.2 atomic凭什么保证原子性?</h2><p>上面的自旋锁的粗暴实现，有一个很基础的前提，就是 isLock.compare_exchange_weak (expect,true) 这个操作对于多线程的并发操作来说是原子的，是多线程中最小的且不可并行化的操作。C++ 11宣称atomic类型的变量保证了该对象的原子性，那么具体在操作系统层面的实现基础是什么？<br>事实上，操作系统对原子性的操作保障无能为力，原子性的保障是来自于硬件层的支持。<br>在传统的CPU中，执行一条普通的指令是需要取指、译码、执行、写回结果等许多步骤的，这些指令是可以打断，可以相互穿插的，为了多线程的编程，CPU不得不专门提供一条Test and Exchange指令，把“检测内容，等于xx则修改其值”这样必须两三条指令才能完成的操作整合进一条指令来保障这个 isLock &#x3D; xx 这个操作不被打断或者穿插。</p>\n<h2 id=\"2-3-如果多核条件下原子性还存在吗？\"><a href=\"#2-3-如果多核条件下原子性还存在吗？\" class=\"headerlink\" title=\"2.3 如果多核条件下原子性还存在吗？\"></a>2.3 如果多核条件下原子性还存在吗？</h2><p>但是现代化的CPU都不能单核那么简单的，基本上都是多CPU在并发处理指令，并发处理指令则必定会遇到缓存数据与内存数据之间可能存在不一致的情况：如果线程a和b位于两个不同的CPU核上，那么确定保障了对同一个变量写的原子性吗？</p>\n<h3 id=\"2-3-1-单核心CPU的写策略\"><a href=\"#2-3-1-单核心CPU的写策略\" class=\"headerlink\" title=\"2.3.1 单核心CPU的写策略\"></a>2.3.1 单核心CPU的写策略</h3><p>先简单回顾一下单核心CPU的两种写策略：</p>\n<ul>\n<li><strong>写直达</strong>：CPU每次访问修改数据时，无论数据在不在缓存中，都将修改后的数据同步到内存中，缓存数据与内存数据保持<strong>强一致性</strong>，这种做法影响写操作的性能。</li>\n<li><strong>写回</strong>：为了避免每次写操作都要进行数据同步带来的性能损失，写回策略里发生读写操作时：<ul>\n<li>如果缓存行中命中了数据，写操作对缓存行中数据进行更新，并标记该缓存行为已修改。</li>\n<li>如果缓存中未命中数据，且数据所对应的缓存行中存放了其他数据：<ul>\n<li><strong>若该缓存行被标记为已修改</strong>，读写操作都会将缓存行中现存的数据<strong>写回</strong>内存中，再将当前要获取的数据从内存读到缓存行，写操作对数据进行更新后标记该缓存行为已修改；</li>\n<li><strong>若该缓存行未被标记为已修改</strong>，读写操作都直接将当前要获取的数据从内存读到缓存行。写操作对数据进行更新后标记该缓存行为已修改。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2-3-2-多核心CPU的写策略\"><a href=\"#2-3-2-多核心CPU的写策略\" class=\"headerlink\" title=\"2.3.2 多核心CPU的写策略\"></a>2.3.2 多核心CPU的写策略</h3><p>早年的多核CPU是通过锁总线来保障缓存的一致性的，这显然是不太合理的，其他CPU都只能进行等待，过于宽泛的颗粒度导致这个锁效率低下。之后逐渐进化成了写传播模式。</p>\n<ul>\n<li><strong>写传播：</strong>CPU进行缓存数据更新时需要告知其他CPU</li>\n</ul>\n<p>如果出现了多个CPU对同一个数据操作的告知，则要求CPU对同一数据的修改应当保证事务<strong>串行化</strong>，否则会出现问题。<br>举个例子：CPU1、CPU2同时修改了数据A，CPU1把修改数据广播给CPU2、CPU3、CPU4，CPU2将修改数据广播给了CPU1、CPU3、CPU4，如果CPU3先接收到了CPU1的修改后接收到了CPU2的修改，而CPU4的接收顺序与3相反，此时3、4中A数据的值就可能不一致了，CPU1、CPU2互相接收对方的修改数据也会导致数据不一致的情况。<br>CPU的写传播是通过总线进行传播的，单纯的总线传播是无法保障事务的串行化的，需要依赖于缓存一致性协议（MESI）。<br>MESI首先规定了缓存的四种状态：</p>\n<ul>\n<li>_Modified_，已修改</li>\n<li>_Exclusive_，独占</li>\n<li>_Shared_，共享</li>\n<li>_Invalidated_，已失效</li>\n</ul>\n<p><img src=\"/images/lock-free-programming-1.png\" alt=\"图片_20231214231518.png\"></p>\n<h3 id=\"2-3-3-一些其他的引申\"><a href=\"#2-3-3-一些其他的引申\" class=\"headerlink\" title=\"2.3.3 一些其他的引申\"></a>2.3.3 一些其他的引申</h3><p>缓存一致性协议确实可以保障多核CPU缓存一致性，但是由于需要广播所以过于低效，所以实际CPU并不会遵守这个协议，为了提高性能CPU实际上存在着 Store Buffer和Invalidate Queue这两个机制，但是这边不进行展开了。</p>\n<h2 id=\"2-4-是否可能存在指令乱序的问题？\"><a href=\"#2-4-是否可能存在指令乱序的问题？\" class=\"headerlink\" title=\"2.4 是否可能存在指令乱序的问题？\"></a>2.4 是否可能存在指令乱序的问题？</h2><h3 id=\"2-4-1-跨线程的无依赖指令可能存在乱序\"><a href=\"#2-4-1-跨线程的无依赖指令可能存在乱序\" class=\"headerlink\" title=\"2.4.1 跨线程的无依赖指令可能存在乱序\"></a>2.4.1 跨线程的无依赖指令可能存在乱序</h3><p>到目前为止，我们已经从捋清楚了在多核CPU的情况下，对某个atomic变量进行修改操作是原子性的这一事件的声明。接下来我们需要面对另外一个问题：指令乱序。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//共享变量</span></span><br><span class=\"line\"><span class=\"type\">int</span> a, b, c = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread1</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    a = <span class=\"number\">1</span>;  <span class=\"comment\">//1</span></span><br><span class=\"line\">    b = a;  <span class=\"comment\">//2</span></span><br><span class=\"line\">    c = <span class=\"number\">1</span>;  <span class=\"comment\">//3</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread2</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(c == <span class=\"number\">0</span>) <span class=\"keyword\">continue</span>; <span class=\"comment\">//4 </span></span><br><span class=\"line\">    <span class=\"built_in\">assert</span>(b == <span class=\"number\">1</span>); <span class=\"comment\">//5</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>由于指令重排的存在可能导致1、3、4、5、2的执行顺序的出现。这将超出我们对共享资源上访问顺序的控制。</p>\n<h3 id=\"2-4-2-通过内存屏障解决指令乱序问题\"><a href=\"#2-4-2-通过内存屏障解决指令乱序问题\" class=\"headerlink\" title=\"2.4.2 通过内存屏障解决指令乱序问题\"></a>2.4.2 通过内存屏障解决指令乱序问题</h3><h4 id=\"2-4-2-1-内存屏障概念\"><a href=\"#2-4-2-1-内存屏障概念\" class=\"headerlink\" title=\"2.4.2.1 内存屏障概念\"></a>2.4.2.1 内存屏障概念</h4><p>内存屏障就是将内存&#x2F;缓存的读写操作过程进行分隔。<br>缓存和内存之间的操作分为 Store 和 Load 两种。</p>\n<ul>\n<li>Store：将处理器缓存的数据刷新到内存中。</li>\n<li>Load：将内存存储的数据拷贝到处理器的缓存中。</li>\n</ul>\n<p><img src=\"/images/lock-free-programming-2.png\" alt=\"图片_20231214231440.png\"><br>从上表中可以看出来，内存屏障的主要作用就是通过<strong>强制读写内存来间接避免指令重排</strong>。<br>所以，在之前那个程序中进行如下更改就可以避免指令重排，强制保障执行顺序为12345：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//共享变量</span></span><br><span class=\"line\"><span class=\"type\">int</span> a, b, c = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread1</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    a = <span class=\"number\">1</span>;  <span class=\"comment\">//1</span></span><br><span class=\"line\">    b = a;  <span class=\"comment\">//2</span></span><br><span class=\"line\">    <span class=\"built_in\">StoreStoreBarriers</span>();</span><br><span class=\"line\">    c = <span class=\"number\">1</span>;  <span class=\"comment\">//3</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread2</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(c == <span class=\"number\">0</span>) <span class=\"keyword\">continue</span>; <span class=\"comment\">//4 </span></span><br><span class=\"line\">    <span class=\"built_in\">LoadLoadBarriers</span>();</span><br><span class=\"line\">    <span class=\"built_in\">assert</span>(b == <span class=\"number\">1</span>); <span class=\"comment\">//5</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-4-2-2-C-对内存屏障提供的接口\"><a href=\"#2-4-2-2-C-对内存屏障提供的接口\" class=\"headerlink\" title=\"2.4.2.2 C++对内存屏障提供的接口\"></a>2.4.2.2 C++对内存屏障提供的接口</h4><p>假设在编程过程中存在大量原子读写操作，如果全部操作都不允许指令重排，也就是严格保证顺序一致性，虽然运行结果很容易符合开发者编程预期，降低了开发难度，但是这样会很大程度影响 CPU 执行性能。<br>因此C++ 通过引入内存序接口，提供了控制 CPU 缓存同步的能力给开发者，让内存读写的顺序更加灵活可控。C++ 的内存序允许按照批次保证内存读写顺序，而不必对每一个读写操作保证，也就是说批次和批次之间保持顺序一致性，批次内部保持松散顺序就行。<br>C++提供了六种严格度不同的内存序：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">enum</span> <span class=\"title class_\">memory_order</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    memory_order_relaxed,</span><br><span class=\"line\">    memory_order_acquire,</span><br><span class=\"line\">    memory_order_release,</span><br><span class=\"line\">    memory_order_consume,</span><br><span class=\"line\">    memory_order_acq_rel,</span><br><span class=\"line\">    memory_order_seq_cst,</span><br><span class=\"line\">&#125; memory_oder;</span><br></pre></td></tr></table></figure>\n<p><strong>memory_order_relaxed</strong>是最松散的内存序，使用这种内存序的多个内存操作之间同一个线程里还是按照happens-before（happens-before 指的是内存模型中两项操作的顺序关系。例如说操作 A 先于操作 B，也就是说操作 A 发生在操作 B 之前，操作 A 产生的影响能够被操作 B 观察到。这里的「影响」包括：内存中共享变量的值、发送了消息、调用了方法等）的关系执行，但是不同线程之间的执行关系是任意的。<br>在以下代码的示例中，使用了<strong>memory_order_relaxed</strong>内存序，执行顺序有可能是0或者42</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">atomic&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">guard</span><span class=\"params\">(<span class=\"number\">0</span>)</span></span>;</span><br><span class=\"line\"><span class=\"type\">int</span> payload = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 在线程1运行的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread1</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    payload = <span class=\"number\">42</span>;<span class=\"comment\">//1</span></span><br><span class=\"line\">    guard.<span class=\"built_in\">store</span>(<span class=\"number\">1</span>, std::memory_order_relaxed);<span class=\"comment\">//2</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 在线程2运行的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread2</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (guard.<span class=\"built_in\">load</span>(std::memory_order_relaxed) != <span class=\"number\">0</span>)<span class=\"comment\">//3</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        p = payload;<span class=\"comment\">//4</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>memory_order_seq_cst</strong>在底层同时使用了 StoreStore 屏障和 LoadLoad 屏障来实现，因此保证了内存读写顺序和指令顺序一是致的。这种内存序要严格控制每一次内存读写的顺序，所以执行效率是所有内程序里最低的。顺序一致性序列是完全保证内存读写顺序和指令顺序一致的，所以最终的 p 值为 42。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">atomic&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">guard</span><span class=\"params\">(<span class=\"number\">0</span>)</span></span>;</span><br><span class=\"line\"><span class=\"type\">int</span> payload = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 在线程1运行的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread1</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    payload = <span class=\"number\">42</span>;</span><br><span class=\"line\">    guard.<span class=\"built_in\">store</span>(<span class=\"number\">1</span>, std::memory_order_seq_cst);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 在线程2运行的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread2</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (guard.<span class=\"built_in\">load</span>(std::memory_order_seq_cst) != <span class=\"number\">0</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        p = payload;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>memory_order_release</strong> 和 <strong>memory_order_acquire</strong>是释放和获取序列。<br>release 底层使用了 StoreStore 屏障，保证在此内存操作之前的所有 Store 操作都不可能重排到此操作之后；也可以理解为这个操作使 CPU 将所有缓存写入了内存，使其他缓存可见。<br>acquire 底层使用了 LoadLoad 屏障，保存在此内存操作之后的所有 Load 操作都不可能重排到此操作之前；也可以理解为这个操作使 CPU 将所有抛弃了所有缓存，重新从内存读取数据。<br>使用这种内存序，保证了 std::memory_order_release 之前的 Store 操作按一个批次同步到其他缓存，同时 std::memory_order_acquire 之后的 Load 操作按一个批次从内存加载数据到缓存，保证了局部的一致性。<br>这种内存序因为是按批次来同步缓存的，所以性能优于顺序一致性序列，但是又没有松散序列高效。<br>在下面代码中，就是保证写线程写完之后，读线程才开始读的局部一致性，所以最终的 p 值为 42。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">atomic&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">guard</span><span class=\"params\">(<span class=\"number\">0</span>)</span></span>;</span><br><span class=\"line\"><span class=\"type\">int</span> payload = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 在线程1运行的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread1</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    payload = <span class=\"number\">42</span>;</span><br><span class=\"line\">    guard.<span class=\"built_in\">store</span>(<span class=\"number\">1</span>, std::memory_order_release);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 在线程2运行的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">thread2</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (guard.<span class=\"built_in\">load</span>(std::memory_order_acquire) != <span class=\"number\">0</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        p = payload;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p><strong>memory_order_release</strong> 和 **memory_order_consume **是数据依赖序列。<br>memory_order_consume 的底层实现并不使用内存屏障，而是分析数据依赖来保证数据依赖链上的指令的顺序一致性。<br>在从内存加载数据到缓存的时候，根据数据依赖链的顺序去加载。写入内存还是使用 memory_order_release 的策略不变。这种内存序在多平台方面，支持不是很好，有一些硬件设备并不支持这种内存序列，因此它会被退化成获取-释放序列。</p>\n"},{"title":"Git多路Merge算法原理","date":"2024-02-01T11:02:57.000Z","_content":"这篇笔记是对git使用中自动merge算法的好奇，查找了一些资料，简单做了个总结，留以存档。\n# 1 Git的组成\n## 1.1 工作区(workspace)\n就是我们当前工作空间，也就是我们当前能在本地文件夹下面看到的文件结构。初始化工作空间或者工作空间clean的时候，文件内容和index暂存区是一致的，随着修改，工作区文件在没有add到暂存区时候，工作区将和暂存区是不一致的。\n## 1.2 暂存区(index)\n老版本概念也叫Cache区，就是文件暂时存放的地方，所有暂时存放在暂存区中的文件将随着一个commit一起提交到local repository 此时 local repository里面文件将完全被暂存区所取代。暂存区是git架构设计中非常重要和难理解的一部分。后续会有专门的文章研究暂存区。\n## 1.3 本地仓库(local repository)\ngit 是分布式版本控制系统，和其他版本控制系统不同的是他可以完全去中心化工作，你可以不用和中央服务器(remote server)进行通信，在本地即可进行全部离线操作，包括log，history，commit，diff等等。 完成离线操作最核心是因为git有一个几乎和远程一样的本地仓库，所有本地离线操作都可以在本地完成，等需要的时候再和远程服务进行交互。\n## 1.4 远程仓库(remote repository)\n中心化仓库，所有人共享，本地仓库会需要和远程仓库进行交互，也就能将其他所有人内容更新到本地仓库把自己内容上传分享给其他人。结构大体和本地仓库一样。\n# 2 状态模型\n## 2.1 状态流转![image.png](/images/git-note/1.png)\n## 2.2 文件变化\n![image.png](/images/git-note/2.png)\n# 3 存储模型\ngit 区别与其他 vcs 系统的一个最主要原因之一是：git 对文件版本管理和其他vcs系统对文件版本的实现理念完成不一样。这也就是git 版本管理为什么如此强大的最核心的地方。\nSvn 等其他的VCS对文件版本的理念是以文件为水平维度，记录每个文件在每个版本下的delta改变。\nGit 对文件版本的管理理念却是以每次提交为一次快照，提交时对**所有文件**做一次**全量快照**，然后**存储快照引用**。\nGit 在存储层，如果文件数据没有改变的文件，Git只是存储指向源文件的一个引用，并不会直接多次存储文件，这一点可以在pack 文件中看见。\n如下图所示：\n![image.png](/images/git-note/3.png)\n# 4 Merge算法\n## 4.1 Q&A\n\n- Q: git merge 是用时间先后决定merge结果的，后面会覆盖前面的?\n- A: git 是分布式的文件版本控制系统，在分布式环境中时间是不可靠的，git是靠三路合并算法进行合并的。\n\n- git merge 只要两行不相同就一定会报冲突，叫人工解决?\n- 答：git 尽管两行内容不一样，smart git 会进行取舍，当git无法进行取舍的时候才会进行人工解决冲突。\n\n## 4.2 合并算法\n### 4.2.1 二路合并\n二路合并算法就是讲两个文件进行逐行对别，如果行内容不同就报冲突。\n```cpp\nconsole.log(\"Hello World\");\n```\n```cpp\nconsole.log(\"World Hello\");\n```\n\n- Mine 代表你本地修改\n- Theirs 代表其他人修改\n\n假设对于同一个文件，出现你和其他人一起修改，此时如果git来进行合并，git就懵逼了，因为Git既不敢得罪你(Mine)，也不能得罪他们(Theirs) ，无理无据，git只能让你自己搞了，但是这种情况太多了而且其实也没有必要。\n### 4.2.2 三路合并\n三路合并就是先找出一个基准，然后以基准为Base 进行合并，如果2个文件相对基准(base)都发生了改变 那git 就报冲突，然后让你人工决断。否则，git将取相对于基准(base)变化的那个为最终结果。\n\n- Base 代表上一个版本，即公共祖先\n- Mine 代表你本地修改\n- Theirs 代表其他人修改\n- Merge 代表git进行merge后的结果\n#### 4.2.2.1 自动merge场景\n```cpp\nconsole.log(\"Hello World\");\n```\n```cpp\nconsole.log(\"Hello World\");\n```\n```cpp\nconsole.log(\"World Hello\");\n```\n```cpp\nconsole.log(\"World Hello\");\n```\n这样当git进行合并的时候，git就知道是其他人修改了，本地没有更改，git就会自动把最终结果变成如下，这个结构也是大多merge工具的常见布局，比如IDEA\n#### 4.2.2.2 手动merge场景\n需要手动merge的场景就是Mine和Theis都对相同的\n```cpp\nconsole.log(\"Hello World\");\n```\n```cpp\nconsole.log(\"World Flynn\");\n```\n```cpp\nconsole.log(\"World Hello\");\n```\n```cpp\n<<<<<<<Mine\nconsole.log(\"World Flynn\");\n=======\nconsole.log(\"World Hello\");\n>>>>>>>Theirs\n```\n在这种情况下，Mine和Theirs都对分支进行了修改，git重新遇到了二路合并的问题，需要手动解决冲突。\n#### 4.2.2.3 三路合并示例\n![image.png](/images/git-note/4.png)\n\n1. 上面①~⑨代表一个个修改集合(commit)，每个commit都有一个唯一7位SHA-1唯一表示。\n2. ①，②，④，⑦修改集串联起来就是一个链，此时用master指向这个集合就代表master分支，**分支本质是一个快照。**\n3. 同样dev分支也是由一个个commit组成\n\n现在在dev分支上由于各种原因要运行git merge master需要把master分支的更新合并到dev分支上，本质上就是合并修改集 ⑦(Mine) 和 ⑧(Theirs) ，此时我们要利用**DAG(有向无环图)**相关算法找到我们**公共的祖先** ②（Base）然后进行**三方合并**，最后合并生成 ⑨\n```java\n//找出公共祖先的commitId(Base)\ngit merge-base --all commit_id1(Yours/Theirs) commit_id2(Yours/Theirs) \n```\n在实际开发环境中，分支的Graph更为复杂，但基本的算法原理不变。\n![image.png](/images/git-note/5.png)\n### 4.2.3 递归三路合并\n#### 4.2.3.1 公共祖先不唯一问题\n**抽象化**\n```java\n       ---1---o---A\n           \\ /\n            X\n           / \\\n       ---2---o---o---B\n```\n**具体化**\n![image.png](/images/git-note/6.png)\n> （这部分图有点问题，阅读理解困难，可跳过直接看问题）\n> 简短描述下 如何会出现上面的图：\n> 1. 在master分支上新建文件foo.c ,写入数据\"A\"到文件里面\n> 2. 新建分支task2 **git checkout -b task2 0**,0 代表commit Id\n> 3. 新建并提交commit ① 和 ③\n> 4. 切换分支到master，新建并提交commit ②\n> 5. 新建并修改foo.c文件中数据为\"B\",并提交commit ④\n> 6. merge commit ③ **git merge task2**,生成commit ⑥\n> 7. 新建分支task1 **git chekcout -b ④**\n> 8. 在task1 merge ③ **git merge task2** 生成commit ⑤\n> 9. 新建commit ⑦，并修改foo.c文件内容为\"C\"\n> 10. 切换分支到master上，并准备merge task1 分支(merge ⑦-> ⑥)\n\n\n我们如果要合并 ⑦(source) -> ⑥(destination)\n会发现有⑥和⑦有两个最佳公共祖先③和④\n以③为公共祖先时需要手动解决冲突 /foo.c = BC???\n![image.png](/images/git-note/7.png)\n以④作为公共祖先将得到 /foo.c=C\n![image.png](/images/git-note/8.png)\n#### 4.2.3.2 git解法\ngit 既不是直接用③，也不是用④，而是将2个祖先进行合并成一个虚拟的 X /foo.c = B。因为③ 和 ④ 公共祖先是 0/foo.c = A，根据③和④以及他们的公共祖先进行递归三路归并进行合成的到虚拟的 X /foo.c = B。\n![image.png](/images/git-note/9.png)\n","source":"_posts/Git-note.md","raw":"---\ntitle: Git多路Merge算法原理\ndate: 2024-02-01 19:02:57\ntags: 学习杂记\n---\n这篇笔记是对git使用中自动merge算法的好奇，查找了一些资料，简单做了个总结，留以存档。\n# 1 Git的组成\n## 1.1 工作区(workspace)\n就是我们当前工作空间，也就是我们当前能在本地文件夹下面看到的文件结构。初始化工作空间或者工作空间clean的时候，文件内容和index暂存区是一致的，随着修改，工作区文件在没有add到暂存区时候，工作区将和暂存区是不一致的。\n## 1.2 暂存区(index)\n老版本概念也叫Cache区，就是文件暂时存放的地方，所有暂时存放在暂存区中的文件将随着一个commit一起提交到local repository 此时 local repository里面文件将完全被暂存区所取代。暂存区是git架构设计中非常重要和难理解的一部分。后续会有专门的文章研究暂存区。\n## 1.3 本地仓库(local repository)\ngit 是分布式版本控制系统，和其他版本控制系统不同的是他可以完全去中心化工作，你可以不用和中央服务器(remote server)进行通信，在本地即可进行全部离线操作，包括log，history，commit，diff等等。 完成离线操作最核心是因为git有一个几乎和远程一样的本地仓库，所有本地离线操作都可以在本地完成，等需要的时候再和远程服务进行交互。\n## 1.4 远程仓库(remote repository)\n中心化仓库，所有人共享，本地仓库会需要和远程仓库进行交互，也就能将其他所有人内容更新到本地仓库把自己内容上传分享给其他人。结构大体和本地仓库一样。\n# 2 状态模型\n## 2.1 状态流转![image.png](/images/git-note/1.png)\n## 2.2 文件变化\n![image.png](/images/git-note/2.png)\n# 3 存储模型\ngit 区别与其他 vcs 系统的一个最主要原因之一是：git 对文件版本管理和其他vcs系统对文件版本的实现理念完成不一样。这也就是git 版本管理为什么如此强大的最核心的地方。\nSvn 等其他的VCS对文件版本的理念是以文件为水平维度，记录每个文件在每个版本下的delta改变。\nGit 对文件版本的管理理念却是以每次提交为一次快照，提交时对**所有文件**做一次**全量快照**，然后**存储快照引用**。\nGit 在存储层，如果文件数据没有改变的文件，Git只是存储指向源文件的一个引用，并不会直接多次存储文件，这一点可以在pack 文件中看见。\n如下图所示：\n![image.png](/images/git-note/3.png)\n# 4 Merge算法\n## 4.1 Q&A\n\n- Q: git merge 是用时间先后决定merge结果的，后面会覆盖前面的?\n- A: git 是分布式的文件版本控制系统，在分布式环境中时间是不可靠的，git是靠三路合并算法进行合并的。\n\n- git merge 只要两行不相同就一定会报冲突，叫人工解决?\n- 答：git 尽管两行内容不一样，smart git 会进行取舍，当git无法进行取舍的时候才会进行人工解决冲突。\n\n## 4.2 合并算法\n### 4.2.1 二路合并\n二路合并算法就是讲两个文件进行逐行对别，如果行内容不同就报冲突。\n```cpp\nconsole.log(\"Hello World\");\n```\n```cpp\nconsole.log(\"World Hello\");\n```\n\n- Mine 代表你本地修改\n- Theirs 代表其他人修改\n\n假设对于同一个文件，出现你和其他人一起修改，此时如果git来进行合并，git就懵逼了，因为Git既不敢得罪你(Mine)，也不能得罪他们(Theirs) ，无理无据，git只能让你自己搞了，但是这种情况太多了而且其实也没有必要。\n### 4.2.2 三路合并\n三路合并就是先找出一个基准，然后以基准为Base 进行合并，如果2个文件相对基准(base)都发生了改变 那git 就报冲突，然后让你人工决断。否则，git将取相对于基准(base)变化的那个为最终结果。\n\n- Base 代表上一个版本，即公共祖先\n- Mine 代表你本地修改\n- Theirs 代表其他人修改\n- Merge 代表git进行merge后的结果\n#### 4.2.2.1 自动merge场景\n```cpp\nconsole.log(\"Hello World\");\n```\n```cpp\nconsole.log(\"Hello World\");\n```\n```cpp\nconsole.log(\"World Hello\");\n```\n```cpp\nconsole.log(\"World Hello\");\n```\n这样当git进行合并的时候，git就知道是其他人修改了，本地没有更改，git就会自动把最终结果变成如下，这个结构也是大多merge工具的常见布局，比如IDEA\n#### 4.2.2.2 手动merge场景\n需要手动merge的场景就是Mine和Theis都对相同的\n```cpp\nconsole.log(\"Hello World\");\n```\n```cpp\nconsole.log(\"World Flynn\");\n```\n```cpp\nconsole.log(\"World Hello\");\n```\n```cpp\n<<<<<<<Mine\nconsole.log(\"World Flynn\");\n=======\nconsole.log(\"World Hello\");\n>>>>>>>Theirs\n```\n在这种情况下，Mine和Theirs都对分支进行了修改，git重新遇到了二路合并的问题，需要手动解决冲突。\n#### 4.2.2.3 三路合并示例\n![image.png](/images/git-note/4.png)\n\n1. 上面①~⑨代表一个个修改集合(commit)，每个commit都有一个唯一7位SHA-1唯一表示。\n2. ①，②，④，⑦修改集串联起来就是一个链，此时用master指向这个集合就代表master分支，**分支本质是一个快照。**\n3. 同样dev分支也是由一个个commit组成\n\n现在在dev分支上由于各种原因要运行git merge master需要把master分支的更新合并到dev分支上，本质上就是合并修改集 ⑦(Mine) 和 ⑧(Theirs) ，此时我们要利用**DAG(有向无环图)**相关算法找到我们**公共的祖先** ②（Base）然后进行**三方合并**，最后合并生成 ⑨\n```java\n//找出公共祖先的commitId(Base)\ngit merge-base --all commit_id1(Yours/Theirs) commit_id2(Yours/Theirs) \n```\n在实际开发环境中，分支的Graph更为复杂，但基本的算法原理不变。\n![image.png](/images/git-note/5.png)\n### 4.2.3 递归三路合并\n#### 4.2.3.1 公共祖先不唯一问题\n**抽象化**\n```java\n       ---1---o---A\n           \\ /\n            X\n           / \\\n       ---2---o---o---B\n```\n**具体化**\n![image.png](/images/git-note/6.png)\n> （这部分图有点问题，阅读理解困难，可跳过直接看问题）\n> 简短描述下 如何会出现上面的图：\n> 1. 在master分支上新建文件foo.c ,写入数据\"A\"到文件里面\n> 2. 新建分支task2 **git checkout -b task2 0**,0 代表commit Id\n> 3. 新建并提交commit ① 和 ③\n> 4. 切换分支到master，新建并提交commit ②\n> 5. 新建并修改foo.c文件中数据为\"B\",并提交commit ④\n> 6. merge commit ③ **git merge task2**,生成commit ⑥\n> 7. 新建分支task1 **git chekcout -b ④**\n> 8. 在task1 merge ③ **git merge task2** 生成commit ⑤\n> 9. 新建commit ⑦，并修改foo.c文件内容为\"C\"\n> 10. 切换分支到master上，并准备merge task1 分支(merge ⑦-> ⑥)\n\n\n我们如果要合并 ⑦(source) -> ⑥(destination)\n会发现有⑥和⑦有两个最佳公共祖先③和④\n以③为公共祖先时需要手动解决冲突 /foo.c = BC???\n![image.png](/images/git-note/7.png)\n以④作为公共祖先将得到 /foo.c=C\n![image.png](/images/git-note/8.png)\n#### 4.2.3.2 git解法\ngit 既不是直接用③，也不是用④，而是将2个祖先进行合并成一个虚拟的 X /foo.c = B。因为③ 和 ④ 公共祖先是 0/foo.c = A，根据③和④以及他们的公共祖先进行递归三路归并进行合成的到虚拟的 X /foo.c = B。\n![image.png](/images/git-note/9.png)\n","slug":"Git-note","published":1,"updated":"2024-02-01T11:11:21.194Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cls34916b0000ynx57dh67tl8","content":"<p>这篇笔记是对git使用中自动merge算法的好奇，查找了一些资料，简单做了个总结，留以存档。</p>\n<h1 id=\"1-Git的组成\"><a href=\"#1-Git的组成\" class=\"headerlink\" title=\"1 Git的组成\"></a>1 Git的组成</h1><h2 id=\"1-1-工作区-workspace\"><a href=\"#1-1-工作区-workspace\" class=\"headerlink\" title=\"1.1 工作区(workspace)\"></a>1.1 工作区(workspace)</h2><p>就是我们当前工作空间，也就是我们当前能在本地文件夹下面看到的文件结构。初始化工作空间或者工作空间clean的时候，文件内容和index暂存区是一致的，随着修改，工作区文件在没有add到暂存区时候，工作区将和暂存区是不一致的。</p>\n<h2 id=\"1-2-暂存区-index\"><a href=\"#1-2-暂存区-index\" class=\"headerlink\" title=\"1.2 暂存区(index)\"></a>1.2 暂存区(index)</h2><p>老版本概念也叫Cache区，就是文件暂时存放的地方，所有暂时存放在暂存区中的文件将随着一个commit一起提交到local repository 此时 local repository里面文件将完全被暂存区所取代。暂存区是git架构设计中非常重要和难理解的一部分。后续会有专门的文章研究暂存区。</p>\n<h2 id=\"1-3-本地仓库-local-repository\"><a href=\"#1-3-本地仓库-local-repository\" class=\"headerlink\" title=\"1.3 本地仓库(local repository)\"></a>1.3 本地仓库(local repository)</h2><p>git 是分布式版本控制系统，和其他版本控制系统不同的是他可以完全去中心化工作，你可以不用和中央服务器(remote server)进行通信，在本地即可进行全部离线操作，包括log，history，commit，diff等等。 完成离线操作最核心是因为git有一个几乎和远程一样的本地仓库，所有本地离线操作都可以在本地完成，等需要的时候再和远程服务进行交互。</p>\n<h2 id=\"1-4-远程仓库-remote-repository\"><a href=\"#1-4-远程仓库-remote-repository\" class=\"headerlink\" title=\"1.4 远程仓库(remote repository)\"></a>1.4 远程仓库(remote repository)</h2><p>中心化仓库，所有人共享，本地仓库会需要和远程仓库进行交互，也就能将其他所有人内容更新到本地仓库把自己内容上传分享给其他人。结构大体和本地仓库一样。</p>\n<h1 id=\"2-状态模型\"><a href=\"#2-状态模型\" class=\"headerlink\" title=\"2 状态模型\"></a>2 状态模型</h1><h2 id=\"2-1-状态流转\"><a href=\"#2-1-状态流转\" class=\"headerlink\" title=\"2.1 状态流转\"></a>2.1 状态流转<img src=\"/images/git-note/1.png\" alt=\"image.png\"></h2><h2 id=\"2-2-文件变化\"><a href=\"#2-2-文件变化\" class=\"headerlink\" title=\"2.2 文件变化\"></a>2.2 文件变化</h2><p><img src=\"/images/git-note/2.png\" alt=\"image.png\"></p>\n<h1 id=\"3-存储模型\"><a href=\"#3-存储模型\" class=\"headerlink\" title=\"3 存储模型\"></a>3 存储模型</h1><p>git 区别与其他 vcs 系统的一个最主要原因之一是：git 对文件版本管理和其他vcs系统对文件版本的实现理念完成不一样。这也就是git 版本管理为什么如此强大的最核心的地方。<br>Svn 等其他的VCS对文件版本的理念是以文件为水平维度，记录每个文件在每个版本下的delta改变。<br>Git 对文件版本的管理理念却是以每次提交为一次快照，提交时对<strong>所有文件</strong>做一次<strong>全量快照</strong>，然后<strong>存储快照引用</strong>。<br>Git 在存储层，如果文件数据没有改变的文件，Git只是存储指向源文件的一个引用，并不会直接多次存储文件，这一点可以在pack 文件中看见。<br>如下图所示：<br><img src=\"/images/git-note/3.png\" alt=\"image.png\"></p>\n<h1 id=\"4-Merge算法\"><a href=\"#4-Merge算法\" class=\"headerlink\" title=\"4 Merge算法\"></a>4 Merge算法</h1><h2 id=\"4-1-Q-A\"><a href=\"#4-1-Q-A\" class=\"headerlink\" title=\"4.1 Q&amp;A\"></a>4.1 Q&amp;A</h2><ul>\n<li><p>Q: git merge 是用时间先后决定merge结果的，后面会覆盖前面的?</p>\n</li>\n<li><p>A: git 是分布式的文件版本控制系统，在分布式环境中时间是不可靠的，git是靠三路合并算法进行合并的。</p>\n</li>\n<li><p>git merge 只要两行不相同就一定会报冲突，叫人工解决?</p>\n</li>\n<li><p>答：git 尽管两行内容不一样，smart git 会进行取舍，当git无法进行取舍的时候才会进行人工解决冲突。</p>\n</li>\n</ul>\n<h2 id=\"4-2-合并算法\"><a href=\"#4-2-合并算法\" class=\"headerlink\" title=\"4.2 合并算法\"></a>4.2 合并算法</h2><h3 id=\"4-2-1-二路合并\"><a href=\"#4-2-1-二路合并\" class=\"headerlink\" title=\"4.2.1 二路合并\"></a>4.2.1 二路合并</h3><p>二路合并算法就是讲两个文件进行逐行对别，如果行内容不同就报冲突。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;Hello World&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Hello&quot;</span>);</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Mine 代表你本地修改</li>\n<li>Theirs 代表其他人修改</li>\n</ul>\n<p>假设对于同一个文件，出现你和其他人一起修改，此时如果git来进行合并，git就懵逼了，因为Git既不敢得罪你(Mine)，也不能得罪他们(Theirs) ，无理无据，git只能让你自己搞了，但是这种情况太多了而且其实也没有必要。</p>\n<h3 id=\"4-2-2-三路合并\"><a href=\"#4-2-2-三路合并\" class=\"headerlink\" title=\"4.2.2 三路合并\"></a>4.2.2 三路合并</h3><p>三路合并就是先找出一个基准，然后以基准为Base 进行合并，如果2个文件相对基准(base)都发生了改变 那git 就报冲突，然后让你人工决断。否则，git将取相对于基准(base)变化的那个为最终结果。</p>\n<ul>\n<li>Base 代表上一个版本，即公共祖先</li>\n<li>Mine 代表你本地修改</li>\n<li>Theirs 代表其他人修改</li>\n<li>Merge 代表git进行merge后的结果</li>\n</ul>\n<h4 id=\"4-2-2-1-自动merge场景\"><a href=\"#4-2-2-1-自动merge场景\" class=\"headerlink\" title=\"4.2.2.1 自动merge场景\"></a>4.2.2.1 自动merge场景</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;Hello World&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;Hello World&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Hello&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Hello&quot;</span>);</span><br></pre></td></tr></table></figure>\n<p>这样当git进行合并的时候，git就知道是其他人修改了，本地没有更改，git就会自动把最终结果变成如下，这个结构也是大多merge工具的常见布局，比如IDEA</p>\n<h4 id=\"4-2-2-2-手动merge场景\"><a href=\"#4-2-2-2-手动merge场景\" class=\"headerlink\" title=\"4.2.2.2 手动merge场景\"></a>4.2.2.2 手动merge场景</h4><p>需要手动merge的场景就是Mine和Theis都对相同的</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;Hello World&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Flynn&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Hello&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;&lt;&lt;&lt;&lt;&lt;&lt;Mine</span><br><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Flynn&quot;</span>);</span><br><span class=\"line\">=======</span><br><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Hello&quot;</span>);</span><br><span class=\"line\">&gt;&gt;&gt;&gt;&gt;&gt;&gt;Theirs</span><br></pre></td></tr></table></figure>\n<p>在这种情况下，Mine和Theirs都对分支进行了修改，git重新遇到了二路合并的问题，需要手动解决冲突。</p>\n<h4 id=\"4-2-2-3-三路合并示例\"><a href=\"#4-2-2-3-三路合并示例\" class=\"headerlink\" title=\"4.2.2.3 三路合并示例\"></a>4.2.2.3 三路合并示例</h4><p><img src=\"/images/git-note/4.png\" alt=\"image.png\"></p>\n<ol>\n<li>上面①~⑨代表一个个修改集合(commit)，每个commit都有一个唯一7位SHA-1唯一表示。</li>\n<li>①，②，④，⑦修改集串联起来就是一个链，此时用master指向这个集合就代表master分支，<strong>分支本质是一个快照。</strong></li>\n<li>同样dev分支也是由一个个commit组成</li>\n</ol>\n<p>现在在dev分支上由于各种原因要运行git merge master需要把master分支的更新合并到dev分支上，本质上就是合并修改集 ⑦(Mine) 和 ⑧(Theirs) ，此时我们要利用<strong>DAG(有向无环图)<strong>相关算法找到我们</strong>公共的祖先</strong> ②（Base）然后进行<strong>三方合并</strong>，最后合并生成 ⑨</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//找出公共祖先的commitId(Base)</span></span><br><span class=\"line\">git merge-base --all <span class=\"title function_\">commit_id1</span><span class=\"params\">(Yours/Theirs)</span> commit_id2(Yours/Theirs) </span><br></pre></td></tr></table></figure>\n<p>在实际开发环境中，分支的Graph更为复杂，但基本的算法原理不变。<br><img src=\"/images/git-note/5.png\" alt=\"image.png\"></p>\n<h3 id=\"4-2-3-递归三路合并\"><a href=\"#4-2-3-递归三路合并\" class=\"headerlink\" title=\"4.2.3 递归三路合并\"></a>4.2.3 递归三路合并</h3><h4 id=\"4-2-3-1-公共祖先不唯一问题\"><a href=\"#4-2-3-1-公共祖先不唯一问题\" class=\"headerlink\" title=\"4.2.3.1 公共祖先不唯一问题\"></a>4.2.3.1 公共祖先不唯一问题</h4><p><strong>抽象化</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---<span class=\"number\">1</span>---o---A</span><br><span class=\"line\">    \\ /</span><br><span class=\"line\">     X</span><br><span class=\"line\">    / \\</span><br><span class=\"line\">---<span class=\"number\">2</span>---o---o---B</span><br></pre></td></tr></table></figure>\n<p><strong>具体化</strong><br><img src=\"/images/git-note/6.png\" alt=\"image.png\"></p>\n<blockquote>\n<p>（这部分图有点问题，阅读理解困难，可跳过直接看问题）<br>简短描述下 如何会出现上面的图：</p>\n<ol>\n<li>在master分支上新建文件foo.c ,写入数据”A”到文件里面</li>\n<li>新建分支task2 <strong>git checkout -b task2 0</strong>,0 代表commit Id</li>\n<li>新建并提交commit ① 和 ③</li>\n<li>切换分支到master，新建并提交commit ②</li>\n<li>新建并修改foo.c文件中数据为”B”,并提交commit ④</li>\n<li>merge commit ③ <strong>git merge task2</strong>,生成commit ⑥</li>\n<li>新建分支task1 <strong>git chekcout -b ④</strong></li>\n<li>在task1 merge ③ <strong>git merge task2</strong> 生成commit ⑤</li>\n<li>新建commit ⑦，并修改foo.c文件内容为”C”</li>\n<li>切换分支到master上，并准备merge task1 分支(merge ⑦-&gt; ⑥)</li>\n</ol>\n</blockquote>\n<p>我们如果要合并 ⑦(source) -&gt; ⑥(destination)<br>会发现有⑥和⑦有两个最佳公共祖先③和④<br>以③为公共祖先时需要手动解决冲突 &#x2F;foo.c &#x3D; BC???<br><img src=\"/images/git-note/7.png\" alt=\"image.png\"><br>以④作为公共祖先将得到 &#x2F;foo.c&#x3D;C<br><img src=\"/images/git-note/8.png\" alt=\"image.png\"></p>\n<h4 id=\"4-2-3-2-git解法\"><a href=\"#4-2-3-2-git解法\" class=\"headerlink\" title=\"4.2.3.2 git解法\"></a>4.2.3.2 git解法</h4><p>git 既不是直接用③，也不是用④，而是将2个祖先进行合并成一个虚拟的 X &#x2F;foo.c &#x3D; B。因为③ 和 ④ 公共祖先是 0&#x2F;foo.c &#x3D; A，根据③和④以及他们的公共祖先进行递归三路归并进行合成的到虚拟的 X &#x2F;foo.c &#x3D; B。<br><img src=\"/images/git-note/9.png\" alt=\"image.png\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>这篇笔记是对git使用中自动merge算法的好奇，查找了一些资料，简单做了个总结，留以存档。</p>\n<h1 id=\"1-Git的组成\"><a href=\"#1-Git的组成\" class=\"headerlink\" title=\"1 Git的组成\"></a>1 Git的组成</h1><h2 id=\"1-1-工作区-workspace\"><a href=\"#1-1-工作区-workspace\" class=\"headerlink\" title=\"1.1 工作区(workspace)\"></a>1.1 工作区(workspace)</h2><p>就是我们当前工作空间，也就是我们当前能在本地文件夹下面看到的文件结构。初始化工作空间或者工作空间clean的时候，文件内容和index暂存区是一致的，随着修改，工作区文件在没有add到暂存区时候，工作区将和暂存区是不一致的。</p>\n<h2 id=\"1-2-暂存区-index\"><a href=\"#1-2-暂存区-index\" class=\"headerlink\" title=\"1.2 暂存区(index)\"></a>1.2 暂存区(index)</h2><p>老版本概念也叫Cache区，就是文件暂时存放的地方，所有暂时存放在暂存区中的文件将随着一个commit一起提交到local repository 此时 local repository里面文件将完全被暂存区所取代。暂存区是git架构设计中非常重要和难理解的一部分。后续会有专门的文章研究暂存区。</p>\n<h2 id=\"1-3-本地仓库-local-repository\"><a href=\"#1-3-本地仓库-local-repository\" class=\"headerlink\" title=\"1.3 本地仓库(local repository)\"></a>1.3 本地仓库(local repository)</h2><p>git 是分布式版本控制系统，和其他版本控制系统不同的是他可以完全去中心化工作，你可以不用和中央服务器(remote server)进行通信，在本地即可进行全部离线操作，包括log，history，commit，diff等等。 完成离线操作最核心是因为git有一个几乎和远程一样的本地仓库，所有本地离线操作都可以在本地完成，等需要的时候再和远程服务进行交互。</p>\n<h2 id=\"1-4-远程仓库-remote-repository\"><a href=\"#1-4-远程仓库-remote-repository\" class=\"headerlink\" title=\"1.4 远程仓库(remote repository)\"></a>1.4 远程仓库(remote repository)</h2><p>中心化仓库，所有人共享，本地仓库会需要和远程仓库进行交互，也就能将其他所有人内容更新到本地仓库把自己内容上传分享给其他人。结构大体和本地仓库一样。</p>\n<h1 id=\"2-状态模型\"><a href=\"#2-状态模型\" class=\"headerlink\" title=\"2 状态模型\"></a>2 状态模型</h1><h2 id=\"2-1-状态流转\"><a href=\"#2-1-状态流转\" class=\"headerlink\" title=\"2.1 状态流转\"></a>2.1 状态流转<img src=\"/images/git-note/1.png\" alt=\"image.png\"></h2><h2 id=\"2-2-文件变化\"><a href=\"#2-2-文件变化\" class=\"headerlink\" title=\"2.2 文件变化\"></a>2.2 文件变化</h2><p><img src=\"/images/git-note/2.png\" alt=\"image.png\"></p>\n<h1 id=\"3-存储模型\"><a href=\"#3-存储模型\" class=\"headerlink\" title=\"3 存储模型\"></a>3 存储模型</h1><p>git 区别与其他 vcs 系统的一个最主要原因之一是：git 对文件版本管理和其他vcs系统对文件版本的实现理念完成不一样。这也就是git 版本管理为什么如此强大的最核心的地方。<br>Svn 等其他的VCS对文件版本的理念是以文件为水平维度，记录每个文件在每个版本下的delta改变。<br>Git 对文件版本的管理理念却是以每次提交为一次快照，提交时对<strong>所有文件</strong>做一次<strong>全量快照</strong>，然后<strong>存储快照引用</strong>。<br>Git 在存储层，如果文件数据没有改变的文件，Git只是存储指向源文件的一个引用，并不会直接多次存储文件，这一点可以在pack 文件中看见。<br>如下图所示：<br><img src=\"/images/git-note/3.png\" alt=\"image.png\"></p>\n<h1 id=\"4-Merge算法\"><a href=\"#4-Merge算法\" class=\"headerlink\" title=\"4 Merge算法\"></a>4 Merge算法</h1><h2 id=\"4-1-Q-A\"><a href=\"#4-1-Q-A\" class=\"headerlink\" title=\"4.1 Q&amp;A\"></a>4.1 Q&amp;A</h2><ul>\n<li><p>Q: git merge 是用时间先后决定merge结果的，后面会覆盖前面的?</p>\n</li>\n<li><p>A: git 是分布式的文件版本控制系统，在分布式环境中时间是不可靠的，git是靠三路合并算法进行合并的。</p>\n</li>\n<li><p>git merge 只要两行不相同就一定会报冲突，叫人工解决?</p>\n</li>\n<li><p>答：git 尽管两行内容不一样，smart git 会进行取舍，当git无法进行取舍的时候才会进行人工解决冲突。</p>\n</li>\n</ul>\n<h2 id=\"4-2-合并算法\"><a href=\"#4-2-合并算法\" class=\"headerlink\" title=\"4.2 合并算法\"></a>4.2 合并算法</h2><h3 id=\"4-2-1-二路合并\"><a href=\"#4-2-1-二路合并\" class=\"headerlink\" title=\"4.2.1 二路合并\"></a>4.2.1 二路合并</h3><p>二路合并算法就是讲两个文件进行逐行对别，如果行内容不同就报冲突。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;Hello World&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Hello&quot;</span>);</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Mine 代表你本地修改</li>\n<li>Theirs 代表其他人修改</li>\n</ul>\n<p>假设对于同一个文件，出现你和其他人一起修改，此时如果git来进行合并，git就懵逼了，因为Git既不敢得罪你(Mine)，也不能得罪他们(Theirs) ，无理无据，git只能让你自己搞了，但是这种情况太多了而且其实也没有必要。</p>\n<h3 id=\"4-2-2-三路合并\"><a href=\"#4-2-2-三路合并\" class=\"headerlink\" title=\"4.2.2 三路合并\"></a>4.2.2 三路合并</h3><p>三路合并就是先找出一个基准，然后以基准为Base 进行合并，如果2个文件相对基准(base)都发生了改变 那git 就报冲突，然后让你人工决断。否则，git将取相对于基准(base)变化的那个为最终结果。</p>\n<ul>\n<li>Base 代表上一个版本，即公共祖先</li>\n<li>Mine 代表你本地修改</li>\n<li>Theirs 代表其他人修改</li>\n<li>Merge 代表git进行merge后的结果</li>\n</ul>\n<h4 id=\"4-2-2-1-自动merge场景\"><a href=\"#4-2-2-1-自动merge场景\" class=\"headerlink\" title=\"4.2.2.1 自动merge场景\"></a>4.2.2.1 自动merge场景</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;Hello World&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;Hello World&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Hello&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Hello&quot;</span>);</span><br></pre></td></tr></table></figure>\n<p>这样当git进行合并的时候，git就知道是其他人修改了，本地没有更改，git就会自动把最终结果变成如下，这个结构也是大多merge工具的常见布局，比如IDEA</p>\n<h4 id=\"4-2-2-2-手动merge场景\"><a href=\"#4-2-2-2-手动merge场景\" class=\"headerlink\" title=\"4.2.2.2 手动merge场景\"></a>4.2.2.2 手动merge场景</h4><p>需要手动merge的场景就是Mine和Theis都对相同的</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;Hello World&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Flynn&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Hello&quot;</span>);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;&lt;&lt;&lt;&lt;&lt;&lt;Mine</span><br><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Flynn&quot;</span>);</span><br><span class=\"line\">=======</span><br><span class=\"line\">console.<span class=\"built_in\">log</span>(<span class=\"string\">&quot;World Hello&quot;</span>);</span><br><span class=\"line\">&gt;&gt;&gt;&gt;&gt;&gt;&gt;Theirs</span><br></pre></td></tr></table></figure>\n<p>在这种情况下，Mine和Theirs都对分支进行了修改，git重新遇到了二路合并的问题，需要手动解决冲突。</p>\n<h4 id=\"4-2-2-3-三路合并示例\"><a href=\"#4-2-2-3-三路合并示例\" class=\"headerlink\" title=\"4.2.2.3 三路合并示例\"></a>4.2.2.3 三路合并示例</h4><p><img src=\"/images/git-note/4.png\" alt=\"image.png\"></p>\n<ol>\n<li>上面①~⑨代表一个个修改集合(commit)，每个commit都有一个唯一7位SHA-1唯一表示。</li>\n<li>①，②，④，⑦修改集串联起来就是一个链，此时用master指向这个集合就代表master分支，<strong>分支本质是一个快照。</strong></li>\n<li>同样dev分支也是由一个个commit组成</li>\n</ol>\n<p>现在在dev分支上由于各种原因要运行git merge master需要把master分支的更新合并到dev分支上，本质上就是合并修改集 ⑦(Mine) 和 ⑧(Theirs) ，此时我们要利用<strong>DAG(有向无环图)<strong>相关算法找到我们</strong>公共的祖先</strong> ②（Base）然后进行<strong>三方合并</strong>，最后合并生成 ⑨</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//找出公共祖先的commitId(Base)</span></span><br><span class=\"line\">git merge-base --all <span class=\"title function_\">commit_id1</span><span class=\"params\">(Yours/Theirs)</span> commit_id2(Yours/Theirs) </span><br></pre></td></tr></table></figure>\n<p>在实际开发环境中，分支的Graph更为复杂，但基本的算法原理不变。<br><img src=\"/images/git-note/5.png\" alt=\"image.png\"></p>\n<h3 id=\"4-2-3-递归三路合并\"><a href=\"#4-2-3-递归三路合并\" class=\"headerlink\" title=\"4.2.3 递归三路合并\"></a>4.2.3 递归三路合并</h3><h4 id=\"4-2-3-1-公共祖先不唯一问题\"><a href=\"#4-2-3-1-公共祖先不唯一问题\" class=\"headerlink\" title=\"4.2.3.1 公共祖先不唯一问题\"></a>4.2.3.1 公共祖先不唯一问题</h4><p><strong>抽象化</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---<span class=\"number\">1</span>---o---A</span><br><span class=\"line\">    \\ /</span><br><span class=\"line\">     X</span><br><span class=\"line\">    / \\</span><br><span class=\"line\">---<span class=\"number\">2</span>---o---o---B</span><br></pre></td></tr></table></figure>\n<p><strong>具体化</strong><br><img src=\"/images/git-note/6.png\" alt=\"image.png\"></p>\n<blockquote>\n<p>（这部分图有点问题，阅读理解困难，可跳过直接看问题）<br>简短描述下 如何会出现上面的图：</p>\n<ol>\n<li>在master分支上新建文件foo.c ,写入数据”A”到文件里面</li>\n<li>新建分支task2 <strong>git checkout -b task2 0</strong>,0 代表commit Id</li>\n<li>新建并提交commit ① 和 ③</li>\n<li>切换分支到master，新建并提交commit ②</li>\n<li>新建并修改foo.c文件中数据为”B”,并提交commit ④</li>\n<li>merge commit ③ <strong>git merge task2</strong>,生成commit ⑥</li>\n<li>新建分支task1 <strong>git chekcout -b ④</strong></li>\n<li>在task1 merge ③ <strong>git merge task2</strong> 生成commit ⑤</li>\n<li>新建commit ⑦，并修改foo.c文件内容为”C”</li>\n<li>切换分支到master上，并准备merge task1 分支(merge ⑦-&gt; ⑥)</li>\n</ol>\n</blockquote>\n<p>我们如果要合并 ⑦(source) -&gt; ⑥(destination)<br>会发现有⑥和⑦有两个最佳公共祖先③和④<br>以③为公共祖先时需要手动解决冲突 &#x2F;foo.c &#x3D; BC???<br><img src=\"/images/git-note/7.png\" alt=\"image.png\"><br>以④作为公共祖先将得到 &#x2F;foo.c&#x3D;C<br><img src=\"/images/git-note/8.png\" alt=\"image.png\"></p>\n<h4 id=\"4-2-3-2-git解法\"><a href=\"#4-2-3-2-git解法\" class=\"headerlink\" title=\"4.2.3.2 git解法\"></a>4.2.3.2 git解法</h4><p>git 既不是直接用③，也不是用④，而是将2个祖先进行合并成一个虚拟的 X &#x2F;foo.c &#x3D; B。因为③ 和 ④ 公共祖先是 0&#x2F;foo.c &#x3D; A，根据③和④以及他们的公共祖先进行递归三路归并进行合成的到虚拟的 X &#x2F;foo.c &#x3D; B。<br><img src=\"/images/git-note/9.png\" alt=\"image.png\"></p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"clrhz6rwf00010ox533q1ciw5","tag_id":"clrhz6rwk00030ox5fj28fcof","_id":"clrhz6rwq00080ox5hzu64s3m"},{"post_id":"clrhz6rws000a0ox546afb3zn","tag_id":"clrhz6rwp00070ox59wtr7non","_id":"clrhz6rwy000h0ox563hn4gz5"},{"post_id":"clrhz6rwv000d0ox53yrbdp5h","tag_id":"clrhz6rx3000o0ox53fm0aedb","_id":"clrhz6rx4000s0ox55dyn2vtx"},{"post_id":"clrhz6rwv000d0ox53yrbdp5h","tag_id":"clrhz6rwp00070ox59wtr7non","_id":"clrhz6rx5000t0ox5ayvmhsh9"},{"post_id":"cls01gnk000001ax57sxn64hc","tag_id":"clrhz6rx4000r0ox56u9g5wdy","_id":"cls01gnk600011ax5b7c61vku"},{"post_id":"cls21ghtm0000ygx533k5a3an","tag_id":"clrhz6rwp00070ox59wtr7non","_id":"cls21ghts0002ygx5a06p2jej"},{"post_id":"cls21ghtq0001ygx55ii23rhs","tag_id":"clrhz6rwp00070ox59wtr7non","_id":"cls21ghts0003ygx5bm8xecs8"},{"post_id":"cls34916b0000ynx57dh67tl8","tag_id":"cls34916n0001ynx5fvzbhfmb","_id":"cls34916r0002ynx58swjfrp2"}],"Tag":[{"name":"design pattern","_id":"clrhz6rwk00030ox5fj28fcof"},{"name":"Cpp","_id":"clrhz6rwp00070ox59wtr7non"},{"name":"Gpt","_id":"clrhz6rx3000o0ox53fm0aedb"},{"name":"Plan","_id":"clrhz6rx4000r0ox56u9g5wdy"},{"name":"学习杂记","_id":"cls34916n0001ynx5fvzbhfmb"}]}}